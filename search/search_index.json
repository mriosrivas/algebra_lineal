{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"\u00c1lgebra Lineal por Manuel R\u00edos Esta es una p\u00e1gina en desarrollo por lo que pueden haber muchos errores, los cuales puedes reportar . \u00c1lgebra Lineal es Una rama de las matem\u00e1ticas que estudia conceptos como: Sistemas de ecuaciones lineal Vectores Matrices Espacios vectoriales Transformaciones lineales \u00bfQuienes la usan? Matem\u00e1ticos F\u00edsicos Ingenieros Computadoras Libro de Texto \u00c1lgebra Lineal y sus Aplicaciones","title":"Inicio"},{"location":"#algebra-lineal","text":"","title":"\u00c1lgebra Lineal"},{"location":"#por-manuel-rios","text":"Esta es una p\u00e1gina en desarrollo por lo que pueden haber muchos errores, los cuales puedes reportar .","title":"por Manuel R\u00edos"},{"location":"#algebra-lineal-es","text":"Una rama de las matem\u00e1ticas que estudia conceptos como: Sistemas de ecuaciones lineal Vectores Matrices Espacios vectoriales Transformaciones lineales","title":"\u00c1lgebra Lineal es"},{"location":"#quienes-la-usan","text":"Matem\u00e1ticos F\u00edsicos Ingenieros Computadoras Libro de Texto \u00c1lgebra Lineal y sus Aplicaciones","title":"\u00bfQuienes la usan?"},{"location":"programa_2020/","text":"Programa de \u00c1lgebra Lineal CONTENIDO SECCI\u00d3N FECHAS Ecuaciones lineales en \u00e1lgebra lineal Sistemas de ecuaciones lineales. 1.1 25/05 Reducci\u00f3n por filas y formas escalonadas. 1.2 26/05 Ecuaciones vectoriales. 1.3 27/05 Ecuaci\u00f3n matricial $A\\boldsymbol{x}=\\boldsymbol{b}$ 1.4 27/05 Conjuntos soluci\u00f3n de sistemas lineales. 1.5 28/05 Independencia lineal. 1.7 28/05 Introducci\u00f3n a las transformaciones lineales. 1.8 01/06 Matriz de una transformaci\u00f3n lineal. 1.9 01/06 Primer Examen Corto 1.1-1.9 02/06 \u00c1lgebra de matrices Operaciones de matrices. 2.1 03/06 La inversa de una matriz. 2.2 04/06 Caracterizaciones de matrices invertibles. 2.3 08/06 Factorizaciones de matrices. 2.5 09/06 Aplicaciones a los gr\u00e1ficos por computadora. 2.7 10/06 Segundo Examen Corto 2.1-2.7 12/06 [1] Determinantes Introducci\u00f3n a los determinantes. 3.1 11/06 Propiedades de los determinantes. 3.2 11/06 Espacios vectoriales Espacios y subespacios vectoriales. 4.1 15/06 Espacios nulos, espacios columna y transformaciones lineales. 4.2 16/06 Tercer Examen Corto 3.1-3.2, 4.1-4-2 18/06 Conjuntos linealmente independientes. 4.3 17/06 Sistemas de coordenadas. 4.4 22/06 La dimensi\u00f3n de un espacio vectorial. 4.5 23/06 Rango. 4.6 24/06 Cadenas de Markov. 4.9 25/06 Cuarto Examen Corto 4.3-4-9 29/06 Valores propios y vectores propios Vectores propios y valores propios. 5.1 01/07 La ecuaci\u00f3n caracter\u00edstica. 5.2 02/07 Diagonalizaci\u00f3n. 5.3 06/07 Quinto Examen Corto 5.1-5.3 10/07 [1] Ortogonalidad y m\u00ednimos cuadrados Producto interior, longitud y ortogonalidad. 6.1 07/07 Conjuntos ortogonales. 6.2 08/07 Proyecciones ortogonales. 6.3 08/07 Proceso Gram-Schmidt. 6.4 09/07 Problemas de m\u00ednimos cuadrados. 6.5 09/07 Examen Final 15/07 Ponderaci\u00f3n del Curso Actividad Cantidad Punteo Ex\u00e1menes Cortos 5 60 Tareas - 10 Final 1 30 [1] Estos d\u00edas son viernes, por lo que ser\u00e1n fuera del d\u00eda normal de clases.","title":"Programaci\u00f3n del Curso"},{"location":"programa_2020/#programa-de-algebra-lineal","text":"CONTENIDO SECCI\u00d3N FECHAS Ecuaciones lineales en \u00e1lgebra lineal Sistemas de ecuaciones lineales. 1.1 25/05 Reducci\u00f3n por filas y formas escalonadas. 1.2 26/05 Ecuaciones vectoriales. 1.3 27/05 Ecuaci\u00f3n matricial $A\\boldsymbol{x}=\\boldsymbol{b}$ 1.4 27/05 Conjuntos soluci\u00f3n de sistemas lineales. 1.5 28/05 Independencia lineal. 1.7 28/05 Introducci\u00f3n a las transformaciones lineales. 1.8 01/06 Matriz de una transformaci\u00f3n lineal. 1.9 01/06 Primer Examen Corto 1.1-1.9 02/06 \u00c1lgebra de matrices Operaciones de matrices. 2.1 03/06 La inversa de una matriz. 2.2 04/06 Caracterizaciones de matrices invertibles. 2.3 08/06 Factorizaciones de matrices. 2.5 09/06 Aplicaciones a los gr\u00e1ficos por computadora. 2.7 10/06 Segundo Examen Corto 2.1-2.7 12/06 [1] Determinantes Introducci\u00f3n a los determinantes. 3.1 11/06 Propiedades de los determinantes. 3.2 11/06 Espacios vectoriales Espacios y subespacios vectoriales. 4.1 15/06 Espacios nulos, espacios columna y transformaciones lineales. 4.2 16/06 Tercer Examen Corto 3.1-3.2, 4.1-4-2 18/06 Conjuntos linealmente independientes. 4.3 17/06 Sistemas de coordenadas. 4.4 22/06 La dimensi\u00f3n de un espacio vectorial. 4.5 23/06 Rango. 4.6 24/06 Cadenas de Markov. 4.9 25/06 Cuarto Examen Corto 4.3-4-9 29/06 Valores propios y vectores propios Vectores propios y valores propios. 5.1 01/07 La ecuaci\u00f3n caracter\u00edstica. 5.2 02/07 Diagonalizaci\u00f3n. 5.3 06/07 Quinto Examen Corto 5.1-5.3 10/07 [1] Ortogonalidad y m\u00ednimos cuadrados Producto interior, longitud y ortogonalidad. 6.1 07/07 Conjuntos ortogonales. 6.2 08/07 Proyecciones ortogonales. 6.3 08/07 Proceso Gram-Schmidt. 6.4 09/07 Problemas de m\u00ednimos cuadrados. 6.5 09/07 Examen Final 15/07","title":"Programa de \u00c1lgebra Lineal"},{"location":"programa_2020/#ponderacion-del-curso","text":"Actividad Cantidad Punteo Ex\u00e1menes Cortos 5 60 Tareas - 10 Final 1 30 [1] Estos d\u00edas son viernes, por lo que ser\u00e1n fuera del d\u00eda normal de clases.","title":"Ponderaci\u00f3n del Curso"},{"location":"chapter_01/11_ecuaciones_lineales/","text":"1. Ecuaciones Lineales en \u00c1lgebra Lineal 1.1 Sistemas de Ecuaciones Lineales Ecuaci\u00f3n Lineal: Es una ecuaci\u00f3n que puede ser escrita en la forma a_1x_1+a_2x_2+...+a_nx_n=b Donde: $b$ pueden ser n\u00fameros reales o complejos $a_1, a_2, ..., a_n$ se denominan coeficientes y pueden ser reales o complejos Sistema de Ecuaciones Lineales o Sistema Lineal: Es una colecci\u00f3n de una o m\u00e1s ecuaciones lineales con las mismas variables $x_1, x_2, ..., x_n$ Soluci\u00f3n del Sistema: Es una lista de n\u00fameros $(s_1, s_2, ..., s_n)$ que al ser substituidos en $x_1, x_2, ..., x_n$ hacen una ecuaci\u00f3n verdadera. Conjunto Soluci\u00f3n: Son todas las posibles soluciones del sistema. Sistema Equivalente: Cuando dos sistemas poseen el mismo conjunto soluci\u00f3n. Tipos de Soluci\u00f3n: Dado un sistema de ecuaciones a_1x_1+a_2x_2=l_1 \\alpha_1x_1+\\alpha_2x_2=l_2 Ninguna Soluci\u00f3n Exactamente una Soluci\u00f3n Infinitas Soluciones Sistema Inconsistente Sistema Consistente Sistema Consistente Notaci\u00f3n Matricial: Una matriz es un arreglo rectangular de n\u00fameros. x_1-5x_2+4x_3=-3 2x_1-7x_2+3x_3=-2 -2x_1+x_2+7x_3=-1 Matriz de Coeficientes Matriz Aumentada \\left[ \\begin{matrix} 1 & -5 & 4 \\\\ 2 & -7 & 3 \\\\ -2 & 1 & 7 \\end{matrix} \\right] \\left[ \\begin{matrix} 1 & -5 & 4 & -3 \\\\ 2 & -7 & 3 & -2 \\\\ -2 & 1 & 7 & -1 \\end{matrix} \\right] Tama\u00f1o de una Matriz: Se dice que una matriz es de $m\\times n$ , donde $m$ es el n\u00famero de filas y $n$ el n\u00famero de columnas. Soluci\u00f3n de un Sistema Lineal La idea es implementar un sistema equivalente que tendr\u00eda la misma soluci\u00f3n al sistema original dado. Pasar de esto A esto \\begin{matrix} 2x_1 & & -6x_3 & =-8 \\\\ & x_2 & +2x_3 & =3 \\\\ 3x_1 & +6x_2 & -2x_3 & =-4 \\end{matrix} \\begin{matrix} x_1 & & & =2 \\\\ & x_2 & & =-1 \\\\ & & x_3 & =2 \\end{matrix} \\left [\\begin{matrix} 2 & 0 & -6 & -8 \\\\ 0 & 1 & 2 & 3 \\\\ 3 & 6 & -2 & -4 \\end{matrix} \\right ] \\left [\\begin{matrix} 1 & 0 & 0 & 2 \\\\ 0 & 1 & 0 & -1 \\\\ 0 & 0 & 1 & 2 \\end{matrix} \\right ] Ejemplo 1: Determine la soluci\u00f3n de \\begin{matrix} 2x_1 & & -6x_3 & =-8 \\\\ & x_2 & +2x_3 & =3 \\\\ 3x_1 & +6x_2 & -2x_3 & =-4 \\end{matrix} Ejemplo 2: Encuentre la soluci\u00f3n para el siguiente sistema de ecuaciones. \\begin{matrix} x_1 & -5x_2 & +4x_3 & =-3 \\\\ 2x_1 & -7x_2 & +3x_3 & =-2 \\\\ -2x_1 & +x_2 & +7x_3 & =-1\\end{matrix} Tipos de Operaciones Elementales Reemplazo $R_1 + kR_2 \\rightarrow R_1$ Intercambio $R_1 \\leftrightarrow R_2$ Escalamiento $kR_1 \\rightarrow R_1$ Se dice que dos matrices son equivalentes por fila si existe una secuencia de operaciones de fila que transforman a una matriz en otra. Las operaciones de fila son reversibles. Existen dos preguntas que se deben hacer respecto a un sistema lineal: \u00bfEs consistente el sistema? (\u00bfTiene por lo menos una soluci\u00f3n?) De existir soluci\u00f3n, \u00bfLa soluci\u00f3n es \u00fanica? TAREA SECCI\u00d3N 1.1 1, 3, 7, 9 13, 19, 21, 25, 31","title":"1.1 Sistemas de Ecuaciones Lineales"},{"location":"chapter_01/11_ecuaciones_lineales/#1-ecuaciones-lineales-en-algebra-lineal","text":"","title":"1. Ecuaciones Lineales en \u00c1lgebra Lineal"},{"location":"chapter_01/11_ecuaciones_lineales/#11-sistemas-de-ecuaciones-lineales","text":"Ecuaci\u00f3n Lineal: Es una ecuaci\u00f3n que puede ser escrita en la forma a_1x_1+a_2x_2+...+a_nx_n=b Donde: $b$ pueden ser n\u00fameros reales o complejos $a_1, a_2, ..., a_n$ se denominan coeficientes y pueden ser reales o complejos Sistema de Ecuaciones Lineales o Sistema Lineal: Es una colecci\u00f3n de una o m\u00e1s ecuaciones lineales con las mismas variables $x_1, x_2, ..., x_n$ Soluci\u00f3n del Sistema: Es una lista de n\u00fameros $(s_1, s_2, ..., s_n)$ que al ser substituidos en $x_1, x_2, ..., x_n$ hacen una ecuaci\u00f3n verdadera. Conjunto Soluci\u00f3n: Son todas las posibles soluciones del sistema. Sistema Equivalente: Cuando dos sistemas poseen el mismo conjunto soluci\u00f3n. Tipos de Soluci\u00f3n: Dado un sistema de ecuaciones a_1x_1+a_2x_2=l_1 \\alpha_1x_1+\\alpha_2x_2=l_2 Ninguna Soluci\u00f3n Exactamente una Soluci\u00f3n Infinitas Soluciones Sistema Inconsistente Sistema Consistente Sistema Consistente Notaci\u00f3n Matricial: Una matriz es un arreglo rectangular de n\u00fameros. x_1-5x_2+4x_3=-3 2x_1-7x_2+3x_3=-2 -2x_1+x_2+7x_3=-1 Matriz de Coeficientes Matriz Aumentada \\left[ \\begin{matrix} 1 & -5 & 4 \\\\ 2 & -7 & 3 \\\\ -2 & 1 & 7 \\end{matrix} \\right] \\left[ \\begin{matrix} 1 & -5 & 4 & -3 \\\\ 2 & -7 & 3 & -2 \\\\ -2 & 1 & 7 & -1 \\end{matrix} \\right] Tama\u00f1o de una Matriz: Se dice que una matriz es de $m\\times n$ , donde $m$ es el n\u00famero de filas y $n$ el n\u00famero de columnas.","title":"1.1 Sistemas de Ecuaciones Lineales"},{"location":"chapter_01/11_ecuaciones_lineales/#solucion-de-un-sistema-lineal","text":"La idea es implementar un sistema equivalente que tendr\u00eda la misma soluci\u00f3n al sistema original dado. Pasar de esto A esto \\begin{matrix} 2x_1 & & -6x_3 & =-8 \\\\ & x_2 & +2x_3 & =3 \\\\ 3x_1 & +6x_2 & -2x_3 & =-4 \\end{matrix} \\begin{matrix} x_1 & & & =2 \\\\ & x_2 & & =-1 \\\\ & & x_3 & =2 \\end{matrix} \\left [\\begin{matrix} 2 & 0 & -6 & -8 \\\\ 0 & 1 & 2 & 3 \\\\ 3 & 6 & -2 & -4 \\end{matrix} \\right ] \\left [\\begin{matrix} 1 & 0 & 0 & 2 \\\\ 0 & 1 & 0 & -1 \\\\ 0 & 0 & 1 & 2 \\end{matrix} \\right ] Ejemplo 1: Determine la soluci\u00f3n de \\begin{matrix} 2x_1 & & -6x_3 & =-8 \\\\ & x_2 & +2x_3 & =3 \\\\ 3x_1 & +6x_2 & -2x_3 & =-4 \\end{matrix} Ejemplo 2: Encuentre la soluci\u00f3n para el siguiente sistema de ecuaciones. \\begin{matrix} x_1 & -5x_2 & +4x_3 & =-3 \\\\ 2x_1 & -7x_2 & +3x_3 & =-2 \\\\ -2x_1 & +x_2 & +7x_3 & =-1\\end{matrix}","title":"Soluci\u00f3n de un Sistema Lineal"},{"location":"chapter_01/11_ecuaciones_lineales/#tipos-de-operaciones-elementales","text":"Reemplazo $R_1 + kR_2 \\rightarrow R_1$ Intercambio $R_1 \\leftrightarrow R_2$ Escalamiento $kR_1 \\rightarrow R_1$ Se dice que dos matrices son equivalentes por fila si existe una secuencia de operaciones de fila que transforman a una matriz en otra. Las operaciones de fila son reversibles. Existen dos preguntas que se deben hacer respecto a un sistema lineal: \u00bfEs consistente el sistema? (\u00bfTiene por lo menos una soluci\u00f3n?) De existir soluci\u00f3n, \u00bfLa soluci\u00f3n es \u00fanica? TAREA SECCI\u00d3N 1.1 1, 3, 7, 9 13, 19, 21, 25, 31","title":"Tipos de Operaciones Elementales"},{"location":"chapter_01/12_reduccion_filas/","text":"1. Ecuaciones Lineales en \u00c1lgebra Lineal 1.2 Reducci\u00f3n por Filas y Formas Escalonadas (aka Gauss-Jordan) Entrada Principal: Se refiere al elemento distinto de cero que se encuentra m\u00e1s a la izquierda en una fila. Las siguientes matrices est\u00e1n de la forma: Escalonada Escalonada Reducida \\left[ \\begin{matrix} \\underline{2} & -3 & 2 & 1 \\\\ 0 & \\underline{1} & -4 & 8 \\\\ 0 & 0 & 0 & \\underline{\\frac{5}{2} }\\end{matrix} \\right] \\left[ \\begin{matrix} \\underline{1} & 0 & 0 & 29 \\\\ 0 & \\underline{1} & 0 & 16 \\\\ 0 & 0 & \\underline{1} & 3 \\end{matrix} \\right] \\left[ \\begin{matrix} \\underline{3} & 4 & 1 & -3 \\\\ 0 & \\underline{1} & 2 & 5 \\\\ 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\end{matrix} \\right] \\left[ \\begin{matrix} \\underline{1} & 0 & 2 & 1 \\\\ 0 & \\underline{1} & 0 & 3 \\\\ 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\end{matrix} \\right] Una matriz en forma escalonada reducida tiene en cada entrada principal el valor de 1 . Posici\u00f3n Pivote: Son aquellas entradas principales que se utilizan para crear ceros por medio de operaciones de fila. (Observe que se refiere a posiciones.) Columna Pivote: Son aquellas columnas donde se encuentra una posici\u00f3n pivote. \u00bfCu\u00e1l es la utilidad de esto? Cada matriz es equivalente por filas a una, y solo una, matriz escalonada reducida. -Teorema I Ejemplo 1: \u00bfCu\u00e1les son las posiciones y columnas pivote de la siguiente matriz? \\left[ \\begin{matrix} 1 & 2 & 4 & 5 \\\\ 2 & 4 & 5 & 4 \\\\ 4 & 5 & 4 & 2 \\end{matrix} \\right] Algoritmo de Reducci\u00f3n por Filas Se divide en dos etapas: Fase progresiva $\\space \\rightarrow \\space \\downarrow$ Fase regresiva $\\space \\leftarrow \\space \\uparrow$ Ejemplo 2: Implemente el algoritmo de reducci\u00f3n por filas para llevar la matriz $M$ a su forma escalonada reducida. M = \\left[ \\begin{matrix} 9 & 9 & -7 & 6 \\\\ -7 & 0 & -1 & -10 \\\\ 9 & 6 & 8 & 45 \\end{matrix} \\right] Ejemplo 3: Observe la matriz escalonada reducida, encuentre la soluci\u00f3n de este sistema. \\left[\\begin{matrix} 1 & 0 & -5 & 1 \\\\ 0 & 1 & 1 & 4 \\\\ 0 & 0 & 0 & 0 \\end{matrix} \\right] Existencia y Unicidad de las Soluciones Observe la siguiente matriz \\left[\\begin{matrix} 1 & 0 & 0 & 0 & 4 \\\\ 0 & 1 & 0 & 0 & 1 \\\\ 0 & 0 & 1 & 0 & 7 \\\\ 0 & 0 & 0 & a & b \\end{matrix} \\right] si en la \u00faltima fila de una matriz escalonada aumentada se tiene $a$ $b$ Soluci\u00f3n Consistente Restricci\u00f3n $0$ $0$ infinitas Si $k$ $l$ \u00fanica Si $k$ y $l$ $\\in \\mathbb{R}$ y $k \\neq 0$ $0$ $l$ no posee No $l$ $\\in \\mathbb{R}$ y $l \\neq 0$ TAREA SECCI\u00d3N 1.2 1, 3, 4, 7, 9, 11, 13, 15, 16, 17, 19","title":"1.2 Reducci\u00f3n por Filas"},{"location":"chapter_01/12_reduccion_filas/#1-ecuaciones-lineales-en-algebra-lineal","text":"","title":"1. Ecuaciones Lineales en \u00c1lgebra Lineal"},{"location":"chapter_01/12_reduccion_filas/#12-reduccion-por-filas-y-formas-escalonadas-aka-gauss-jordan","text":"Entrada Principal: Se refiere al elemento distinto de cero que se encuentra m\u00e1s a la izquierda en una fila. Las siguientes matrices est\u00e1n de la forma: Escalonada Escalonada Reducida \\left[ \\begin{matrix} \\underline{2} & -3 & 2 & 1 \\\\ 0 & \\underline{1} & -4 & 8 \\\\ 0 & 0 & 0 & \\underline{\\frac{5}{2} }\\end{matrix} \\right] \\left[ \\begin{matrix} \\underline{1} & 0 & 0 & 29 \\\\ 0 & \\underline{1} & 0 & 16 \\\\ 0 & 0 & \\underline{1} & 3 \\end{matrix} \\right] \\left[ \\begin{matrix} \\underline{3} & 4 & 1 & -3 \\\\ 0 & \\underline{1} & 2 & 5 \\\\ 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\end{matrix} \\right] \\left[ \\begin{matrix} \\underline{1} & 0 & 2 & 1 \\\\ 0 & \\underline{1} & 0 & 3 \\\\ 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\end{matrix} \\right] Una matriz en forma escalonada reducida tiene en cada entrada principal el valor de 1 . Posici\u00f3n Pivote: Son aquellas entradas principales que se utilizan para crear ceros por medio de operaciones de fila. (Observe que se refiere a posiciones.) Columna Pivote: Son aquellas columnas donde se encuentra una posici\u00f3n pivote.","title":"1.2 Reducci\u00f3n por Filas y Formas Escalonadas (aka Gauss-Jordan)"},{"location":"chapter_01/12_reduccion_filas/#cual-es-la-utilidad-de-esto","text":"Cada matriz es equivalente por filas a una, y solo una, matriz escalonada reducida. -Teorema I Ejemplo 1: \u00bfCu\u00e1les son las posiciones y columnas pivote de la siguiente matriz? \\left[ \\begin{matrix} 1 & 2 & 4 & 5 \\\\ 2 & 4 & 5 & 4 \\\\ 4 & 5 & 4 & 2 \\end{matrix} \\right]","title":"\u00bfCu\u00e1l es la utilidad de esto?"},{"location":"chapter_01/12_reduccion_filas/#algoritmo-de-reduccion-por-filas","text":"Se divide en dos etapas: Fase progresiva $\\space \\rightarrow \\space \\downarrow$ Fase regresiva $\\space \\leftarrow \\space \\uparrow$ Ejemplo 2: Implemente el algoritmo de reducci\u00f3n por filas para llevar la matriz $M$ a su forma escalonada reducida. M = \\left[ \\begin{matrix} 9 & 9 & -7 & 6 \\\\ -7 & 0 & -1 & -10 \\\\ 9 & 6 & 8 & 45 \\end{matrix} \\right] Ejemplo 3: Observe la matriz escalonada reducida, encuentre la soluci\u00f3n de este sistema. \\left[\\begin{matrix} 1 & 0 & -5 & 1 \\\\ 0 & 1 & 1 & 4 \\\\ 0 & 0 & 0 & 0 \\end{matrix} \\right]","title":"Algoritmo de Reducci\u00f3n por Filas"},{"location":"chapter_01/12_reduccion_filas/#existencia-y-unicidad-de-las-soluciones","text":"Observe la siguiente matriz \\left[\\begin{matrix} 1 & 0 & 0 & 0 & 4 \\\\ 0 & 1 & 0 & 0 & 1 \\\\ 0 & 0 & 1 & 0 & 7 \\\\ 0 & 0 & 0 & a & b \\end{matrix} \\right] si en la \u00faltima fila de una matriz escalonada aumentada se tiene $a$ $b$ Soluci\u00f3n Consistente Restricci\u00f3n $0$ $0$ infinitas Si $k$ $l$ \u00fanica Si $k$ y $l$ $\\in \\mathbb{R}$ y $k \\neq 0$ $0$ $l$ no posee No $l$ $\\in \\mathbb{R}$ y $l \\neq 0$ TAREA SECCI\u00d3N 1.2 1, 3, 4, 7, 9, 11, 13, 15, 16, 17, 19","title":"Existencia y Unicidad de las Soluciones"},{"location":"chapter_01/13_ecuaciones_vectoriales/","text":"1. Ecuaciones Lineales en \u00c1lgebra Lineal 1.3 Ecuaciones Vectoriales Vector: Lista ordenada de n\u00fameros que permiten describir sistemas lineales. Comenzaremos a estudiar vectores en $\\mathbb{R}^2$ pero puede ser extendido a $\\mathbb{R}^n$ Vectores en $\\mathbb{R}^2$ son aquellos compuestos por los n\u00fameros reales y que poseen 2 entradas. Ejemplo de estos vectores tenemos: \\boldsymbol{u} = \\left[ \\begin{matrix} 3\\\\ -1\\end{matrix} \\right] \\;\\;\\;\\;\\;\\;\\; \\boldsymbol{v} = \\left[ \\begin{matrix} 0.1\\\\ 0.2\\end{matrix} \\right] \\;\\;\\;\\;\\;\\;\\; \\boldsymbol{w} = \\left[ \\begin{matrix} w_1\\\\ w_2\\end{matrix} \\right] \\space Algunas propiedades son: Suma: \\boldsymbol{u} + \\boldsymbol{v} = \\left[ \\begin{matrix} 3\\\\ -1\\end{matrix} \\right] + \\left[ \\begin{matrix} 0.1\\\\ 0.2\\end{matrix} \\right] = \\left[ \\begin{matrix} 3+0.1\\\\ -1+0.2\\end{matrix} \\right] = \\left[ \\begin{matrix} 3.1\\\\ -0.8\\end{matrix} \\right]\\space Multiplicaci\u00f3n por un Escalar: c=3 \\;\\;\\;\\;\\;\\;\\;\\; c\\boldsymbol{u}=3\\left[ \\begin{matrix} 3\\\\ -1\\end{matrix} \\right]=\\left[ \\begin{matrix} 9\\\\ -3\\end{matrix} \\right] Nota: Algunos textos el vector columna puede ser escrito como \\left[ \\begin{matrix} 3\\\\ -1\\end{matrix} \\right] \\rightarrow \\;\\;\\; \\left<3,-1\\right> Sin embargo, no confundir con \\left[ \\begin{matrix} 3\\\\ -1\\end{matrix} \\right] \\neq \\left[3,-1\\right] Representaci\u00f3n Geom\u00e9trica en $\\mathbb{R}^2$ Si se tienen los vectores \\boldsymbol{u} = \\left[ \\begin{matrix} 3\\\\ -1\\end{matrix} \\right] \\;\\;\\;\\;\\;\\;\\; \\boldsymbol{v} = \\left[ \\begin{matrix} 2\\\\ 2\\end{matrix} \\right] Determine la suma de ambos vectores Link en GeoGebra \u200b La regla del paralelogramo establece que $\\boldsymbol{u}+\\boldsymbol{v}$ es el cuarto v\u00e9rtice de un paralelogramo que se forma con los vectores $\\boldsymbol{0}$ , $\\boldsymbol{u}$ y $\\boldsymbol{v}$. El vector $\\boldsymbol{0}$ consiste en: \\boldsymbol{0} = \\left[ \\begin{matrix} 0\\\\ 0\\end{matrix} \\right] Representaci\u00f3n Geom\u00e9trica en $\\mathbb{R}^3$ Vectores en $\\mathbb{R}^3$ son matrices columna de $3 \\times 1$ con tres entradas \\boldsymbol{u} = \\left[ \\begin{matrix} 2\\\\ 3 \\\\4 \\end{matrix} \\right] Link en GeoGebra Vectores en $\\mathbb{R}^n$ Los vectores en $\\mathbb{R}^n$ son matrices columna $n \\times 1$ con $n$ entradas. Propiedades Algebraicas de $\\mathbb{R}^n$ Dados los vectores $\\boldsymbol{u}$, $\\boldsymbol{v}$, $\\boldsymbol{w}$ y los escalares $c$ y $d$ $\\;\\;\\;\\boldsymbol{u}+ \\boldsymbol{v} = \\boldsymbol{v}+\\boldsymbol{u}$ $\\;\\;\\;(\\boldsymbol{u}+ \\boldsymbol{v})+\\boldsymbol{w} = \\boldsymbol{u}+(\\boldsymbol{v}+\\boldsymbol{w})$ $\\;\\;\\;\\boldsymbol{u}+ \\boldsymbol{0} = \\boldsymbol{0}+\\boldsymbol{u} = \\boldsymbol{u}$ $\\;\\;\\;\\boldsymbol{u}+ (-1)\\boldsymbol{u} = \\boldsymbol{u}+\\boldsymbol{-u} = \\boldsymbol{0}$ $\\;\\;\\;c(\\boldsymbol{u}+ \\boldsymbol{v}) = c\\boldsymbol{u}+c\\boldsymbol{v}$ $\\;\\;\\;(c+d)\\boldsymbol{u} = c\\boldsymbol{u}+d\\boldsymbol{u}$ $\\;\\;\\;c(d\\boldsymbol{u}) = cd\\boldsymbol{u}$ $\\;\\;\\;(1)\\boldsymbol{u} = \\boldsymbol{u}$ Combinaciones Lineales Dados los vectores $\\boldsymbol{v_1}, \\boldsymbol{v_2}, ..., \\boldsymbol{v_p}$ en $\\mathbb{R}^n$ y los escalares $c_1, c_2, ..., c_p$ \\boldsymbol{y}=c_1\\boldsymbol{v_1}+c_2\\boldsymbol{v_2}+...+c_p\\boldsymbol{v_p} se denomina combinaci\u00f3n lineal de $\\boldsymbol{v_1}, \\boldsymbol{v_2}, ..., \\boldsymbol{v_p}$ con pesos $c_1, c_2, ..., c_p$. Ejemplo 1: Dado $\\boldsymbol{y}=c_1\\boldsymbol{v_1}+c_2\\boldsymbol{v_2}$ en $\\mathbb{R}^3$ \\boldsymbol{y} = \\left[ \\begin{matrix} 7 \\\\ 4 \\\\ -3 \\end{matrix} \\right] \\;\\;\\;\\;\\;\\;\\; \\boldsymbol{v_1} = \\left[ \\begin{matrix} 1 \\\\ -2 \\\\ -5 \\end{matrix} \\right] \\;\\;\\;\\;\\;\\;\\; \\boldsymbol{v_2} = \\left[ \\begin{matrix} 2 \\\\ 5 \\\\ 6 \\end{matrix} \\right] \\;\\;\\;\\;\\;\\;\\; \u00bfCu\u00e1les son los valores de los pesos $c_1$ y $c_2$ para que se cumpla dicho sistema lineal? Por lo tanto, se puede generalizar que la ecuaci\u00f3n vectorial x_1\\boldsymbol{a_1}+x_2\\boldsymbol{a_2}+...+x_n\\boldsymbol{a_n}=\\boldsymbol{b} tiene el mismo conjunto soluci\u00f3n que el sistema lineal cuya matriz aumentada es \\left[\\boldsymbol{a_1}\\;\\;\\;\\boldsymbol{a_2}\\;...\\;\\boldsymbol{a_n}\\;\\;\\;\\boldsymbol{b}\\right] $\\boldsymbol{b}$ solo se puede generar si y solo si existe una soluci\u00f3n al sistema lineal. Pensemos nuevamente en la ecuaci\u00f3n vectorial \\boldsymbol{y}=c_1\\boldsymbol{v_1}+c_2\\boldsymbol{v_2}+...+c_p\\boldsymbol{v_p} Existe una infinidad de valores $c_1, c_2,...,c_p$ que dar\u00e1n origen al subconjunto generado por $\\boldsymbol{v_1}, \\boldsymbol{v_2}, ..., \\boldsymbol{v_p}$. A estas combinaciones se le llama subconjunto de $\\mathbb{R}^n$ extendido o generado por $\\boldsymbol{v_1}, \\boldsymbol{v_2}, ..., \\boldsymbol{v_p}$. Su notaci\u00f3n es Gen\\left\\{ \\boldsymbol{v_1}, \\boldsymbol{v_2}, ..., \\boldsymbol{v_p}\\right\\} Por ejemplo, preguntar si $\\boldsymbol{b}$ est\u00e1 en Gen\\left\\{ \\boldsymbol{v_1}, \\boldsymbol{v_2}, ..., \\boldsymbol{v_p}\\right\\} equivale a preguntar si x_1\\boldsymbol{v_1}+x_2\\boldsymbol{v_2}+...+x_p\\boldsymbol{v_p}=\\boldsymbol{b} tiene soluci\u00f3n. Nota: Tenemos 3 maneras de preguntar lo mismo. Encuentre la soluci\u00f3n del sistema Encuentre el peso o valor de los coeficientes. El vector $\\boldsymbol{b}$ pertenece a Gen\\left\\{ \\boldsymbol{v_1}, \\boldsymbol{v_2}, ..., \\boldsymbol{v_p}\\right\\} Representaci\u00f3n Geom\u00e9trica de Gen Supongamos a $\\boldsymbol{u}$ en $\\mathbb{R}^3$ . Gen\\left\\{ \\boldsymbol{u}\\right\\} consiste en todos los m\u00faltiplos escalares de $\\boldsymbol{u}$. Supongamos a $\\boldsymbol{u}$ y $\\boldsymbol{v}$ en $\\mathbb{R}^3$ , con $\\boldsymbol{u}$ , $\\boldsymbol{v}\\neq \\boldsymbol{0}$ $\\wedge$ $\\boldsymbol{u}\\neq k\\boldsymbol{v}$ Gen\\left\\{ \\boldsymbol{u},\\boldsymbol{v}\\right\\} consiste en todos los m\u00faltiplos escalares de $\\boldsymbol{u}$ y $\\boldsymbol{v}$. Link en GeoGebra Ejemplo 2: Dada la matriz $A=\\left[\\boldsymbol{a_1} \\;\\; \\boldsymbol{a_2} \\;\\;\\boldsymbol{a_3} \\right]$ determine si $\\boldsymbol{b}$ en Gen \\{ \\boldsymbol{a_1}, \\boldsymbol{a_2}, \\boldsymbol{a_3}\\} A = \\left[ \\begin{matrix} 1 & 0 & -4 \\\\ 0 & 3 & -2 \\\\ -2 & 6 & 3 \\end{matrix} \\right] \\;\\;\\; \\boldsymbol{b} = \\left[ \\begin{matrix} 4 \\\\ 1 \\\\ -4 \\end{matrix} \\right] Ejemplo 3: Para la misma matriz $A$ , est\u00e1 $\\boldsymbol{b}$ en \\left\\{ \\boldsymbol{a_1}, \\boldsymbol{a_2}, \\boldsymbol{a_3}\\right\\} TAREA SECCI\u00d3N 1.3 1, 2, 5, 6, 9, 11, 12, 13, 21, 26, 29","title":"1.3 Ecuaciones Vectoriales"},{"location":"chapter_01/13_ecuaciones_vectoriales/#1-ecuaciones-lineales-en-algebra-lineal","text":"","title":"1. Ecuaciones Lineales en \u00c1lgebra Lineal"},{"location":"chapter_01/13_ecuaciones_vectoriales/#13-ecuaciones-vectoriales","text":"Vector: Lista ordenada de n\u00fameros que permiten describir sistemas lineales. Comenzaremos a estudiar vectores en $\\mathbb{R}^2$ pero puede ser extendido a $\\mathbb{R}^n$ Vectores en $\\mathbb{R}^2$ son aquellos compuestos por los n\u00fameros reales y que poseen 2 entradas. Ejemplo de estos vectores tenemos: \\boldsymbol{u} = \\left[ \\begin{matrix} 3\\\\ -1\\end{matrix} \\right] \\;\\;\\;\\;\\;\\;\\; \\boldsymbol{v} = \\left[ \\begin{matrix} 0.1\\\\ 0.2\\end{matrix} \\right] \\;\\;\\;\\;\\;\\;\\; \\boldsymbol{w} = \\left[ \\begin{matrix} w_1\\\\ w_2\\end{matrix} \\right] \\space Algunas propiedades son: Suma: \\boldsymbol{u} + \\boldsymbol{v} = \\left[ \\begin{matrix} 3\\\\ -1\\end{matrix} \\right] + \\left[ \\begin{matrix} 0.1\\\\ 0.2\\end{matrix} \\right] = \\left[ \\begin{matrix} 3+0.1\\\\ -1+0.2\\end{matrix} \\right] = \\left[ \\begin{matrix} 3.1\\\\ -0.8\\end{matrix} \\right]\\space Multiplicaci\u00f3n por un Escalar: c=3 \\;\\;\\;\\;\\;\\;\\;\\; c\\boldsymbol{u}=3\\left[ \\begin{matrix} 3\\\\ -1\\end{matrix} \\right]=\\left[ \\begin{matrix} 9\\\\ -3\\end{matrix} \\right] Nota: Algunos textos el vector columna puede ser escrito como \\left[ \\begin{matrix} 3\\\\ -1\\end{matrix} \\right] \\rightarrow \\;\\;\\; \\left<3,-1\\right> Sin embargo, no confundir con \\left[ \\begin{matrix} 3\\\\ -1\\end{matrix} \\right] \\neq \\left[3,-1\\right]","title":"1.3 Ecuaciones Vectoriales"},{"location":"chapter_01/13_ecuaciones_vectoriales/#representacion-geometrica-en-mathbbr2","text":"Si se tienen los vectores \\boldsymbol{u} = \\left[ \\begin{matrix} 3\\\\ -1\\end{matrix} \\right] \\;\\;\\;\\;\\;\\;\\; \\boldsymbol{v} = \\left[ \\begin{matrix} 2\\\\ 2\\end{matrix} \\right] Determine la suma de ambos vectores Link en GeoGebra \u200b La regla del paralelogramo establece que $\\boldsymbol{u}+\\boldsymbol{v}$ es el cuarto v\u00e9rtice de un paralelogramo que se forma con los vectores $\\boldsymbol{0}$ , $\\boldsymbol{u}$ y $\\boldsymbol{v}$. El vector $\\boldsymbol{0}$ consiste en: \\boldsymbol{0} = \\left[ \\begin{matrix} 0\\\\ 0\\end{matrix} \\right]","title":"Representaci\u00f3n Geom\u00e9trica en $\\mathbb{R}^2$"},{"location":"chapter_01/13_ecuaciones_vectoriales/#representacion-geometrica-en-mathbbr3","text":"Vectores en $\\mathbb{R}^3$ son matrices columna de $3 \\times 1$ con tres entradas \\boldsymbol{u} = \\left[ \\begin{matrix} 2\\\\ 3 \\\\4 \\end{matrix} \\right] Link en GeoGebra","title":"Representaci\u00f3n Geom\u00e9trica en $\\mathbb{R}^3$"},{"location":"chapter_01/13_ecuaciones_vectoriales/#vectores-en-mathbbrn","text":"Los vectores en $\\mathbb{R}^n$ son matrices columna $n \\times 1$ con $n$ entradas.","title":"Vectores en $\\mathbb{R}^n$"},{"location":"chapter_01/13_ecuaciones_vectoriales/#propiedades-algebraicas-de-mathbbrn","text":"Dados los vectores $\\boldsymbol{u}$, $\\boldsymbol{v}$, $\\boldsymbol{w}$ y los escalares $c$ y $d$ $\\;\\;\\;\\boldsymbol{u}+ \\boldsymbol{v} = \\boldsymbol{v}+\\boldsymbol{u}$ $\\;\\;\\;(\\boldsymbol{u}+ \\boldsymbol{v})+\\boldsymbol{w} = \\boldsymbol{u}+(\\boldsymbol{v}+\\boldsymbol{w})$ $\\;\\;\\;\\boldsymbol{u}+ \\boldsymbol{0} = \\boldsymbol{0}+\\boldsymbol{u} = \\boldsymbol{u}$ $\\;\\;\\;\\boldsymbol{u}+ (-1)\\boldsymbol{u} = \\boldsymbol{u}+\\boldsymbol{-u} = \\boldsymbol{0}$ $\\;\\;\\;c(\\boldsymbol{u}+ \\boldsymbol{v}) = c\\boldsymbol{u}+c\\boldsymbol{v}$ $\\;\\;\\;(c+d)\\boldsymbol{u} = c\\boldsymbol{u}+d\\boldsymbol{u}$ $\\;\\;\\;c(d\\boldsymbol{u}) = cd\\boldsymbol{u}$ $\\;\\;\\;(1)\\boldsymbol{u} = \\boldsymbol{u}$","title":"Propiedades Algebraicas de $\\mathbb{R}^n$"},{"location":"chapter_01/13_ecuaciones_vectoriales/#combinaciones-lineales","text":"Dados los vectores $\\boldsymbol{v_1}, \\boldsymbol{v_2}, ..., \\boldsymbol{v_p}$ en $\\mathbb{R}^n$ y los escalares $c_1, c_2, ..., c_p$ \\boldsymbol{y}=c_1\\boldsymbol{v_1}+c_2\\boldsymbol{v_2}+...+c_p\\boldsymbol{v_p} se denomina combinaci\u00f3n lineal de $\\boldsymbol{v_1}, \\boldsymbol{v_2}, ..., \\boldsymbol{v_p}$ con pesos $c_1, c_2, ..., c_p$. Ejemplo 1: Dado $\\boldsymbol{y}=c_1\\boldsymbol{v_1}+c_2\\boldsymbol{v_2}$ en $\\mathbb{R}^3$ \\boldsymbol{y} = \\left[ \\begin{matrix} 7 \\\\ 4 \\\\ -3 \\end{matrix} \\right] \\;\\;\\;\\;\\;\\;\\; \\boldsymbol{v_1} = \\left[ \\begin{matrix} 1 \\\\ -2 \\\\ -5 \\end{matrix} \\right] \\;\\;\\;\\;\\;\\;\\; \\boldsymbol{v_2} = \\left[ \\begin{matrix} 2 \\\\ 5 \\\\ 6 \\end{matrix} \\right] \\;\\;\\;\\;\\;\\;\\; \u00bfCu\u00e1les son los valores de los pesos $c_1$ y $c_2$ para que se cumpla dicho sistema lineal? Por lo tanto, se puede generalizar que la ecuaci\u00f3n vectorial x_1\\boldsymbol{a_1}+x_2\\boldsymbol{a_2}+...+x_n\\boldsymbol{a_n}=\\boldsymbol{b} tiene el mismo conjunto soluci\u00f3n que el sistema lineal cuya matriz aumentada es \\left[\\boldsymbol{a_1}\\;\\;\\;\\boldsymbol{a_2}\\;...\\;\\boldsymbol{a_n}\\;\\;\\;\\boldsymbol{b}\\right] $\\boldsymbol{b}$ solo se puede generar si y solo si existe una soluci\u00f3n al sistema lineal. Pensemos nuevamente en la ecuaci\u00f3n vectorial \\boldsymbol{y}=c_1\\boldsymbol{v_1}+c_2\\boldsymbol{v_2}+...+c_p\\boldsymbol{v_p} Existe una infinidad de valores $c_1, c_2,...,c_p$ que dar\u00e1n origen al subconjunto generado por $\\boldsymbol{v_1}, \\boldsymbol{v_2}, ..., \\boldsymbol{v_p}$. A estas combinaciones se le llama subconjunto de $\\mathbb{R}^n$ extendido o generado por $\\boldsymbol{v_1}, \\boldsymbol{v_2}, ..., \\boldsymbol{v_p}$. Su notaci\u00f3n es Gen\\left\\{ \\boldsymbol{v_1}, \\boldsymbol{v_2}, ..., \\boldsymbol{v_p}\\right\\} Por ejemplo, preguntar si $\\boldsymbol{b}$ est\u00e1 en Gen\\left\\{ \\boldsymbol{v_1}, \\boldsymbol{v_2}, ..., \\boldsymbol{v_p}\\right\\} equivale a preguntar si x_1\\boldsymbol{v_1}+x_2\\boldsymbol{v_2}+...+x_p\\boldsymbol{v_p}=\\boldsymbol{b} tiene soluci\u00f3n. Nota: Tenemos 3 maneras de preguntar lo mismo. Encuentre la soluci\u00f3n del sistema Encuentre el peso o valor de los coeficientes. El vector $\\boldsymbol{b}$ pertenece a Gen\\left\\{ \\boldsymbol{v_1}, \\boldsymbol{v_2}, ..., \\boldsymbol{v_p}\\right\\}","title":"Combinaciones Lineales"},{"location":"chapter_01/13_ecuaciones_vectoriales/#representacion-geometrica-de-gen","text":"Supongamos a $\\boldsymbol{u}$ en $\\mathbb{R}^3$ . Gen\\left\\{ \\boldsymbol{u}\\right\\} consiste en todos los m\u00faltiplos escalares de $\\boldsymbol{u}$. Supongamos a $\\boldsymbol{u}$ y $\\boldsymbol{v}$ en $\\mathbb{R}^3$ , con $\\boldsymbol{u}$ , $\\boldsymbol{v}\\neq \\boldsymbol{0}$ $\\wedge$ $\\boldsymbol{u}\\neq k\\boldsymbol{v}$ Gen\\left\\{ \\boldsymbol{u},\\boldsymbol{v}\\right\\} consiste en todos los m\u00faltiplos escalares de $\\boldsymbol{u}$ y $\\boldsymbol{v}$. Link en GeoGebra Ejemplo 2: Dada la matriz $A=\\left[\\boldsymbol{a_1} \\;\\; \\boldsymbol{a_2} \\;\\;\\boldsymbol{a_3} \\right]$ determine si $\\boldsymbol{b}$ en Gen \\{ \\boldsymbol{a_1}, \\boldsymbol{a_2}, \\boldsymbol{a_3}\\} A = \\left[ \\begin{matrix} 1 & 0 & -4 \\\\ 0 & 3 & -2 \\\\ -2 & 6 & 3 \\end{matrix} \\right] \\;\\;\\; \\boldsymbol{b} = \\left[ \\begin{matrix} 4 \\\\ 1 \\\\ -4 \\end{matrix} \\right] Ejemplo 3: Para la misma matriz $A$ , est\u00e1 $\\boldsymbol{b}$ en \\left\\{ \\boldsymbol{a_1}, \\boldsymbol{a_2}, \\boldsymbol{a_3}\\right\\} TAREA SECCI\u00d3N 1.3 1, 2, 5, 6, 9, 11, 12, 13, 21, 26, 29","title":"Representaci\u00f3n Geom\u00e9trica de Gen"},{"location":"chapter_01/14_ecuacion_matricial/","text":"1. Ecuaciones Lineales en \u00c1lgebra Lineal 1.4 Ecuaci\u00f3n Matricial $A\\boldsymbol{x}=\\boldsymbol{b}$ Una manera m\u00e1s formal de expresar la ecuaci\u00f3n vectorial es por medio de la matriz $A$ $\\left(m \\times n \\right)$ y el vector $\\boldsymbol{x}$ de $\\left(n \\times 1 \\right)$. A \\boldsymbol{x}=\\left[\\boldsymbol{a_1} \\;\\;\\; \\boldsymbol{a_2} \\;\\dots\\; \\boldsymbol{a_n} \\right]\\left[ \\begin{matrix} x_1\\\\ x_2\\\\\\vdots \\\\x_n \\end{matrix} \\right]=x_1\\boldsymbol{a_1}+x_2\\boldsymbol{a_2}+\\dots+x_n\\boldsymbol{a_n} Ejemplo 1: Dada la matriz $A$ y el vector $\\boldsymbol{x}$ encuentre el producto $A\\boldsymbol{x}$. A = \\left[ \\begin{matrix} 1 & 3 & 5 \\\\ 2 & -4 & -1 \\end{matrix} \\right] \\;\\;\\;\\;\\; \\boldsymbol{x} = \\left[ \\begin{matrix} 1\\\\ 2 \\\\3 \\end{matrix} \\right] Ejemplo 2: Si \\boldsymbol{v_1} = \\left[ \\begin{matrix} 1\\\\ 0 \\\\3 \\end{matrix} \\right], \\boldsymbol{v_2} = \\left[ \\begin{matrix} 4\\\\ -7 \\\\1 \\end{matrix} \\right], \\boldsymbol{v_3} = \\left[ \\begin{matrix} 0\\\\ 3 \\\\-4 \\end{matrix} \\right] escriba la ecuaci\u00f3n $8\\boldsymbol{v_1}-4\\boldsymbol{v_2}+3\\boldsymbol{v_3}$ como el producto de una matriz por un vector. En resumen: La ecuaci\u00f3n matricial $A\\boldsymbol{x}=\\boldsymbol{b}$ La ecuaci\u00f3n vectorial $x_1\\boldsymbol{a_1}+x_2\\boldsymbol{a_2}+...+x_n\\boldsymbol{a_n}=\\boldsymbol{b}$ La matriz aumentada $\\left[\\boldsymbol{a_1} \\;\\;\\; \\boldsymbol{a_2} \\;\\dots\\; \\boldsymbol{a_n}\\;\\;\\; \\boldsymbol{b} \\right]$ Tienen la misma soluci\u00f3n. Con esto se puede decir que $A\\boldsymbol{x}=\\boldsymbol{b}$ tiene soluci\u00f3n si y solo si $\\boldsymbol{b}$ es una combinaci\u00f3n lineal de las columnas de $A$. Ejemplo 3: \u00bfPara que valores de $h$ el sistema es consistente? A = \\left[ \\begin{matrix} 1 & 5 & -3 \\\\ -1 & -4 & 1 \\\\ -2 & -7 & 0 \\end{matrix} \\right] \\;\\;\\;\\;\\; \\boldsymbol{b} = \\left[ \\begin{matrix} -4\\\\ 3 \\\\h \\end{matrix} \\right] Producto Fila-Vector para calcular $A\\boldsymbol{x}$ Sean $A$ una matriz de $(3 \\times 3)$ y $\\boldsymbol{x}$ un vector de $(3 \\times 1)$. El producto $A\\boldsymbol{x}$ puede ser calculado como: A\\boldsymbol{x} = \\left[ \\begin{matrix} a_{11} & a_{12} & a_{13} \\\\ a_{21} & a_{22} & a_{23} \\\\ a_{31} & a_{32} & a_{33} \\end{matrix} \\right]\\left[ \\begin{matrix} x_1\\\\ x_2 \\\\x_3 \\end{matrix} \\right] = \\left[ \\begin{matrix} a_{11}x_1 + a_{12}x_2 + a_{13}x_3 \\\\ a_{21}x_1 + a_{22}x_2 + a_{23}x_3 \\\\ a_{31}x_1 + a_{32}x_2 + a_{33}x_3 \\end{matrix} \\right] Matriz Identidad: Consiste en una matriz cuadrada de $(n \\times n)$ con su diagonal principal de unos y el resto con elementos cero. I= \\left[ \\begin{matrix} 1 & 0 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 & 0 \\\\ 0 & 0 & \\ddots & 0 & 0 \\\\ 0 & 0 & 0 & 1 & \\vdots \\\\ 0 & 0 & 0 & \\dots & 1 \\end{matrix} \\right] Un producto interesante es el de multiplicar por la Matriz Identidad, por ejemplo para la Matriz Identidad $I$ de $(3 \\times 3)$ se tiene: I = \\left[ \\begin{matrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{matrix} \\right]\\left[ \\begin{matrix} x_1\\\\ x_2 \\\\x_3 \\end{matrix} \\right]=\\left[ \\begin{matrix} 1\\cdot x_1 + 0 \\cdot x_2 + 0 \\cdot x_3 \\\\ 0\\cdot x_1 + 1 \\cdot x_2 + 0 \\cdot x_3 \\\\ 0\\cdot x_1 + 0 \\cdot x_2 + 1 \\cdot x_3 \\end{matrix} \\right]=\\left[ \\begin{matrix} x_1\\\\ x_2 \\\\x_3 \\end{matrix} \\right] Propiedades del Producto Matriz-Vector $A\\boldsymbol{x}$ $A(\\boldsymbol{u}+\\boldsymbol{v})=A\\boldsymbol{u}+A\\boldsymbol{v}$ $A(c\\boldsymbol{u})=c(A\\boldsymbol{u})$ TAREA SECCI\u00d3N 1.4 1, 3, 5, 7, 9, 11, 13, 15, 17, 21, 25, 31","title":"1.4 Ecuaci\u00f3n Matricial"},{"location":"chapter_01/14_ecuacion_matricial/#1-ecuaciones-lineales-en-algebra-lineal","text":"","title":"1. Ecuaciones Lineales en \u00c1lgebra Lineal"},{"location":"chapter_01/14_ecuacion_matricial/#14-ecuacion-matricial-aboldsymbolxboldsymbolb","text":"Una manera m\u00e1s formal de expresar la ecuaci\u00f3n vectorial es por medio de la matriz $A$ $\\left(m \\times n \\right)$ y el vector $\\boldsymbol{x}$ de $\\left(n \\times 1 \\right)$. A \\boldsymbol{x}=\\left[\\boldsymbol{a_1} \\;\\;\\; \\boldsymbol{a_2} \\;\\dots\\; \\boldsymbol{a_n} \\right]\\left[ \\begin{matrix} x_1\\\\ x_2\\\\\\vdots \\\\x_n \\end{matrix} \\right]=x_1\\boldsymbol{a_1}+x_2\\boldsymbol{a_2}+\\dots+x_n\\boldsymbol{a_n} Ejemplo 1: Dada la matriz $A$ y el vector $\\boldsymbol{x}$ encuentre el producto $A\\boldsymbol{x}$. A = \\left[ \\begin{matrix} 1 & 3 & 5 \\\\ 2 & -4 & -1 \\end{matrix} \\right] \\;\\;\\;\\;\\; \\boldsymbol{x} = \\left[ \\begin{matrix} 1\\\\ 2 \\\\3 \\end{matrix} \\right] Ejemplo 2: Si \\boldsymbol{v_1} = \\left[ \\begin{matrix} 1\\\\ 0 \\\\3 \\end{matrix} \\right], \\boldsymbol{v_2} = \\left[ \\begin{matrix} 4\\\\ -7 \\\\1 \\end{matrix} \\right], \\boldsymbol{v_3} = \\left[ \\begin{matrix} 0\\\\ 3 \\\\-4 \\end{matrix} \\right] escriba la ecuaci\u00f3n $8\\boldsymbol{v_1}-4\\boldsymbol{v_2}+3\\boldsymbol{v_3}$ como el producto de una matriz por un vector. En resumen: La ecuaci\u00f3n matricial $A\\boldsymbol{x}=\\boldsymbol{b}$ La ecuaci\u00f3n vectorial $x_1\\boldsymbol{a_1}+x_2\\boldsymbol{a_2}+...+x_n\\boldsymbol{a_n}=\\boldsymbol{b}$ La matriz aumentada $\\left[\\boldsymbol{a_1} \\;\\;\\; \\boldsymbol{a_2} \\;\\dots\\; \\boldsymbol{a_n}\\;\\;\\; \\boldsymbol{b} \\right]$ Tienen la misma soluci\u00f3n. Con esto se puede decir que $A\\boldsymbol{x}=\\boldsymbol{b}$ tiene soluci\u00f3n si y solo si $\\boldsymbol{b}$ es una combinaci\u00f3n lineal de las columnas de $A$. Ejemplo 3: \u00bfPara que valores de $h$ el sistema es consistente? A = \\left[ \\begin{matrix} 1 & 5 & -3 \\\\ -1 & -4 & 1 \\\\ -2 & -7 & 0 \\end{matrix} \\right] \\;\\;\\;\\;\\; \\boldsymbol{b} = \\left[ \\begin{matrix} -4\\\\ 3 \\\\h \\end{matrix} \\right]","title":"1.4 Ecuaci\u00f3n Matricial $A\\boldsymbol{x}=\\boldsymbol{b}$"},{"location":"chapter_01/14_ecuacion_matricial/#producto-fila-vector-para-calcular-aboldsymbolx","text":"Sean $A$ una matriz de $(3 \\times 3)$ y $\\boldsymbol{x}$ un vector de $(3 \\times 1)$. El producto $A\\boldsymbol{x}$ puede ser calculado como: A\\boldsymbol{x} = \\left[ \\begin{matrix} a_{11} & a_{12} & a_{13} \\\\ a_{21} & a_{22} & a_{23} \\\\ a_{31} & a_{32} & a_{33} \\end{matrix} \\right]\\left[ \\begin{matrix} x_1\\\\ x_2 \\\\x_3 \\end{matrix} \\right] = \\left[ \\begin{matrix} a_{11}x_1 + a_{12}x_2 + a_{13}x_3 \\\\ a_{21}x_1 + a_{22}x_2 + a_{23}x_3 \\\\ a_{31}x_1 + a_{32}x_2 + a_{33}x_3 \\end{matrix} \\right] Matriz Identidad: Consiste en una matriz cuadrada de $(n \\times n)$ con su diagonal principal de unos y el resto con elementos cero. I= \\left[ \\begin{matrix} 1 & 0 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 & 0 \\\\ 0 & 0 & \\ddots & 0 & 0 \\\\ 0 & 0 & 0 & 1 & \\vdots \\\\ 0 & 0 & 0 & \\dots & 1 \\end{matrix} \\right] Un producto interesante es el de multiplicar por la Matriz Identidad, por ejemplo para la Matriz Identidad $I$ de $(3 \\times 3)$ se tiene: I = \\left[ \\begin{matrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{matrix} \\right]\\left[ \\begin{matrix} x_1\\\\ x_2 \\\\x_3 \\end{matrix} \\right]=\\left[ \\begin{matrix} 1\\cdot x_1 + 0 \\cdot x_2 + 0 \\cdot x_3 \\\\ 0\\cdot x_1 + 1 \\cdot x_2 + 0 \\cdot x_3 \\\\ 0\\cdot x_1 + 0 \\cdot x_2 + 1 \\cdot x_3 \\end{matrix} \\right]=\\left[ \\begin{matrix} x_1\\\\ x_2 \\\\x_3 \\end{matrix} \\right]","title":"Producto Fila-Vector para calcular $A\\boldsymbol{x}$"},{"location":"chapter_01/14_ecuacion_matricial/#propiedades-del-producto-matriz-vector-aboldsymbolx","text":"$A(\\boldsymbol{u}+\\boldsymbol{v})=A\\boldsymbol{u}+A\\boldsymbol{v}$ $A(c\\boldsymbol{u})=c(A\\boldsymbol{u})$ TAREA SECCI\u00d3N 1.4 1, 3, 5, 7, 9, 11, 13, 15, 17, 21, 25, 31","title":"Propiedades del Producto Matriz-Vector $A\\boldsymbol{x}$"},{"location":"chapter_01/15_conjuntos_sistemas_lineales/","text":"1. Ecuaciones Lineales en \u00c1lgebra Lineal 1.5 Conjuntos Soluci\u00f3n de Sistemas Lineales Un sistema lineal homog\u00e9neo es aquel que cumple con la ecuaci\u00f3n A\\boldsymbol{x}=\\boldsymbol{0} Posee dos tipos de soluciones: Soluci\u00f3n trivial $\\rightarrow$ El vector $\\boldsymbol{x}= \\boldsymbol{0}$ Soluci\u00f3n no trivial $\\rightarrow$ Si y solo si la ecuaci\u00f3n tiene una variable libre Ejemplo: 1 Determine si el siguiente sistema homog\u00e9neo tiene soluci\u00f3n no trivial x_1+2x_2-3x_3=0 2x_1+x_2-3x_3=0 -x1+x_2=0 Ejemplo 2: Dado el siguiente sistema homog\u00e9neo determine x_1-2x_3-7x_4=0 x_2+2x_3-4x_4=0 Las variables b\u00e1sicas y las variables libres. La forma general de la ecuaci\u00f3n vectorial Sistemas Lineales No Homog\u00e9neos Un sistema lineal no homog\u00e9neo es aquel cuyo vector $\\boldsymbol{b} \\neq 0$. Cuando un sistema lineal no homog\u00e9neo tiene muchas soluciones se puede obtener la soluci\u00f3n como la combinaci\u00f3n de: La soluci\u00f3n del sistema homog\u00e9neo La soluci\u00f3n particular Ejemplo 3: Dado el sistema lineal del Ejemplo 1 encuentre la soluci\u00f3n para el sistema lineal no homog\u00e9neo con \\boldsymbol{b} = \\left[ \\begin{matrix} 1\\\\ 1 \\\\0 \\end{matrix} \\right] La soluci\u00f3n de la ecuaci\u00f3n lineal homog\u00e9nea tiene la forma \\boldsymbol{x} = v_{l1}\\boldsymbol{u_1}+v_{l2}\\boldsymbol{u_2}+\\dots+v_{ln}\\boldsymbol{u_n} Donde $v_{l1}, v_{l2},\\dots,v_{ln}$ son las variables libres del sistema y $\\boldsymbol{u_1}, \\boldsymbol{u_2},\\dots,\\boldsymbol{u_n}$ los vectores asociados a las mismas. La soluci\u00f3n de la ecuaci\u00f3n lineal no homog\u00e9nea tiene la forma \\boldsymbol{x} = \\boxed{v_{l1}\\boldsymbol{u_1}+v_{l2}\\boldsymbol{u_2}+\\dots+v_{ln}\\boldsymbol{u_n}}+ \\boldsymbol{p} Donde $\\boldsymbol{p}$ es la soluci\u00f3n particular del sistema. Interpretaci\u00f3n Geom\u00e9trica Supongamos que el sistema lineal en $\\mathbb{R}^2$ tiene: Soluci\u00f3n $\\boldsymbol{x}=t\\boldsymbol{v}$ para $A\\boldsymbol{x}=\\boldsymbol{0}$ Soluci\u00f3n $\\boldsymbol{x}=t\\boldsymbol{v}+\\boldsymbol{p}$ para $A\\boldsymbol{x}=\\boldsymbol{b}$ Link en GeoGebra Link en GeoGebra TAREA SECCI\u00d3N 1.5 1, 3, 5, 6, 7, 8, 11, 13, 14, 17","title":"1.5 Conjuntos de Sistemas Lineales"},{"location":"chapter_01/15_conjuntos_sistemas_lineales/#1-ecuaciones-lineales-en-algebra-lineal","text":"","title":"1. Ecuaciones Lineales en \u00c1lgebra Lineal"},{"location":"chapter_01/15_conjuntos_sistemas_lineales/#15-conjuntos-solucion-de-sistemas-lineales","text":"Un sistema lineal homog\u00e9neo es aquel que cumple con la ecuaci\u00f3n A\\boldsymbol{x}=\\boldsymbol{0} Posee dos tipos de soluciones: Soluci\u00f3n trivial $\\rightarrow$ El vector $\\boldsymbol{x}= \\boldsymbol{0}$ Soluci\u00f3n no trivial $\\rightarrow$ Si y solo si la ecuaci\u00f3n tiene una variable libre Ejemplo: 1 Determine si el siguiente sistema homog\u00e9neo tiene soluci\u00f3n no trivial x_1+2x_2-3x_3=0 2x_1+x_2-3x_3=0 -x1+x_2=0 Ejemplo 2: Dado el siguiente sistema homog\u00e9neo determine x_1-2x_3-7x_4=0 x_2+2x_3-4x_4=0 Las variables b\u00e1sicas y las variables libres. La forma general de la ecuaci\u00f3n vectorial","title":"1.5 Conjuntos Soluci\u00f3n de Sistemas Lineales"},{"location":"chapter_01/15_conjuntos_sistemas_lineales/#sistemas-lineales-no-homogeneos","text":"Un sistema lineal no homog\u00e9neo es aquel cuyo vector $\\boldsymbol{b} \\neq 0$. Cuando un sistema lineal no homog\u00e9neo tiene muchas soluciones se puede obtener la soluci\u00f3n como la combinaci\u00f3n de: La soluci\u00f3n del sistema homog\u00e9neo La soluci\u00f3n particular Ejemplo 3: Dado el sistema lineal del Ejemplo 1 encuentre la soluci\u00f3n para el sistema lineal no homog\u00e9neo con \\boldsymbol{b} = \\left[ \\begin{matrix} 1\\\\ 1 \\\\0 \\end{matrix} \\right] La soluci\u00f3n de la ecuaci\u00f3n lineal homog\u00e9nea tiene la forma \\boldsymbol{x} = v_{l1}\\boldsymbol{u_1}+v_{l2}\\boldsymbol{u_2}+\\dots+v_{ln}\\boldsymbol{u_n} Donde $v_{l1}, v_{l2},\\dots,v_{ln}$ son las variables libres del sistema y $\\boldsymbol{u_1}, \\boldsymbol{u_2},\\dots,\\boldsymbol{u_n}$ los vectores asociados a las mismas. La soluci\u00f3n de la ecuaci\u00f3n lineal no homog\u00e9nea tiene la forma \\boldsymbol{x} = \\boxed{v_{l1}\\boldsymbol{u_1}+v_{l2}\\boldsymbol{u_2}+\\dots+v_{ln}\\boldsymbol{u_n}}+ \\boldsymbol{p} Donde $\\boldsymbol{p}$ es la soluci\u00f3n particular del sistema.","title":"Sistemas Lineales No Homog\u00e9neos"},{"location":"chapter_01/15_conjuntos_sistemas_lineales/#interpretacion-geometrica","text":"Supongamos que el sistema lineal en $\\mathbb{R}^2$ tiene: Soluci\u00f3n $\\boldsymbol{x}=t\\boldsymbol{v}$ para $A\\boldsymbol{x}=\\boldsymbol{0}$ Soluci\u00f3n $\\boldsymbol{x}=t\\boldsymbol{v}+\\boldsymbol{p}$ para $A\\boldsymbol{x}=\\boldsymbol{b}$ Link en GeoGebra Link en GeoGebra TAREA SECCI\u00d3N 1.5 1, 3, 5, 6, 7, 8, 11, 13, 14, 17","title":"Interpretaci\u00f3n Geom\u00e9trica"},{"location":"chapter_01/17_independencia_lineal/","text":"1. Ecuaciones Lineales en \u00c1lgebra Lineal 1.7 Independencia Lineal El conjunto de vectores \\left\\{ \\boldsymbol{v_1}, \\boldsymbol{v_2}, \\dots, \\boldsymbol{v_n} \\right\\} en $\\mathbb{R}^n$ para el sistema homog\u00e9neo x_1\\boldsymbol{v_1}+x_2\\boldsymbol{v_2}+\\dots+x_p\\boldsymbol{v_p}=\\boldsymbol{0} puede ser: Linealmente Independiente $\\rightarrow$ Soluci\u00f3n Trivial Linealmente Dependiente $\\rightarrow$ Soluci\u00f3n no Trivial Si la matriz $A= \\left[\\boldsymbol{a_1} \\;\\;\\; \\boldsymbol{a_2} \\;\\dots\\; \\boldsymbol{a_n}\\;\\;\\; \\boldsymbol{0}\\right]$ tiene soluci\u00f3n trivial, $A$ es linealmente independiente. Ejemplo 1: Determine si \\left\\{\\boldsymbol{v_1}, \\boldsymbol{v_2}, \\boldsymbol{v_3} \\right\\} es linealmente independiente. \\boldsymbol{v_1} = \\left[ \\begin{matrix} -4\\\\ 0 \\\\1 \\\\2\\end{matrix} \\right] \\;\\;\\; \\boldsymbol{v_2} = \\left[ \\begin{matrix} -3\\\\ -1 \\\\1 \\\\1\\end{matrix} \\right] \\;\\;\\; \\boldsymbol{v_3} = \\left[ \\begin{matrix} 0\\\\ 5 \\\\-5 \\\\-10\\end{matrix} \\right] Ejemplo 2: Dados $\\boldsymbol{a_1}, \\boldsymbol{a_2}, \\boldsymbol{a_3}, \\boldsymbol{a_4}$ \\boldsymbol{a_1} = \\left[ \\begin{matrix} 1\\\\ -2 \\\\0 \\end{matrix} \\right] \\;\\;\\; \\boldsymbol{a_2} = \\left[ \\begin{matrix} -2\\\\ 4 \\\\1 \\end{matrix} \\right] \\;\\;\\; \\boldsymbol{a_3} = \\left[ \\begin{matrix} 3\\\\ -6 \\\\-1 \\end{matrix} \\right] \\;\\;\\; \\boldsymbol{a_4} = \\left[ \\begin{matrix} 2\\\\ 2 \\\\3 \\end{matrix} \\right] Determine si \\left\\{\\boldsymbol{a_1}, \\boldsymbol{a_2}, \\boldsymbol{a_3}, \\boldsymbol{a_4} \\right\\} es linealmente independiente. Encuentre una relaci\u00f3n de dependencia lineal. Vectores Linealmente Dependientes El conjunto de vectores \\left\\{\\boldsymbol{u},\\boldsymbol{v} \\right\\} es linealmente dependiente si uno de los vectores es m\u00faltiplo del otro. Para el conjunto de vectores \\left\\{ \\boldsymbol{v_1}, \\boldsymbol{v_2}, \\dots, \\boldsymbol{v_n} \\right\\} si uno de estos vectores es combinaci\u00f3n lineal con otro se dice que este conjunto es linealmente dependiente. Si un conjunto contiene m\u00e1s vectores que entradas en cada vector, entonces el conjunto es linealmente dependiente. Existen m\u00e1s variables que ecuaciones en un sistema de ecuaciones. Si un conjunto s=\\left\\{ \\boldsymbol{v_1}, \\boldsymbol{v_2}, \\dots, \\boldsymbol{v_p} \\right\\} en $\\mathbb{R}^n$ contiene el vector cero, entonces el conjunto es linealmente dependiente. Ejemplo 3: Determine por inspecci\u00f3n si el conjunto dado es linealmente dependiente. \\left[ \\begin{matrix} 1\\\\2\\\\4 \\end{matrix}\\right], \\;\\;\\; \\left[ \\begin{matrix} 3\\\\0\\\\9 \\end{matrix}\\right], \\;\\;\\; \\left[ \\begin{matrix} 3\\\\1\\\\5 \\end{matrix}\\right], \\;\\;\\; \\left[ \\begin{matrix} 4\\\\8\\\\1 \\end{matrix}\\right] \\;\\;\\; \\left[ \\begin{matrix} 3\\\\5\\\\8 \\end{matrix}\\right], \\;\\;\\; \\left[ \\begin{matrix} 0\\\\0\\\\0 \\end{matrix}\\right], \\;\\;\\; \\left[ \\begin{matrix} -1\\\\-2\\\\4 \\end{matrix}\\right] \\;\\;\\; \\left[ \\begin{matrix} 20\\\\-40\\\\15\\\\35 \\end{matrix}\\right], \\;\\;\\; \\left[ \\begin{matrix} 16\\\\-32\\\\13\\\\28 \\end{matrix}\\right] \\;\\;\\; TAREA SECCI\u00d3N 1.7 1, 2, 5, 7, 11, 13, 16, 18, 20, 31","title":"1.7 Independencia Lineal"},{"location":"chapter_01/17_independencia_lineal/#1-ecuaciones-lineales-en-algebra-lineal","text":"","title":"1. Ecuaciones Lineales en \u00c1lgebra Lineal"},{"location":"chapter_01/17_independencia_lineal/#17-independencia-lineal","text":"El conjunto de vectores \\left\\{ \\boldsymbol{v_1}, \\boldsymbol{v_2}, \\dots, \\boldsymbol{v_n} \\right\\} en $\\mathbb{R}^n$ para el sistema homog\u00e9neo x_1\\boldsymbol{v_1}+x_2\\boldsymbol{v_2}+\\dots+x_p\\boldsymbol{v_p}=\\boldsymbol{0} puede ser: Linealmente Independiente $\\rightarrow$ Soluci\u00f3n Trivial Linealmente Dependiente $\\rightarrow$ Soluci\u00f3n no Trivial Si la matriz $A= \\left[\\boldsymbol{a_1} \\;\\;\\; \\boldsymbol{a_2} \\;\\dots\\; \\boldsymbol{a_n}\\;\\;\\; \\boldsymbol{0}\\right]$ tiene soluci\u00f3n trivial, $A$ es linealmente independiente. Ejemplo 1: Determine si \\left\\{\\boldsymbol{v_1}, \\boldsymbol{v_2}, \\boldsymbol{v_3} \\right\\} es linealmente independiente. \\boldsymbol{v_1} = \\left[ \\begin{matrix} -4\\\\ 0 \\\\1 \\\\2\\end{matrix} \\right] \\;\\;\\; \\boldsymbol{v_2} = \\left[ \\begin{matrix} -3\\\\ -1 \\\\1 \\\\1\\end{matrix} \\right] \\;\\;\\; \\boldsymbol{v_3} = \\left[ \\begin{matrix} 0\\\\ 5 \\\\-5 \\\\-10\\end{matrix} \\right] Ejemplo 2: Dados $\\boldsymbol{a_1}, \\boldsymbol{a_2}, \\boldsymbol{a_3}, \\boldsymbol{a_4}$ \\boldsymbol{a_1} = \\left[ \\begin{matrix} 1\\\\ -2 \\\\0 \\end{matrix} \\right] \\;\\;\\; \\boldsymbol{a_2} = \\left[ \\begin{matrix} -2\\\\ 4 \\\\1 \\end{matrix} \\right] \\;\\;\\; \\boldsymbol{a_3} = \\left[ \\begin{matrix} 3\\\\ -6 \\\\-1 \\end{matrix} \\right] \\;\\;\\; \\boldsymbol{a_4} = \\left[ \\begin{matrix} 2\\\\ 2 \\\\3 \\end{matrix} \\right] Determine si \\left\\{\\boldsymbol{a_1}, \\boldsymbol{a_2}, \\boldsymbol{a_3}, \\boldsymbol{a_4} \\right\\} es linealmente independiente. Encuentre una relaci\u00f3n de dependencia lineal.","title":"1.7 Independencia Lineal"},{"location":"chapter_01/17_independencia_lineal/#vectores-linealmente-dependientes","text":"El conjunto de vectores \\left\\{\\boldsymbol{u},\\boldsymbol{v} \\right\\} es linealmente dependiente si uno de los vectores es m\u00faltiplo del otro. Para el conjunto de vectores \\left\\{ \\boldsymbol{v_1}, \\boldsymbol{v_2}, \\dots, \\boldsymbol{v_n} \\right\\} si uno de estos vectores es combinaci\u00f3n lineal con otro se dice que este conjunto es linealmente dependiente. Si un conjunto contiene m\u00e1s vectores que entradas en cada vector, entonces el conjunto es linealmente dependiente. Existen m\u00e1s variables que ecuaciones en un sistema de ecuaciones. Si un conjunto s=\\left\\{ \\boldsymbol{v_1}, \\boldsymbol{v_2}, \\dots, \\boldsymbol{v_p} \\right\\} en $\\mathbb{R}^n$ contiene el vector cero, entonces el conjunto es linealmente dependiente. Ejemplo 3: Determine por inspecci\u00f3n si el conjunto dado es linealmente dependiente. \\left[ \\begin{matrix} 1\\\\2\\\\4 \\end{matrix}\\right], \\;\\;\\; \\left[ \\begin{matrix} 3\\\\0\\\\9 \\end{matrix}\\right], \\;\\;\\; \\left[ \\begin{matrix} 3\\\\1\\\\5 \\end{matrix}\\right], \\;\\;\\; \\left[ \\begin{matrix} 4\\\\8\\\\1 \\end{matrix}\\right] \\;\\;\\; \\left[ \\begin{matrix} 3\\\\5\\\\8 \\end{matrix}\\right], \\;\\;\\; \\left[ \\begin{matrix} 0\\\\0\\\\0 \\end{matrix}\\right], \\;\\;\\; \\left[ \\begin{matrix} -1\\\\-2\\\\4 \\end{matrix}\\right] \\;\\;\\; \\left[ \\begin{matrix} 20\\\\-40\\\\15\\\\35 \\end{matrix}\\right], \\;\\;\\; \\left[ \\begin{matrix} 16\\\\-32\\\\13\\\\28 \\end{matrix}\\right] \\;\\;\\; TAREA SECCI\u00d3N 1.7 1, 2, 5, 7, 11, 13, 16, 18, 20, 31","title":"Vectores Linealmente Dependientes"},{"location":"chapter_01/18_intro_transformaciones/","text":"1. Ecuaciones Lineales en \u00c1lgebra Lineal 1.8 Introducci\u00f3n a las Transformaciones Lineales Podemos pensar en la matriz $A$ como un objeto que act\u00faa sobre un vector $\\boldsymbol{x}$ multiplic\u00e1ndolo para producir un nuevo vector $A\\boldsymbol{x}$. Supongamos que tenemos los vectores \\boldsymbol{u_1} = \\left[ \\begin{matrix} 0\\\\0 \\end{matrix} \\right], \\;\\;\\; \\boldsymbol{u_2} = \\left[ \\begin{matrix} 3\\\\0 \\end{matrix} \\right], \\;\\;\\; \\boldsymbol{u_3} = \\left[ \\begin{matrix} 3\\\\3 \\end{matrix} \\right] \\;\\;\\; y multiplicamos por la matriz A = \\left[ \\begin{matrix} 1 & 2 \\\\ 0 & 1 \\end{matrix} \\right] obtendremos los siguientes resultados A\\boldsymbol{u_1} = \\left[ \\begin{matrix} 1 & 2 \\\\ 0 & 1 \\end{matrix} \\right]\\left[ \\begin{matrix} 0\\\\0 \\end{matrix} \\right] = \\left[ \\begin{matrix} 0\\\\0 \\end{matrix} \\right] \\;\\;\\;\\; A\\boldsymbol{u_2} = \\left[ \\begin{matrix} 1 & 2 \\\\ 0 & 1 \\end{matrix} \\right]\\left[ \\begin{matrix} 3\\\\0 \\end{matrix} \\right] = \\left[ \\begin{matrix} 3\\\\0 \\end{matrix} \\right] \\;\\;\\;\\; A\\boldsymbol{u_3} = \\left[ \\begin{matrix} 1 & 2 \\\\ 0 & 1 \\end{matrix} \\right]\\left[ \\begin{matrix} 3\\\\3 \\end{matrix} \\right] = \\left[ \\begin{matrix} 9\\\\3 \\end{matrix} \\right] Se puede notar como la aplicaci\u00f3n de la matriz $A$ a $\\boldsymbol{u}$ transforma en una nueva $\\boldsymbol{u'}$. Link Geogebra Definiendo una serie de vectores es posible construir figuras m\u00e1s complejas que al aplicarle la matriz $A$ genere transformaciones a esta figura. Link Geogebra Transformaci\u00f3n $T(\\boldsymbol{x})$ En forma general una transformaci\u00f3n es una regla que asigna a cada vector $\\boldsymbol{x}$ en $\\mathbb{R}^n$ un vector $T(\\boldsymbol{x})$ en $\\mathbb{R}^m$. La notaci\u00f3n $T(\\boldsymbol{x})$ es equivalente a $A\\boldsymbol{x}$. A veces se le denomina mapeo o funci\u00f3n. T:\\mathbb{R}^n \\rightarrow \\mathbb{R}^m Para una matriz $A$ de $(m \\times n)$ y un vector $\\boldsymbol{x}$ de $(n \\times 1)$ El domino de $T$ es $\\mathbb{R}^n$, el n\u00famero de filas de $\\boldsymbol{x}$ El codomino de $T$ es $\\mathbb{R}^m$, el n\u00famero de filas de $A$ Rango de una Matriz Es el conjunto de todas las combinaciones linealmente independientes de una matriz. Ejemplo 1: Encuentre un vector $\\boldsymbol{x}$ cuya imagen bajo $T$ sea $\\boldsymbol{b}$. A = \\left[ \\begin{matrix} 1 & -2 & 3 \\\\ 0 & 1 & -3 \\\\ 2 & -5 & 6 \\end{matrix} \\right], \\;\\;\\; \\boldsymbol{b} = \\left[ \\begin{matrix} -6\\\\ -4 \\\\-5 \\end{matrix} \\right] Ejemplo 2: Para los resultados del Ejemplo 1 , \u00bfHay m\u00e1s de una $\\boldsymbol{x}$ cuya imagen bajo $T$ sea $\\boldsymbol{b}$? Ejemplo 3: Para la matriz $A$ del Ejemplo 1 , \u00bfEstar\u00e1 $\\boldsymbol{c}$ en el rango de transformaci\u00f3n? \\boldsymbol{c} = \\left[ \\begin{matrix} -1\\\\ 0 \\\\-5 \\end{matrix} \\right] Propiedades de las Transformaciones Lineales $T(\\boldsymbol u+\\boldsymbol v)=T(\\boldsymbol u)+ T(\\boldsymbol v)$ $T(c \\boldsymbol u)=cT(\\boldsymbol u)$ $T(\\boldsymbol 0)=\\boldsymbol 0$ $T(c\\boldsymbol u+d\\boldsymbol v)=cT(\\boldsymbol u)+ dT(\\boldsymbol v)$ Donde $\\boldsymbol u, \\boldsymbol v$ son vectores y $c, d$ constantes o escalares. Principio de Superposici\u00f3n La respuesta total del sistema es equivalente a la suma de las respuestas individuales. \u00danicamente un c\u00e1lculo con la matriz $A$ C\u00e1lculos en paralelo con la matriz $A$ TAREA SECCI\u00d3N 1.8 1, 3, 5, 7, 9, 13, 16, 23, 24","title":"1.8 Introducci\u00f3n a las Transformaciones"},{"location":"chapter_01/18_intro_transformaciones/#1-ecuaciones-lineales-en-algebra-lineal","text":"","title":"1. Ecuaciones Lineales en \u00c1lgebra Lineal"},{"location":"chapter_01/18_intro_transformaciones/#18-introduccion-a-las-transformaciones-lineales","text":"Podemos pensar en la matriz $A$ como un objeto que act\u00faa sobre un vector $\\boldsymbol{x}$ multiplic\u00e1ndolo para producir un nuevo vector $A\\boldsymbol{x}$. Supongamos que tenemos los vectores \\boldsymbol{u_1} = \\left[ \\begin{matrix} 0\\\\0 \\end{matrix} \\right], \\;\\;\\; \\boldsymbol{u_2} = \\left[ \\begin{matrix} 3\\\\0 \\end{matrix} \\right], \\;\\;\\; \\boldsymbol{u_3} = \\left[ \\begin{matrix} 3\\\\3 \\end{matrix} \\right] \\;\\;\\; y multiplicamos por la matriz A = \\left[ \\begin{matrix} 1 & 2 \\\\ 0 & 1 \\end{matrix} \\right] obtendremos los siguientes resultados A\\boldsymbol{u_1} = \\left[ \\begin{matrix} 1 & 2 \\\\ 0 & 1 \\end{matrix} \\right]\\left[ \\begin{matrix} 0\\\\0 \\end{matrix} \\right] = \\left[ \\begin{matrix} 0\\\\0 \\end{matrix} \\right] \\;\\;\\;\\; A\\boldsymbol{u_2} = \\left[ \\begin{matrix} 1 & 2 \\\\ 0 & 1 \\end{matrix} \\right]\\left[ \\begin{matrix} 3\\\\0 \\end{matrix} \\right] = \\left[ \\begin{matrix} 3\\\\0 \\end{matrix} \\right] \\;\\;\\;\\; A\\boldsymbol{u_3} = \\left[ \\begin{matrix} 1 & 2 \\\\ 0 & 1 \\end{matrix} \\right]\\left[ \\begin{matrix} 3\\\\3 \\end{matrix} \\right] = \\left[ \\begin{matrix} 9\\\\3 \\end{matrix} \\right] Se puede notar como la aplicaci\u00f3n de la matriz $A$ a $\\boldsymbol{u}$ transforma en una nueva $\\boldsymbol{u'}$. Link Geogebra Definiendo una serie de vectores es posible construir figuras m\u00e1s complejas que al aplicarle la matriz $A$ genere transformaciones a esta figura. Link Geogebra","title":"1.8 Introducci\u00f3n a las Transformaciones Lineales"},{"location":"chapter_01/18_intro_transformaciones/#transformacion-tboldsymbolx","text":"En forma general una transformaci\u00f3n es una regla que asigna a cada vector $\\boldsymbol{x}$ en $\\mathbb{R}^n$ un vector $T(\\boldsymbol{x})$ en $\\mathbb{R}^m$. La notaci\u00f3n $T(\\boldsymbol{x})$ es equivalente a $A\\boldsymbol{x}$. A veces se le denomina mapeo o funci\u00f3n. T:\\mathbb{R}^n \\rightarrow \\mathbb{R}^m Para una matriz $A$ de $(m \\times n)$ y un vector $\\boldsymbol{x}$ de $(n \\times 1)$ El domino de $T$ es $\\mathbb{R}^n$, el n\u00famero de filas de $\\boldsymbol{x}$ El codomino de $T$ es $\\mathbb{R}^m$, el n\u00famero de filas de $A$","title":"Transformaci\u00f3n $T(\\boldsymbol{x})$"},{"location":"chapter_01/18_intro_transformaciones/#rango-de-una-matriz","text":"Es el conjunto de todas las combinaciones linealmente independientes de una matriz. Ejemplo 1: Encuentre un vector $\\boldsymbol{x}$ cuya imagen bajo $T$ sea $\\boldsymbol{b}$. A = \\left[ \\begin{matrix} 1 & -2 & 3 \\\\ 0 & 1 & -3 \\\\ 2 & -5 & 6 \\end{matrix} \\right], \\;\\;\\; \\boldsymbol{b} = \\left[ \\begin{matrix} -6\\\\ -4 \\\\-5 \\end{matrix} \\right] Ejemplo 2: Para los resultados del Ejemplo 1 , \u00bfHay m\u00e1s de una $\\boldsymbol{x}$ cuya imagen bajo $T$ sea $\\boldsymbol{b}$? Ejemplo 3: Para la matriz $A$ del Ejemplo 1 , \u00bfEstar\u00e1 $\\boldsymbol{c}$ en el rango de transformaci\u00f3n? \\boldsymbol{c} = \\left[ \\begin{matrix} -1\\\\ 0 \\\\-5 \\end{matrix} \\right]","title":"Rango de una Matriz"},{"location":"chapter_01/18_intro_transformaciones/#propiedades-de-las-transformaciones-lineales","text":"$T(\\boldsymbol u+\\boldsymbol v)=T(\\boldsymbol u)+ T(\\boldsymbol v)$ $T(c \\boldsymbol u)=cT(\\boldsymbol u)$ $T(\\boldsymbol 0)=\\boldsymbol 0$ $T(c\\boldsymbol u+d\\boldsymbol v)=cT(\\boldsymbol u)+ dT(\\boldsymbol v)$ Donde $\\boldsymbol u, \\boldsymbol v$ son vectores y $c, d$ constantes o escalares.","title":"Propiedades de las Transformaciones Lineales"},{"location":"chapter_01/18_intro_transformaciones/#principio-de-superposicion","text":"La respuesta total del sistema es equivalente a la suma de las respuestas individuales. \u00danicamente un c\u00e1lculo con la matriz $A$ C\u00e1lculos en paralelo con la matriz $A$ TAREA SECCI\u00d3N 1.8 1, 3, 5, 7, 9, 13, 16, 23, 24","title":"Principio de Superposici\u00f3n"},{"location":"chapter_01/19_matriz_transformacion/","text":"1. Ecuaciones Lineales en \u00c1lgebra Lineal 1.9 Matriz de una Transformacion Lineal En esta secci\u00f3n veremos como encontrar la matriz de transformaci\u00f3n $A$. La clave para encontrar $A$ es observar que $T$ est\u00e1 plenamente determinada por su acci\u00f3n sobre las columnas de la matriz identidad. Sea la matriz identidad $I_n$ de $(n \\times n)$ I_n = \\left[ \\begin{matrix} \\boldsymbol{e_1}\\;\\;\\; \\boldsymbol{e_2}\\;\\dots\\; \\boldsymbol{e_n} \\end{matrix} \\right] Donde: \\boldsymbol{e_1} = \\left[ \\begin{matrix} 1\\\\ 0 \\\\0 \\\\\\vdots \\\\0 \\end{matrix} \\right], \\;\\;\\; \\boldsymbol{e_2} = \\left[ \\begin{matrix} 0\\\\ 1 \\\\0 \\\\\\vdots \\\\0 \\end{matrix} \\right], \\;\\;\\; \\boldsymbol{e_n} = \\left[ \\begin{matrix} 0\\\\ 0 \\\\0 \\\\\\vdots \\\\1 \\end{matrix} \\right] La matriz $A$ puede definirse como: A = \\left[ \\begin{matrix} T(\\boldsymbol{e_1})\\;\\;\\; T(\\boldsymbol{e_2})\\;\\dots\\; T(\\boldsymbol{e_n}) \\end{matrix} \\right] Por lo que la acci\u00f3n de aplicar la matriz $A$ puede ser descrito como: T(\\boldsymbol{x})=A\\boldsymbol{x} = \\left[ \\begin{matrix} T(\\boldsymbol{e_1})\\;\\;\\; T(\\boldsymbol{e_2})\\;\\dots\\; T(\\boldsymbol{e_n}) \\end{matrix} \\right]\\left[ \\begin{matrix} x_1\\\\ x_2 \\\\\\vdots \\\\x_n \\end{matrix} \\right] Ejemplo 1: Encuentre la matriz est\u00e1ndar $A$ para la transformaci\u00f3n $T(x)=3\\boldsymbol{x}$ para $\\boldsymbol{x}$ en $\\mathbb{R}^2$. Cuando se habla de transformaci\u00f3n lineal nos enfocamos en la propiedad de mapeo. Cuando se habla de transformaci\u00f3n matricial nos enfocamos en c\u00f3mo se implementa ese mapeo. Rotaci\u00f3n de un Vector en $\\mathbb{R}^2$ usando Transformaciones de Matriz Ejemplo 2: Encuentre la matriz est\u00e1ndar $A$ para la rotaci\u00f3n de un \u00e1ngulo $\\varphi$ como se muestra en la figura. Link GeoGebra Ejemplo 3: Determine la matriz est\u00e1ndar $B$ para la rotaci\u00f3n a favor de las manecillas del reloj para un \u00e1ngulo $\\theta$. Existencia y Unicidad de $T$ Un mapeo $T:\\mathbb{R}^n \\rightarrow \\mathbb{R}^m$ es sobre $\\mathbb{R}^m$ cuando existe al menos una soluci\u00f3n . $T$ es uno a uno si para cada $\\boldsymbol{b}$ en $\\mathbb{R}^m$ la ecuaci\u00f3n $T(\\boldsymbol{x})=\\boldsymbol{b}$ tiene una o ninguna soluci\u00f3n . Sea $T:\\mathbb{R}^n \\rightarrow \\mathbb{R}^m$, $T$ es uno a uno si y solo si la ecuaci\u00f3n $T(\\boldsymbol{x})=\\boldsymbol{0}$ tiene \u00fanicamente soluci\u00f3n trivial . $T$ es uno a uno si y solo si las columnas son linealmente independientes. TAREA SECCI\u00d3N 1.9 1, 3, 5, 11, 15, 17, 19","title":"1.9 Matriz Transformaci\u00f3n"},{"location":"chapter_01/19_matriz_transformacion/#1-ecuaciones-lineales-en-algebra-lineal","text":"","title":"1. Ecuaciones Lineales en \u00c1lgebra Lineal"},{"location":"chapter_01/19_matriz_transformacion/#19-matriz-de-una-transformacion-lineal","text":"En esta secci\u00f3n veremos como encontrar la matriz de transformaci\u00f3n $A$. La clave para encontrar $A$ es observar que $T$ est\u00e1 plenamente determinada por su acci\u00f3n sobre las columnas de la matriz identidad. Sea la matriz identidad $I_n$ de $(n \\times n)$ I_n = \\left[ \\begin{matrix} \\boldsymbol{e_1}\\;\\;\\; \\boldsymbol{e_2}\\;\\dots\\; \\boldsymbol{e_n} \\end{matrix} \\right] Donde: \\boldsymbol{e_1} = \\left[ \\begin{matrix} 1\\\\ 0 \\\\0 \\\\\\vdots \\\\0 \\end{matrix} \\right], \\;\\;\\; \\boldsymbol{e_2} = \\left[ \\begin{matrix} 0\\\\ 1 \\\\0 \\\\\\vdots \\\\0 \\end{matrix} \\right], \\;\\;\\; \\boldsymbol{e_n} = \\left[ \\begin{matrix} 0\\\\ 0 \\\\0 \\\\\\vdots \\\\1 \\end{matrix} \\right] La matriz $A$ puede definirse como: A = \\left[ \\begin{matrix} T(\\boldsymbol{e_1})\\;\\;\\; T(\\boldsymbol{e_2})\\;\\dots\\; T(\\boldsymbol{e_n}) \\end{matrix} \\right] Por lo que la acci\u00f3n de aplicar la matriz $A$ puede ser descrito como: T(\\boldsymbol{x})=A\\boldsymbol{x} = \\left[ \\begin{matrix} T(\\boldsymbol{e_1})\\;\\;\\; T(\\boldsymbol{e_2})\\;\\dots\\; T(\\boldsymbol{e_n}) \\end{matrix} \\right]\\left[ \\begin{matrix} x_1\\\\ x_2 \\\\\\vdots \\\\x_n \\end{matrix} \\right] Ejemplo 1: Encuentre la matriz est\u00e1ndar $A$ para la transformaci\u00f3n $T(x)=3\\boldsymbol{x}$ para $\\boldsymbol{x}$ en $\\mathbb{R}^2$. Cuando se habla de transformaci\u00f3n lineal nos enfocamos en la propiedad de mapeo. Cuando se habla de transformaci\u00f3n matricial nos enfocamos en c\u00f3mo se implementa ese mapeo.","title":"1.9 Matriz de una Transformacion Lineal"},{"location":"chapter_01/19_matriz_transformacion/#rotacion-de-un-vector-en-mathbbr2-usando-transformaciones-de-matriz","text":"Ejemplo 2: Encuentre la matriz est\u00e1ndar $A$ para la rotaci\u00f3n de un \u00e1ngulo $\\varphi$ como se muestra en la figura. Link GeoGebra Ejemplo 3: Determine la matriz est\u00e1ndar $B$ para la rotaci\u00f3n a favor de las manecillas del reloj para un \u00e1ngulo $\\theta$.","title":"Rotaci\u00f3n de un Vector en $\\mathbb{R}^2$ usando Transformaciones de Matriz"},{"location":"chapter_01/19_matriz_transformacion/#existencia-y-unicidad-de-t","text":"Un mapeo $T:\\mathbb{R}^n \\rightarrow \\mathbb{R}^m$ es sobre $\\mathbb{R}^m$ cuando existe al menos una soluci\u00f3n . $T$ es uno a uno si para cada $\\boldsymbol{b}$ en $\\mathbb{R}^m$ la ecuaci\u00f3n $T(\\boldsymbol{x})=\\boldsymbol{b}$ tiene una o ninguna soluci\u00f3n . Sea $T:\\mathbb{R}^n \\rightarrow \\mathbb{R}^m$, $T$ es uno a uno si y solo si la ecuaci\u00f3n $T(\\boldsymbol{x})=\\boldsymbol{0}$ tiene \u00fanicamente soluci\u00f3n trivial . $T$ es uno a uno si y solo si las columnas son linealmente independientes. TAREA SECCI\u00d3N 1.9 1, 3, 5, 11, 15, 17, 19","title":"Existencia y Unicidad de $T$"},{"location":"chapter_02/21_Operaciones_de_Matrices/","text":"2. \u00c1lgebra de Matrices 2.1 Operaciones de Matrices A continuaci\u00f3n definiremos algunos conceptos: Supongamos la siguiente matriz de $m \\times n$ A=\\left [\\begin{matrix} a_{11} & a_{12} & \\dots & a_{1n} \\\\ a_{21} & a_{22} & \\dots & a_{2n} \\\\ \\vdots & \\vdots & \\vdots & \\vdots \\\\ a_{m1} & a_{m2} & \\dots & a_{mn} \\end{matrix} \\right ] Llamamos entradas diagonales a los t\u00e9rminos $a_{11}$, $a_{22}$, $a_{33}$, $\\dots$ y \u00e9stos forman la diagonal principal . Existen 3 tipos de matrices de $n \\times n$ de inter\u00e9s que se pueden analizar: Matriz con Entradas Diagonales Matriz identidad Matriz Cero o Nula A=\\left[\\begin{array}{cccc} * & 0 & \\dots & 0\\\\ 0 & * & \\dots & 0\\\\ \\vdots & \\vdots & \\vdots & \\vdots\\\\ 0 & 0 & \\dots & * \\end{array}\\right] I_n=\\left[\\begin{array}{cccc} 1 & 0 & \\dots & 0\\\\ 0 & 1 & \\dots & 0\\\\ \\vdots & \\vdots & \\vdots & \\vdots\\\\ 0 & 0 & \\dots & 1 \\end{array}\\right] O_n=\\left[\\begin{array}{cccc} 0 & 0 & \\dots & 0\\\\ 0 & 0 & \\dots & 0\\\\ \\vdots & \\vdots & \\vdots & \\vdots\\\\ 0 & 0 & \\dots & 0 \\end{array}\\right] Igualdad de matrices: Dos matrices son iguales si tienen las mismas dimensiones $m \\times n$ y las mismas entradas. Suma de Matrices Las matrices deben de ser de la misma dimensi\u00f3n para poder realizar la suma de matrices. Se define t\u00e9rmino a t\u00e9rmino entre los t\u00e9rminos de una matriz con otra. A=\\left[\\begin{array}{ccc} 3 & -5 & -7\\\\ 2 & 1 & 9\\\\ -4 & 0 & 1 \\end{array}\\right] \\;\\;\\;\\;\\;\\; B=\\left[\\begin{array}{ccc} 1 & -3 & 0\\\\ 2 & -2 & 1\\\\ 3 & -1 & 7 \\end{array}\\right] A+B=\\left[\\begin{array}{ccc} 4 & -8 & -7\\\\ 4 & -1 & 10\\\\ -1 & -1 & 8 \\end{array}\\right] La suma de matrices no esta definida si las matrices tienen distintas dimensiones. Multiplicaci\u00f3n por Escalares 3A=3\\left[\\begin{array}{ccc} 3 & -5 & -7\\\\ 2 & 1 & 9\\\\ -4 & 0 & 1 \\end{array}\\right]=\\left[\\begin{array}{ccc} 9 & -15 & -21\\\\ 6 & 3 & 27\\\\ -12 & 0 & 3 \\end{array}\\right] Propiedades de la Suma y Multiplicaci\u00f3n por Escalares Sean $A$, $B$, $C$ matrices de $(m \\times n)$ y $r$, $s$ escalares. $A+B=B+A$ $(A+B)+C=A+(B+C)$ $A+O=A$ $r(A+B)=rA+rB$ $(r+s)A=rA+sA$ $r(sA)=(rs)A$ Multiplicaci\u00f3n de Matrices Como una transformaci\u00f3n de matrices Podemos recordar que la matriz $A$ era una transformaci\u00f3n o mapeo de un espacio a otro, con este concepto podemos extrapolar al caso de tener otra matriz $B$ tal que $BA$ como se muestra en la figura: El producto $A(B\\boldsymbol{x})$ es una composici\u00f3n de mapeos. Como una combinaci\u00f3n lineal Estaremos partiendo de la definici\u00f3n de combinaci\u00f3n lineal con el producto matricial $A\\boldsymbol{x}$ A \\boldsymbol{x}=\\left[\\boldsymbol{a_1} \\boldsymbol{a_2} \\boldsymbol{\\dots} \\boldsymbol{a_p} \\right]\\left[\\begin{array}{c} x_1\\\\ x_2\\\\ \\vdots \\\\x_3 \\end{array}\\right]=x_1\\boldsymbol{a_1}+x_2\\boldsymbol{a_2}+\\dots +x_p\\boldsymbol{a_p} Ahora multiplicaremos por la matriz $B$ B(A \\boldsymbol{x})=B(x_1\\boldsymbol{a_1}+x_2\\boldsymbol{a_2}+\\dots +x_p\\boldsymbol{a_p}) \\;\\;\\;\\;\\; \\;\\;\\;\\;\\;\\ =Bx_1\\boldsymbol{a_1}+Bx_2\\boldsymbol{a_2}+\\dots +Bx_p\\boldsymbol{a_p} \\;\\;\\;\\;\\; \\;\\;\\;\\;\\;\\ =x_1B\\boldsymbol{a_1}+x_2B\\boldsymbol{a_2}+\\dots +x_pB\\boldsymbol{a_p} \\;\\;\\;\\;\\; \\;\\;\\;\\;\\;\\ =\\left[B\\boldsymbol{a_1} B\\boldsymbol{a_2} \\boldsymbol{\\dots} B\\boldsymbol{a_p} \\right]\\left[\\begin{array}{c} x_1\\\\ x_2\\\\ \\vdots \\\\x_3 \\end{array}\\right] Con esto se puede notar que el producto $AB =\\left[B\\boldsymbol{a_1} B\\boldsymbol{a_2} \\boldsymbol{\\dots} B\\boldsymbol{a_p} \\right]$ con $A$ de $(m \\times n)$ y $B$ de $(n \\times p)$. Observe que el producto $B\\boldsymbol{a_n}$ es una combinaci\u00f3n lineal de las columnas de $B$ usando coeficientes de la columna correspondiente de $A$. Ejemplo 1: Dadas las matrices $A$ y $B$ encuentre el producto de $AB$ como la combinaci\u00f3n de las columnas de $A$ con los coeficientes de la columna correspondiente de $B$. A=\\left[\\begin{array}{cc} 2 & 3\\\\ 1 & -5 \\end{array}\\right] \\;\\;\\;\\;\\; B=\\left[\\begin{array}{ccc} 4 & 3 & 6\\\\ 1 & -2 & 3 \\end{array}\\right] Si sabemos que AB = [A\\boldsymbol{b_1} \\;\\;A\\boldsymbol{b_2} \\;\\; A\\boldsymbol{b_3}] Se puede trabajar cada combinaci\u00f3n de las columnas A\\boldsymbol{b_1}=\\left[\\begin{array}{cc} 2 & 3\\\\ 1 & -5 \\end{array}\\right]\\left[\\begin{array}{c} 4\\\\ 1 \\end{array}\\right]=\\left[\\begin{array}{c} 11\\\\ -1 \\end{array}\\right] A\\boldsymbol{b_2}=\\left[\\begin{array}{cc} 2 & 3\\\\ 1 & -5 \\end{array}\\right]\\left[\\begin{array}{c} 3\\\\ -2 \\end{array}\\right]=\\left[\\begin{array}{c} 0\\\\ 13 \\end{array}\\right] A\\boldsymbol{b_3}=\\left[\\begin{array}{cc} 2 & 3\\\\ 1 & -5 \\end{array}\\right]\\left[\\begin{array}{c} 6\\\\ 3 \\end{array}\\right]=\\left[\\begin{array}{c} 21\\\\ -9 \\end{array}\\right] Finalmente el producto $AB$ ser\u00e1 AB = \\left[\\begin{array}{ccc} 11 & 0 & 21\\\\ -1 & 13 & -9 \\end{array}\\right] Regla Fila Columna Sean $A$ de $(2 \\times 2)$ y $B$ de $(2 \\times 3)$ dos matrices como las que se muestran a continuaci\u00f3n A=\\left[\\begin{array}{cc} a_{11} & a_{12}\\\\ a_{21} & a_{22} \\end{array}\\right] \\;\\;\\;\\;\\; B=\\left[\\begin{array}{ccc} b_{11} & b_{12} & b_{13}\\\\ b_{21} & b_{22} & b_{23} \\end{array}\\right] El producto $AB$ se puede calcular como AB=\\left[\\begin{array}{cc} a_{11} & a_{12}\\\\ a_{21} & a_{22} \\end{array}\\right] \\left[\\begin{array}{ccc} b_{11} & b_{12} & b_{13}\\\\ b_{21} & b_{22} & b_{23} \\end{array}\\right]=\\left[\\begin{array}{ccc} a_{11}b_{11}+a_{12}b_{21} & a_{11}b_{12}+a_{12}b_{22} & a_{11}b_{13}+a_{12}b_{23}\\\\ a_{21}b_{11}+a_{22}b_{21} & a_{21}b_{12}+a_{22}b_{22} & a_{21}b_{13}+a_{22}b_{23} \\end{array}\\right] Ejemplo 2: Encuentre el producto $AB$ del Ejemplo 1 por medio de la regla fila columna. C\u00e1lculo de algunos elementos de $AB$ Definiremos la fila $i$ de una matriz $A$ como $\\boldsymbol{a_{i,*}}$ o $\\boldsymbol{a_{i,:}}$ en la cual la segunda notaci\u00f3n da preferencia a ser mejor interpretada en un lenguaje de programaci\u00f3n. Usualmente hemos definido, la columna $j$ de $A$ como $\\boldsymbol{a_{j}}$, sin embargo si deseamos mantener consistencia, tambi\u00e9n puede ser escrito como $\\boldsymbol{a_{*,j}}$ o $\\boldsymbol{a_{:,j}}$. El elemento $i$, $j$ de la matriz $A$ se puede expresar como $a_{i,j}$. Esta representaci\u00f3n depender\u00e1 mucho del contexto en que se usen. Sea $C=AB$ podemos calcular los siguientes valores: Fila $i$ de $AB$ Columna $j$ de $AB$ Elemento $i$, $j$ de $AB$ \\boldsymbol{c}_{i,:}=\\boldsymbol{a_{i,:}}B \\boldsymbol{c}_{:,j}=A\\boldsymbol{b_{:,j}} $c_{i,j}=\\boldsymbol{a_{i,:}}\\boldsymbol{b_{:,j}}$ Propiedades de la Multiplicaci\u00f3n de Matrices Sea $A$ una matriz de $(m \\times n)$, $B$ , $C$ matrices con tama\u00f1os adecuados y $r$ un escalar. Adem\u00e1s sean $I_m$ e $I_n$ la matriz identidad de $(m \\times m)$ y $(n \\times n)$ respectivamente. $A(BC)=(AB)C$ $A(B+C)=AB+AC$ $(B+C)A=BA+CA$ $r(AB)=(rA)B=A(rB)$ $I_mA=A=AI_n$ Advertencias En forma general $AB \\neq BA$, sin embargo si sucediera se dice que $A$ y $B$ son matrices que se conmutan. Si $AB=AC$ no implica que $B=C$. No se pueden \"cancelar\" las matrices $A$. Si $AB=0$ no se puede concluir que $A=0$ o $B=0$. Ejemplo 3: Dadas la matriz $A$ y el producto $AB$ determine cu\u00e1l es la matriz $B$ A=\\left[\\begin{array}{cc} 1 & -3\\\\ -3 & 5 \\end{array}\\right] \\;\\;\\;\\;\\; AB=\\left[\\begin{array}{cc} -3 & -11\\\\ 1 & 17 \\end{array}\\right] Potencias de una Matriz Sea $A$ una matriz de $(n \\times n)$ y $k$ un entero positivo A^k=A \\cdot A \\cdot A \\cdots A=\\Pi_kA Transpuesta de una Matriz Sea una matriz $A$ de $(n \\times m)$ su traspuesta es la matriz $A^T$ de $(m \\times n)$ y est\u00e1 dado como A=\\left [\\begin{matrix} a_{11} & a_{12} & \\dots & a_{1m} \\\\ a_{21} & a_{22} & \\dots & a_{2m} \\\\ \\vdots & \\vdots & \\vdots & \\vdots \\\\ a_{n1} & a_{n2} & \\dots & a_{nm} \\end{matrix} \\right ] A^T=\\left [\\begin{matrix} a_{11} & a_{21} & \\dots & a_{n1} \\\\ a_{12} & a_{22} & \\dots & a_{n2} \\\\ \\vdots & \\vdots & \\vdots & \\vdots \\\\ a_{1m} & a_{2m} & \\dots & a_{nm} \\end{matrix} \\right ] Ejemplo 4: Si se tiene la matriz $A$ encuentre su transpuesta A=\\left[\\begin{array}{cccc} 1 & 2 & 3 & 4\\\\ 5 & 6 & 7 & 8\\\\ 9 & 10 & 11 & 12 \\end{array}\\right] A^T=\\left[\\begin{array}{ccc} 1 & 5 & 9\\\\ 2 & 6 & 10\\\\ 3 & 7 & 11\\\\ 4 & 8 & 12 \\end{array}\\right] Propiedades de la Matriz Transpuesta Sean $A$ y $B$ dos matrices de dimensiones adecuadas y $r$ un escalar. $(A^T)^T=A$ $(A+B)^T=A^T+B^T$ $(rA)^T=rA^T$ $(AB)^T=B^TA^T$ TAREA SECCI\u00d3N 2.1 1, 3, 5, 7, 11, 17, 23, 27, 31","title":"2.1 Operaciones de Matrices"},{"location":"chapter_02/21_Operaciones_de_Matrices/#2-algebra-de-matrices","text":"","title":"2. \u00c1lgebra de Matrices"},{"location":"chapter_02/21_Operaciones_de_Matrices/#21-operaciones-de-matrices","text":"A continuaci\u00f3n definiremos algunos conceptos: Supongamos la siguiente matriz de $m \\times n$ A=\\left [\\begin{matrix} a_{11} & a_{12} & \\dots & a_{1n} \\\\ a_{21} & a_{22} & \\dots & a_{2n} \\\\ \\vdots & \\vdots & \\vdots & \\vdots \\\\ a_{m1} & a_{m2} & \\dots & a_{mn} \\end{matrix} \\right ] Llamamos entradas diagonales a los t\u00e9rminos $a_{11}$, $a_{22}$, $a_{33}$, $\\dots$ y \u00e9stos forman la diagonal principal . Existen 3 tipos de matrices de $n \\times n$ de inter\u00e9s que se pueden analizar: Matriz con Entradas Diagonales Matriz identidad Matriz Cero o Nula A=\\left[\\begin{array}{cccc} * & 0 & \\dots & 0\\\\ 0 & * & \\dots & 0\\\\ \\vdots & \\vdots & \\vdots & \\vdots\\\\ 0 & 0 & \\dots & * \\end{array}\\right] I_n=\\left[\\begin{array}{cccc} 1 & 0 & \\dots & 0\\\\ 0 & 1 & \\dots & 0\\\\ \\vdots & \\vdots & \\vdots & \\vdots\\\\ 0 & 0 & \\dots & 1 \\end{array}\\right] O_n=\\left[\\begin{array}{cccc} 0 & 0 & \\dots & 0\\\\ 0 & 0 & \\dots & 0\\\\ \\vdots & \\vdots & \\vdots & \\vdots\\\\ 0 & 0 & \\dots & 0 \\end{array}\\right] Igualdad de matrices: Dos matrices son iguales si tienen las mismas dimensiones $m \\times n$ y las mismas entradas.","title":"2.1 Operaciones de Matrices"},{"location":"chapter_02/21_Operaciones_de_Matrices/#suma-de-matrices","text":"Las matrices deben de ser de la misma dimensi\u00f3n para poder realizar la suma de matrices. Se define t\u00e9rmino a t\u00e9rmino entre los t\u00e9rminos de una matriz con otra. A=\\left[\\begin{array}{ccc} 3 & -5 & -7\\\\ 2 & 1 & 9\\\\ -4 & 0 & 1 \\end{array}\\right] \\;\\;\\;\\;\\;\\; B=\\left[\\begin{array}{ccc} 1 & -3 & 0\\\\ 2 & -2 & 1\\\\ 3 & -1 & 7 \\end{array}\\right] A+B=\\left[\\begin{array}{ccc} 4 & -8 & -7\\\\ 4 & -1 & 10\\\\ -1 & -1 & 8 \\end{array}\\right] La suma de matrices no esta definida si las matrices tienen distintas dimensiones.","title":"Suma de Matrices"},{"location":"chapter_02/21_Operaciones_de_Matrices/#multiplicacion-por-escalares","text":"3A=3\\left[\\begin{array}{ccc} 3 & -5 & -7\\\\ 2 & 1 & 9\\\\ -4 & 0 & 1 \\end{array}\\right]=\\left[\\begin{array}{ccc} 9 & -15 & -21\\\\ 6 & 3 & 27\\\\ -12 & 0 & 3 \\end{array}\\right]","title":"Multiplicaci\u00f3n por Escalares"},{"location":"chapter_02/21_Operaciones_de_Matrices/#propiedades-de-la-suma-y-multiplicacion-por-escalares","text":"Sean $A$, $B$, $C$ matrices de $(m \\times n)$ y $r$, $s$ escalares. $A+B=B+A$ $(A+B)+C=A+(B+C)$ $A+O=A$ $r(A+B)=rA+rB$ $(r+s)A=rA+sA$ $r(sA)=(rs)A$","title":"Propiedades de la Suma y Multiplicaci\u00f3n por Escalares"},{"location":"chapter_02/21_Operaciones_de_Matrices/#multiplicacion-de-matrices","text":"","title":"Multiplicaci\u00f3n de Matrices"},{"location":"chapter_02/21_Operaciones_de_Matrices/#como-una-transformacion-de-matrices","text":"Podemos recordar que la matriz $A$ era una transformaci\u00f3n o mapeo de un espacio a otro, con este concepto podemos extrapolar al caso de tener otra matriz $B$ tal que $BA$ como se muestra en la figura: El producto $A(B\\boldsymbol{x})$ es una composici\u00f3n de mapeos.","title":"Como una transformaci\u00f3n de matrices"},{"location":"chapter_02/21_Operaciones_de_Matrices/#como-una-combinacion-lineal","text":"Estaremos partiendo de la definici\u00f3n de combinaci\u00f3n lineal con el producto matricial $A\\boldsymbol{x}$ A \\boldsymbol{x}=\\left[\\boldsymbol{a_1} \\boldsymbol{a_2} \\boldsymbol{\\dots} \\boldsymbol{a_p} \\right]\\left[\\begin{array}{c} x_1\\\\ x_2\\\\ \\vdots \\\\x_3 \\end{array}\\right]=x_1\\boldsymbol{a_1}+x_2\\boldsymbol{a_2}+\\dots +x_p\\boldsymbol{a_p} Ahora multiplicaremos por la matriz $B$ B(A \\boldsymbol{x})=B(x_1\\boldsymbol{a_1}+x_2\\boldsymbol{a_2}+\\dots +x_p\\boldsymbol{a_p}) \\;\\;\\;\\;\\; \\;\\;\\;\\;\\;\\ =Bx_1\\boldsymbol{a_1}+Bx_2\\boldsymbol{a_2}+\\dots +Bx_p\\boldsymbol{a_p} \\;\\;\\;\\;\\; \\;\\;\\;\\;\\;\\ =x_1B\\boldsymbol{a_1}+x_2B\\boldsymbol{a_2}+\\dots +x_pB\\boldsymbol{a_p} \\;\\;\\;\\;\\; \\;\\;\\;\\;\\;\\ =\\left[B\\boldsymbol{a_1} B\\boldsymbol{a_2} \\boldsymbol{\\dots} B\\boldsymbol{a_p} \\right]\\left[\\begin{array}{c} x_1\\\\ x_2\\\\ \\vdots \\\\x_3 \\end{array}\\right] Con esto se puede notar que el producto $AB =\\left[B\\boldsymbol{a_1} B\\boldsymbol{a_2} \\boldsymbol{\\dots} B\\boldsymbol{a_p} \\right]$ con $A$ de $(m \\times n)$ y $B$ de $(n \\times p)$. Observe que el producto $B\\boldsymbol{a_n}$ es una combinaci\u00f3n lineal de las columnas de $B$ usando coeficientes de la columna correspondiente de $A$. Ejemplo 1: Dadas las matrices $A$ y $B$ encuentre el producto de $AB$ como la combinaci\u00f3n de las columnas de $A$ con los coeficientes de la columna correspondiente de $B$. A=\\left[\\begin{array}{cc} 2 & 3\\\\ 1 & -5 \\end{array}\\right] \\;\\;\\;\\;\\; B=\\left[\\begin{array}{ccc} 4 & 3 & 6\\\\ 1 & -2 & 3 \\end{array}\\right] Si sabemos que AB = [A\\boldsymbol{b_1} \\;\\;A\\boldsymbol{b_2} \\;\\; A\\boldsymbol{b_3}] Se puede trabajar cada combinaci\u00f3n de las columnas A\\boldsymbol{b_1}=\\left[\\begin{array}{cc} 2 & 3\\\\ 1 & -5 \\end{array}\\right]\\left[\\begin{array}{c} 4\\\\ 1 \\end{array}\\right]=\\left[\\begin{array}{c} 11\\\\ -1 \\end{array}\\right] A\\boldsymbol{b_2}=\\left[\\begin{array}{cc} 2 & 3\\\\ 1 & -5 \\end{array}\\right]\\left[\\begin{array}{c} 3\\\\ -2 \\end{array}\\right]=\\left[\\begin{array}{c} 0\\\\ 13 \\end{array}\\right] A\\boldsymbol{b_3}=\\left[\\begin{array}{cc} 2 & 3\\\\ 1 & -5 \\end{array}\\right]\\left[\\begin{array}{c} 6\\\\ 3 \\end{array}\\right]=\\left[\\begin{array}{c} 21\\\\ -9 \\end{array}\\right] Finalmente el producto $AB$ ser\u00e1 AB = \\left[\\begin{array}{ccc} 11 & 0 & 21\\\\ -1 & 13 & -9 \\end{array}\\right]","title":"Como una combinaci\u00f3n lineal"},{"location":"chapter_02/21_Operaciones_de_Matrices/#regla-fila-columna","text":"Sean $A$ de $(2 \\times 2)$ y $B$ de $(2 \\times 3)$ dos matrices como las que se muestran a continuaci\u00f3n A=\\left[\\begin{array}{cc} a_{11} & a_{12}\\\\ a_{21} & a_{22} \\end{array}\\right] \\;\\;\\;\\;\\; B=\\left[\\begin{array}{ccc} b_{11} & b_{12} & b_{13}\\\\ b_{21} & b_{22} & b_{23} \\end{array}\\right] El producto $AB$ se puede calcular como AB=\\left[\\begin{array}{cc} a_{11} & a_{12}\\\\ a_{21} & a_{22} \\end{array}\\right] \\left[\\begin{array}{ccc} b_{11} & b_{12} & b_{13}\\\\ b_{21} & b_{22} & b_{23} \\end{array}\\right]=\\left[\\begin{array}{ccc} a_{11}b_{11}+a_{12}b_{21} & a_{11}b_{12}+a_{12}b_{22} & a_{11}b_{13}+a_{12}b_{23}\\\\ a_{21}b_{11}+a_{22}b_{21} & a_{21}b_{12}+a_{22}b_{22} & a_{21}b_{13}+a_{22}b_{23} \\end{array}\\right] Ejemplo 2: Encuentre el producto $AB$ del Ejemplo 1 por medio de la regla fila columna.","title":"Regla Fila Columna"},{"location":"chapter_02/21_Operaciones_de_Matrices/#calculo-de-algunos-elementos-de-ab","text":"Definiremos la fila $i$ de una matriz $A$ como $\\boldsymbol{a_{i,*}}$ o $\\boldsymbol{a_{i,:}}$ en la cual la segunda notaci\u00f3n da preferencia a ser mejor interpretada en un lenguaje de programaci\u00f3n. Usualmente hemos definido, la columna $j$ de $A$ como $\\boldsymbol{a_{j}}$, sin embargo si deseamos mantener consistencia, tambi\u00e9n puede ser escrito como $\\boldsymbol{a_{*,j}}$ o $\\boldsymbol{a_{:,j}}$. El elemento $i$, $j$ de la matriz $A$ se puede expresar como $a_{i,j}$. Esta representaci\u00f3n depender\u00e1 mucho del contexto en que se usen. Sea $C=AB$ podemos calcular los siguientes valores: Fila $i$ de $AB$ Columna $j$ de $AB$ Elemento $i$, $j$ de $AB$ \\boldsymbol{c}_{i,:}=\\boldsymbol{a_{i,:}}B \\boldsymbol{c}_{:,j}=A\\boldsymbol{b_{:,j}} $c_{i,j}=\\boldsymbol{a_{i,:}}\\boldsymbol{b_{:,j}}$","title":"C\u00e1lculo de algunos elementos de $AB$"},{"location":"chapter_02/21_Operaciones_de_Matrices/#propiedades-de-la-multiplicacion-de-matrices","text":"Sea $A$ una matriz de $(m \\times n)$, $B$ , $C$ matrices con tama\u00f1os adecuados y $r$ un escalar. Adem\u00e1s sean $I_m$ e $I_n$ la matriz identidad de $(m \\times m)$ y $(n \\times n)$ respectivamente. $A(BC)=(AB)C$ $A(B+C)=AB+AC$ $(B+C)A=BA+CA$ $r(AB)=(rA)B=A(rB)$ $I_mA=A=AI_n$","title":"Propiedades de la Multiplicaci\u00f3n de Matrices"},{"location":"chapter_02/21_Operaciones_de_Matrices/#advertencias","text":"En forma general $AB \\neq BA$, sin embargo si sucediera se dice que $A$ y $B$ son matrices que se conmutan. Si $AB=AC$ no implica que $B=C$. No se pueden \"cancelar\" las matrices $A$. Si $AB=0$ no se puede concluir que $A=0$ o $B=0$. Ejemplo 3: Dadas la matriz $A$ y el producto $AB$ determine cu\u00e1l es la matriz $B$ A=\\left[\\begin{array}{cc} 1 & -3\\\\ -3 & 5 \\end{array}\\right] \\;\\;\\;\\;\\; AB=\\left[\\begin{array}{cc} -3 & -11\\\\ 1 & 17 \\end{array}\\right]","title":"Advertencias"},{"location":"chapter_02/21_Operaciones_de_Matrices/#potencias-de-una-matriz","text":"Sea $A$ una matriz de $(n \\times n)$ y $k$ un entero positivo A^k=A \\cdot A \\cdot A \\cdots A=\\Pi_kA","title":"Potencias de una Matriz"},{"location":"chapter_02/21_Operaciones_de_Matrices/#transpuesta-de-una-matriz","text":"Sea una matriz $A$ de $(n \\times m)$ su traspuesta es la matriz $A^T$ de $(m \\times n)$ y est\u00e1 dado como A=\\left [\\begin{matrix} a_{11} & a_{12} & \\dots & a_{1m} \\\\ a_{21} & a_{22} & \\dots & a_{2m} \\\\ \\vdots & \\vdots & \\vdots & \\vdots \\\\ a_{n1} & a_{n2} & \\dots & a_{nm} \\end{matrix} \\right ] A^T=\\left [\\begin{matrix} a_{11} & a_{21} & \\dots & a_{n1} \\\\ a_{12} & a_{22} & \\dots & a_{n2} \\\\ \\vdots & \\vdots & \\vdots & \\vdots \\\\ a_{1m} & a_{2m} & \\dots & a_{nm} \\end{matrix} \\right ] Ejemplo 4: Si se tiene la matriz $A$ encuentre su transpuesta A=\\left[\\begin{array}{cccc} 1 & 2 & 3 & 4\\\\ 5 & 6 & 7 & 8\\\\ 9 & 10 & 11 & 12 \\end{array}\\right] A^T=\\left[\\begin{array}{ccc} 1 & 5 & 9\\\\ 2 & 6 & 10\\\\ 3 & 7 & 11\\\\ 4 & 8 & 12 \\end{array}\\right]","title":"Transpuesta de una Matriz"},{"location":"chapter_02/21_Operaciones_de_Matrices/#propiedades-de-la-matriz-transpuesta","text":"Sean $A$ y $B$ dos matrices de dimensiones adecuadas y $r$ un escalar. $(A^T)^T=A$ $(A+B)^T=A^T+B^T$ $(rA)^T=rA^T$ $(AB)^T=B^TA^T$ TAREA SECCI\u00d3N 2.1 1, 3, 5, 7, 11, 17, 23, 27, 31","title":"Propiedades de la Matriz Transpuesta"},{"location":"chapter_02/22_Inversa_de_una_Matriz/","text":"2. \u00c1lgebra de Matrices 2.2 Inversa de una Matriz Existe una matriz $C$ tal que al multiplicarse por la matriz $A$ se cumple que CA=I \\;\\;\\;\\;\\; AC=I a esta matriz $C$ se le denomina matriz inversa de $A$ y se escribe como $A^{-1}$. Formalmente cumple con A^{-1}A=I \\;\\;\\;\\;\\; AA^{-1}=I La matriz debe de ser cuadrada, es decir de $(n \\times n)$. A veces se dice que: una matriz invertible es una matriz no singular una matriz no invertible es una matriz singular Inversa de una Matriz de $2 \\times 2$ Una matriz de $2 \\times 2$ tendr\u00e1 inversa si su determinante no es cero. El determinante de una matriz $A$ de $2 \\times 2$ es A=\\left[\\begin{array}{cc} a & b\\\\ c & d \\end{array}\\right] det(A)=ad-cb La matriz $A^{-1}$ estar\u00e1 dada por A^{-1}=\\frac{1}{det(A)}\\left[\\begin{array}{cc} d & -b\\\\ -c & a \\end{array}\\right] Ejemplo 1: Encuentre la inversa de la matriz $A$ A=\\left[\\begin{array}{cc} 3 & 2\\\\ 8 & 5 \\end{array}\\right] Primero encontraremos el determinante de la matriz $A$ det(A)=3\\cdot5-8\\cdot2=-1 Como el determinante es distinto de cero es posible encontrar la inversa de la matriz $A$ A^{-1}=\\frac{1}{-1}\\left[\\begin{array}{cc} 5 & -2\\\\ -8 & 3 \\end{array}\\right]=\\left[\\begin{array}{cc} -5 & 2\\\\ 8 & -3 \\end{array}\\right] Soluci\u00f3n de la Ecuaci\u00f3n $A\\boldsymbol{x}=\\boldsymbol{b}$ por medio de la Inversa $A^{-1}$ Si se tiene el sistema A\\boldsymbol{x}=\\boldsymbol{b} y se aplica la matriz inversa $A^{-1}$ A^{-1}(A\\boldsymbol{x})=A^{-1}\\boldsymbol{b} (A^{-1}A)\\boldsymbol{x}=A^{-1}\\boldsymbol{b} I\\boldsymbol{x}=A^{-1}\\boldsymbol{b} \\boldsymbol{x}=A^{-1}\\boldsymbol{b} Por lo tanto, el sistema puede ser resuelto si se obtiene $A^{-1}\\boldsymbol{b}$. Ejemplo 2: Resolver el siguiente sistema por medio de $A^{-1}$ 7x_1+3x_2=-9 -6x_1-3x_2=4 Propiedades de las Matrices Invertibles Sean $A$, $B$ matrices con inversas $A^{-1}$ y $B^{-1}$ respectivamente. $(A^{-1})^{-1}=A$ $(AB)^{-1}=B^{-1}A^{-1}$ $(A^T)^{-1}=(A^{-1})^T$ Inversa de una Matriz de $n \\times n$ Considere la matriz $A$ y la matriz identidad $I=\\left[\\boldsymbol{e_1} \\;\\; \\boldsymbol{e_2} \\;\\; \\cdots \\;\\; \\boldsymbol{e_n} \\right]$ de $(n \\times n)$. Es posible encontrar la soluci\u00f3n a las ecuaciones $\\left [A \\;\\;\\boldsymbol{e_1} \\right]$, $\\left [A \\;\\;\\boldsymbol{e_2} \\right]$, $\\cdots$ , $\\left [A \\;\\;\\boldsymbol{e_n} \\right]$ por medio de su matriz aumentada. Ahora observe que se pudo haber escrito como \\left [A \\;\\;\\boldsymbol{e_1} \\;\\; \\boldsymbol{e_2} \\cdots \\;\\;\\boldsymbol{e_1}\\right]=\\left [A \\;\\;I \\right] Si a este sistema se le aplican operaciones por fila hasta llevarlo a la forma $\\left [I \\;\\; A^{-1} \\right]$ es posible encontrar $A^{-1} $. Por lo que, la inversa de una matriz puede ser encontrada como \\left [A \\;\\;I \\right] \\sim \\left [I \\;\\; A^{-1} \\right] Ejemplo 3: Encuentre la matriz inversa de $A$ A=\\left[\\begin{array}{ccc} 1 & -3 & 4\\\\ 2 & -5 & 7\\\\ 0 & -1 & -1 \\end{array}\\right] Matriz Elemental Es aquella matriz que se obtiene al realizar una \u00fanica operaci\u00f3n elemental de fila sobe una matriz identidad. Es decir que cumple con ser de la forma I \\sim E Por ejemplo tenemos I \\sim E_1 I \\sim E_2 I \\sim E_3 \\left[\\begin{array}{ccc} 1 & 0 & 0\\\\ 0 & 1 & -5\\\\ 0 & 0 & 1 \\end{array}\\right] \\left[\\begin{array}{ccc} 1 & 0 & 0\\\\ 0 & 0 & 1\\\\ 0 & 1 & 0 \\end{array}\\right] \\left[\\begin{array}{ccc} 1 & 0 & 0\\\\ 0 & 1 & 0\\\\ 2 & 0 & 1 \\end{array}\\right] -5R_3+R_2\\rightarrow R_2 R_2 \\leftrightarrow R_3 2R_1 +R_3\\rightarrow R_3 Ahora veamos el efecto que estas matrices $E_1$, $E_2$ y $E_3$ tienen sobre una matriz $A$. A= \\left[\\begin{array}{ccc} a & b & c\\\\ d & e & f\\\\ g & h & i \\end{array}\\right] E_1A=\\left[\\begin{array}{ccc} a & b & c\\\\ d & e & f\\\\ g & h & i \\end{array}\\right]\\left[\\begin{array}{ccc} 1 & 0 & 0\\\\ 0 & 1 & -5\\\\ 0 & 0 & 1 \\end{array}\\right]=\\left[\\begin{array}{ccc} a & b & c\\\\ d-5g & e-5h & f-5i\\\\ g & h & i \\end{array}\\right] E_2A=\\left[\\begin{array}{ccc} a & b & c\\\\ d & e & f\\\\ g & h & i \\end{array}\\right]\\left[\\begin{array}{ccc} 1 & 0 & 0\\\\ 0 & 0 & 1\\\\ 0 & 1 & 0 \\end{array}\\right]=\\left[\\begin{array}{ccc} a & b & c\\\\ g & h & i\\\\ d & e & f \\end{array}\\right] E_3A=\\left[\\begin{array}{ccc} a & b & c\\\\ d & e & f\\\\ g & h & i \\end{array}\\right]\\left[\\begin{array}{ccc} 1 & 0 & 0\\\\ 0 & 1 & 0\\\\ 2 & 0 & 1 \\end{array}\\right]=\\left[\\begin{array}{ccc} a & b & c\\\\ d & e & f\\\\ 2a+g & 2b+h & 2c+i \\end{array}\\right] Se puede observar que las operaciones entre filas se pueden hacer con multiplicaciones entre matrices de la forma $EA$ donde $E$ se genera al aplicar una transformaci\u00f3n de fila a $I$. Ejemplo 4: Encuentre la inversa de la matriz $E_1$ E_1=\\left[\\begin{array}{ccc} 1 & 0 & 0\\\\ 0 & 1 & -5\\\\ 0 & 0 & 1 \\end{array}\\right] Matriz At\u00f3mica Se conoce como matriz at\u00f3mica a aquella matriz triangular que posee una entrada principal en la cual los elementos debajo de ella no son cero. Estas matrices tienen la caracter\u00edstica de poseer una matriz inversa f\u00e1cil de calcular. Sea la matriz at\u00f3mica $E$ E=\\left[\\begin{array}{cccc} 1 & 0 & 0 & 0\\\\ 2 & 1 & 0 & 0\\\\ 0 & 0 & 1 & 0\\\\ 4 & 0 & 0 & 1 \\end{array}\\right] Su inversa est\u00e1 dada como E^{-1}=\\left[\\begin{array}{cccc} 1 & 0 & 0 & 0\\\\ -2 & 1 & 0 & 0\\\\ 0 & 0 & 1 & 0\\\\ -4 & 0 & 0 & 1 \\end{array}\\right] Matriz Inversa por medio de Matrices Elementales Anteriormente se comprob\u00f3 que la inversa de una matriz puede ser encontrada como \\left [A \\;\\;I \\right] \\sim \\left [I \\;\\; A^{-1} \\right] Por lo que si $A$ es equivalente por filas a $I$ existe una secuencia de operaciones fundamentales de fila que reduce a $A$ en $I$ e $I$ en $A$. La aplicaci\u00f3n de una serie de secuencias de operaciones fundamentales puede ser escrita como A \\sim E_1A \\sim E_2(E_1A) \\sim E_3(E_2E_1A) \\sim \\cdots \\sim E_p(E_{p-1}\\dots E_1A)=I Por lo que al final E_pE_{p-1}\\dots E_1A=I (E_pE_{p-1}\\dots E_1)A=I (E_pE_{p-1}\\dots E_1)^{-1}(E_pE_{p-1}\\dots E_1)A=(E_pE_{p-1}\\dots E_1)^{-1}I A=(E_pE_{p-1}\\dots E_1)^{-1} La matriz inversa puede ser obtenida como A^{-1}=((E_pE_{p-1}\\dots E_1)^{-1})^{-1} A^{-1}=E_pE_{p-1}\\dots E_1 Este concepto ser\u00e1 muy \u00fatil para la descomposici\u00f3n LU de la secci\u00f3n 2.5. TAREA SECCI\u00d3N 2.2 1, 3, 7, 25, 29, 31, 33, 35","title":"2.2 Inversa de una Matriz"},{"location":"chapter_02/22_Inversa_de_una_Matriz/#2-algebra-de-matrices","text":"","title":"2. \u00c1lgebra de Matrices"},{"location":"chapter_02/22_Inversa_de_una_Matriz/#22-inversa-de-una-matriz","text":"Existe una matriz $C$ tal que al multiplicarse por la matriz $A$ se cumple que CA=I \\;\\;\\;\\;\\; AC=I a esta matriz $C$ se le denomina matriz inversa de $A$ y se escribe como $A^{-1}$. Formalmente cumple con A^{-1}A=I \\;\\;\\;\\;\\; AA^{-1}=I La matriz debe de ser cuadrada, es decir de $(n \\times n)$. A veces se dice que: una matriz invertible es una matriz no singular una matriz no invertible es una matriz singular","title":"2.2 Inversa de una Matriz"},{"location":"chapter_02/22_Inversa_de_una_Matriz/#inversa-de-una-matriz-de-2-times-2","text":"Una matriz de $2 \\times 2$ tendr\u00e1 inversa si su determinante no es cero. El determinante de una matriz $A$ de $2 \\times 2$ es A=\\left[\\begin{array}{cc} a & b\\\\ c & d \\end{array}\\right] det(A)=ad-cb La matriz $A^{-1}$ estar\u00e1 dada por A^{-1}=\\frac{1}{det(A)}\\left[\\begin{array}{cc} d & -b\\\\ -c & a \\end{array}\\right] Ejemplo 1: Encuentre la inversa de la matriz $A$ A=\\left[\\begin{array}{cc} 3 & 2\\\\ 8 & 5 \\end{array}\\right] Primero encontraremos el determinante de la matriz $A$ det(A)=3\\cdot5-8\\cdot2=-1 Como el determinante es distinto de cero es posible encontrar la inversa de la matriz $A$ A^{-1}=\\frac{1}{-1}\\left[\\begin{array}{cc} 5 & -2\\\\ -8 & 3 \\end{array}\\right]=\\left[\\begin{array}{cc} -5 & 2\\\\ 8 & -3 \\end{array}\\right]","title":"Inversa de una Matriz de $2 \\times 2$"},{"location":"chapter_02/22_Inversa_de_una_Matriz/#solucion-de-la-ecuacion-aboldsymbolxboldsymbolb-por-medio-de-la-inversa-a-1","text":"Si se tiene el sistema A\\boldsymbol{x}=\\boldsymbol{b} y se aplica la matriz inversa $A^{-1}$ A^{-1}(A\\boldsymbol{x})=A^{-1}\\boldsymbol{b} (A^{-1}A)\\boldsymbol{x}=A^{-1}\\boldsymbol{b} I\\boldsymbol{x}=A^{-1}\\boldsymbol{b} \\boldsymbol{x}=A^{-1}\\boldsymbol{b} Por lo tanto, el sistema puede ser resuelto si se obtiene $A^{-1}\\boldsymbol{b}$. Ejemplo 2: Resolver el siguiente sistema por medio de $A^{-1}$ 7x_1+3x_2=-9 -6x_1-3x_2=4","title":"Soluci\u00f3n de la Ecuaci\u00f3n $A\\boldsymbol{x}=\\boldsymbol{b}$ por medio de la Inversa $A^{-1}$"},{"location":"chapter_02/22_Inversa_de_una_Matriz/#propiedades-de-las-matrices-invertibles","text":"Sean $A$, $B$ matrices con inversas $A^{-1}$ y $B^{-1}$ respectivamente. $(A^{-1})^{-1}=A$ $(AB)^{-1}=B^{-1}A^{-1}$ $(A^T)^{-1}=(A^{-1})^T$","title":"Propiedades de las Matrices Invertibles"},{"location":"chapter_02/22_Inversa_de_una_Matriz/#inversa-de-una-matriz-de-n-times-n","text":"Considere la matriz $A$ y la matriz identidad $I=\\left[\\boldsymbol{e_1} \\;\\; \\boldsymbol{e_2} \\;\\; \\cdots \\;\\; \\boldsymbol{e_n} \\right]$ de $(n \\times n)$. Es posible encontrar la soluci\u00f3n a las ecuaciones $\\left [A \\;\\;\\boldsymbol{e_1} \\right]$, $\\left [A \\;\\;\\boldsymbol{e_2} \\right]$, $\\cdots$ , $\\left [A \\;\\;\\boldsymbol{e_n} \\right]$ por medio de su matriz aumentada. Ahora observe que se pudo haber escrito como \\left [A \\;\\;\\boldsymbol{e_1} \\;\\; \\boldsymbol{e_2} \\cdots \\;\\;\\boldsymbol{e_1}\\right]=\\left [A \\;\\;I \\right] Si a este sistema se le aplican operaciones por fila hasta llevarlo a la forma $\\left [I \\;\\; A^{-1} \\right]$ es posible encontrar $A^{-1} $. Por lo que, la inversa de una matriz puede ser encontrada como \\left [A \\;\\;I \\right] \\sim \\left [I \\;\\; A^{-1} \\right] Ejemplo 3: Encuentre la matriz inversa de $A$ A=\\left[\\begin{array}{ccc} 1 & -3 & 4\\\\ 2 & -5 & 7\\\\ 0 & -1 & -1 \\end{array}\\right]","title":"Inversa de una Matriz de $n \\times n$"},{"location":"chapter_02/22_Inversa_de_una_Matriz/#matriz-elemental","text":"Es aquella matriz que se obtiene al realizar una \u00fanica operaci\u00f3n elemental de fila sobe una matriz identidad. Es decir que cumple con ser de la forma I \\sim E Por ejemplo tenemos I \\sim E_1 I \\sim E_2 I \\sim E_3 \\left[\\begin{array}{ccc} 1 & 0 & 0\\\\ 0 & 1 & -5\\\\ 0 & 0 & 1 \\end{array}\\right] \\left[\\begin{array}{ccc} 1 & 0 & 0\\\\ 0 & 0 & 1\\\\ 0 & 1 & 0 \\end{array}\\right] \\left[\\begin{array}{ccc} 1 & 0 & 0\\\\ 0 & 1 & 0\\\\ 2 & 0 & 1 \\end{array}\\right] -5R_3+R_2\\rightarrow R_2 R_2 \\leftrightarrow R_3 2R_1 +R_3\\rightarrow R_3 Ahora veamos el efecto que estas matrices $E_1$, $E_2$ y $E_3$ tienen sobre una matriz $A$. A= \\left[\\begin{array}{ccc} a & b & c\\\\ d & e & f\\\\ g & h & i \\end{array}\\right] E_1A=\\left[\\begin{array}{ccc} a & b & c\\\\ d & e & f\\\\ g & h & i \\end{array}\\right]\\left[\\begin{array}{ccc} 1 & 0 & 0\\\\ 0 & 1 & -5\\\\ 0 & 0 & 1 \\end{array}\\right]=\\left[\\begin{array}{ccc} a & b & c\\\\ d-5g & e-5h & f-5i\\\\ g & h & i \\end{array}\\right] E_2A=\\left[\\begin{array}{ccc} a & b & c\\\\ d & e & f\\\\ g & h & i \\end{array}\\right]\\left[\\begin{array}{ccc} 1 & 0 & 0\\\\ 0 & 0 & 1\\\\ 0 & 1 & 0 \\end{array}\\right]=\\left[\\begin{array}{ccc} a & b & c\\\\ g & h & i\\\\ d & e & f \\end{array}\\right] E_3A=\\left[\\begin{array}{ccc} a & b & c\\\\ d & e & f\\\\ g & h & i \\end{array}\\right]\\left[\\begin{array}{ccc} 1 & 0 & 0\\\\ 0 & 1 & 0\\\\ 2 & 0 & 1 \\end{array}\\right]=\\left[\\begin{array}{ccc} a & b & c\\\\ d & e & f\\\\ 2a+g & 2b+h & 2c+i \\end{array}\\right] Se puede observar que las operaciones entre filas se pueden hacer con multiplicaciones entre matrices de la forma $EA$ donde $E$ se genera al aplicar una transformaci\u00f3n de fila a $I$. Ejemplo 4: Encuentre la inversa de la matriz $E_1$ E_1=\\left[\\begin{array}{ccc} 1 & 0 & 0\\\\ 0 & 1 & -5\\\\ 0 & 0 & 1 \\end{array}\\right]","title":"Matriz Elemental"},{"location":"chapter_02/22_Inversa_de_una_Matriz/#matriz-atomica","text":"Se conoce como matriz at\u00f3mica a aquella matriz triangular que posee una entrada principal en la cual los elementos debajo de ella no son cero. Estas matrices tienen la caracter\u00edstica de poseer una matriz inversa f\u00e1cil de calcular. Sea la matriz at\u00f3mica $E$ E=\\left[\\begin{array}{cccc} 1 & 0 & 0 & 0\\\\ 2 & 1 & 0 & 0\\\\ 0 & 0 & 1 & 0\\\\ 4 & 0 & 0 & 1 \\end{array}\\right] Su inversa est\u00e1 dada como E^{-1}=\\left[\\begin{array}{cccc} 1 & 0 & 0 & 0\\\\ -2 & 1 & 0 & 0\\\\ 0 & 0 & 1 & 0\\\\ -4 & 0 & 0 & 1 \\end{array}\\right]","title":"Matriz At\u00f3mica"},{"location":"chapter_02/22_Inversa_de_una_Matriz/#matriz-inversa-por-medio-de-matrices-elementales","text":"Anteriormente se comprob\u00f3 que la inversa de una matriz puede ser encontrada como \\left [A \\;\\;I \\right] \\sim \\left [I \\;\\; A^{-1} \\right] Por lo que si $A$ es equivalente por filas a $I$ existe una secuencia de operaciones fundamentales de fila que reduce a $A$ en $I$ e $I$ en $A$. La aplicaci\u00f3n de una serie de secuencias de operaciones fundamentales puede ser escrita como A \\sim E_1A \\sim E_2(E_1A) \\sim E_3(E_2E_1A) \\sim \\cdots \\sim E_p(E_{p-1}\\dots E_1A)=I Por lo que al final E_pE_{p-1}\\dots E_1A=I (E_pE_{p-1}\\dots E_1)A=I (E_pE_{p-1}\\dots E_1)^{-1}(E_pE_{p-1}\\dots E_1)A=(E_pE_{p-1}\\dots E_1)^{-1}I A=(E_pE_{p-1}\\dots E_1)^{-1} La matriz inversa puede ser obtenida como A^{-1}=((E_pE_{p-1}\\dots E_1)^{-1})^{-1} A^{-1}=E_pE_{p-1}\\dots E_1 Este concepto ser\u00e1 muy \u00fatil para la descomposici\u00f3n LU de la secci\u00f3n 2.5. TAREA SECCI\u00d3N 2.2 1, 3, 7, 25, 29, 31, 33, 35","title":"Matriz Inversa por medio de Matrices Elementales"},{"location":"chapter_02/23_Caracterizaciones_de_Matrices_Invertibles/","text":"2. \u00c1lgebra de Matrices 2.3 Caracterizaciones de Matrices Invertibles El teorema de la matriz invertible Sea $A$ una matriz cuadrada de $n \\times n$. Entonces, los siguientes enunciados son equivalentes. Es decir, para una $A$ dada, los enunciados son todos ciertos o todos falsos. $A$ es una matriz invertible. $A$ es equivalente por filas a la matriz identidad $I_n$ $A$ tiene $n$ posiciones pivote. La ecuaci\u00f3n $A\\boldsymbol{x}=\\boldsymbol{0}$ tiene solamente la soluci\u00f3n trivial. Las columnas de $A$ forman un conjunto linealmente independiente. La transformaci\u00f3n lineal $\\boldsymbol{x}\\rightarrow A\\boldsymbol{x}$ es uno a uno. La ecuaci\u00f3n $A\\boldsymbol{x}=\\boldsymbol{b}$ tiene al menos una soluci\u00f3n para toda $\\boldsymbol{b}$ en $\\mathbb{R}^n$. Las columnas de $A$ generan $\\mathbb{R}^n$. La transformaci\u00f3n lineal $\\boldsymbol{x}\\rightarrow A\\boldsymbol{x}$ mapea $\\mathbb{R}^n$ sobre $\\mathbb{R}^n$. Existe una matriz $C$ de $n \\times n$ tal que $CA=I$, Existe una matriz $D$ de $n \\times n$ tal que $AD= I$, $A^T$es una matriz invertible. Ejemplo 1: Sea la matriz $A$ describa como cumple con el teorema de la matriz invertible. A=\\left[\\begin{array}{cccc} 3 & 4 & 7 & 8\\\\ 0 & 1 & 4 & 6\\\\ 0 & 0 & 2 & 4\\\\ 0 & 0 & 0 & 1 \\end{array}\\right] Al aplicar reducciones por fila se comprueba que $A$ tiene una matriz inversa A^{-1}=\\left[\\begin{array}{cccc} \\frac{1}{3} & -\\frac{4}{3} & \\frac{3}{2} & -\\frac{2}{3}\\\\ 0 & 1 & -2 & 2\\\\ 0 & 0 & \\frac{1}{2} & -2\\\\ 0 & 0 & 0 & 1 \\end{array}\\right] Si tiene inversa se puede llevar a la forma $I_n$ Se observa que en su forma escalonada tiene 4 posiciones pivote. Al tener 4 pivotes solo puede tener soluci\u00f3n trivial. Las columnas de $A$ son linealmente independientes pues no se puede construir alguna columna de $A$ con la combinaci\u00f3n de otras columnas de $A$. Cualquier vector $\\boldsymbol{x}$ que sea multiplicado con $A$ para hacer $A\\boldsymbol{x}$ ser\u00e1 \u00fanico. Cada valor de $\\boldsymbol{b}$ es \u00fanico, y debi\u00f3 de ser mapeado por $A$ como un vector $\\boldsymbol{x}$. Al tener 4 pivotes en $A$ se comprueba que $A$ genera en $\\mathbb{R}^4$. Tanto $\\boldsymbol{x}$ como $A\\boldsymbol{x}$ se encuentran en el mismo espacio $\\mathbb{R}^4$. Al existir una inversa para $A$ existe una matriz $C=A^{-1}$ que hace que $CA=I$. Al existir una inversa para $A$ existe una matriz $D=A^{-1}$ que hace que $AD=I$. La matriz transpuesta de $A$ es A^T=\\left[\\begin{array}{cccc} 3 & 0 & 0 & 0\\\\ 4 & 1 & 0 & 0\\\\ 7 & 4 & 2 & 0\\\\ 8 & 6 & 4 & 1 \\end{array}\\right] la cual cumple con tener 4 posiciones pivote por lo que cumple con tener inversa. Trasformaciones Lineales Invertibles Se dice que una transformaci\u00f3n lineal $T: \\mathbb{R}^n \\rightarrow \\mathbb{R}^n$ es invertible si existe una funci\u00f3n $S: \\mathbb{R}^n \\rightarrow \\mathbb{R}^n$ tal que S \\left( T\\left(\\boldsymbol{x} \\right)\\right)=\\boldsymbol{x} T \\left( S\\left(\\boldsymbol{x} \\right)\\right)=\\boldsymbol{x} Adem\u00e1s, como hemos definido a $T(\\boldsymbol{x})=A\\boldsymbol{x}$ S \\left( T\\left(\\boldsymbol{x} \\right)\\right)= S(A\\boldsymbol{x})=A^{-1}A\\boldsymbol{x}=I\\boldsymbol{x}=\\boldsymbol{x} TAREA SECCI\u00d3N 2.3 1, 3, 7, 33, 34, 39","title":"2.3 Caracterizaci\u00f3n de Matrices"},{"location":"chapter_02/23_Caracterizaciones_de_Matrices_Invertibles/#2-algebra-de-matrices","text":"","title":"2. \u00c1lgebra de Matrices"},{"location":"chapter_02/23_Caracterizaciones_de_Matrices_Invertibles/#23-caracterizaciones-de-matrices-invertibles","text":"","title":"2.3 Caracterizaciones de Matrices Invertibles"},{"location":"chapter_02/23_Caracterizaciones_de_Matrices_Invertibles/#el-teorema-de-la-matriz-invertible","text":"Sea $A$ una matriz cuadrada de $n \\times n$. Entonces, los siguientes enunciados son equivalentes. Es decir, para una $A$ dada, los enunciados son todos ciertos o todos falsos. $A$ es una matriz invertible. $A$ es equivalente por filas a la matriz identidad $I_n$ $A$ tiene $n$ posiciones pivote. La ecuaci\u00f3n $A\\boldsymbol{x}=\\boldsymbol{0}$ tiene solamente la soluci\u00f3n trivial. Las columnas de $A$ forman un conjunto linealmente independiente. La transformaci\u00f3n lineal $\\boldsymbol{x}\\rightarrow A\\boldsymbol{x}$ es uno a uno. La ecuaci\u00f3n $A\\boldsymbol{x}=\\boldsymbol{b}$ tiene al menos una soluci\u00f3n para toda $\\boldsymbol{b}$ en $\\mathbb{R}^n$. Las columnas de $A$ generan $\\mathbb{R}^n$. La transformaci\u00f3n lineal $\\boldsymbol{x}\\rightarrow A\\boldsymbol{x}$ mapea $\\mathbb{R}^n$ sobre $\\mathbb{R}^n$. Existe una matriz $C$ de $n \\times n$ tal que $CA=I$, Existe una matriz $D$ de $n \\times n$ tal que $AD= I$, $A^T$es una matriz invertible. Ejemplo 1: Sea la matriz $A$ describa como cumple con el teorema de la matriz invertible. A=\\left[\\begin{array}{cccc} 3 & 4 & 7 & 8\\\\ 0 & 1 & 4 & 6\\\\ 0 & 0 & 2 & 4\\\\ 0 & 0 & 0 & 1 \\end{array}\\right] Al aplicar reducciones por fila se comprueba que $A$ tiene una matriz inversa A^{-1}=\\left[\\begin{array}{cccc} \\frac{1}{3} & -\\frac{4}{3} & \\frac{3}{2} & -\\frac{2}{3}\\\\ 0 & 1 & -2 & 2\\\\ 0 & 0 & \\frac{1}{2} & -2\\\\ 0 & 0 & 0 & 1 \\end{array}\\right] Si tiene inversa se puede llevar a la forma $I_n$ Se observa que en su forma escalonada tiene 4 posiciones pivote. Al tener 4 pivotes solo puede tener soluci\u00f3n trivial. Las columnas de $A$ son linealmente independientes pues no se puede construir alguna columna de $A$ con la combinaci\u00f3n de otras columnas de $A$. Cualquier vector $\\boldsymbol{x}$ que sea multiplicado con $A$ para hacer $A\\boldsymbol{x}$ ser\u00e1 \u00fanico. Cada valor de $\\boldsymbol{b}$ es \u00fanico, y debi\u00f3 de ser mapeado por $A$ como un vector $\\boldsymbol{x}$. Al tener 4 pivotes en $A$ se comprueba que $A$ genera en $\\mathbb{R}^4$. Tanto $\\boldsymbol{x}$ como $A\\boldsymbol{x}$ se encuentran en el mismo espacio $\\mathbb{R}^4$. Al existir una inversa para $A$ existe una matriz $C=A^{-1}$ que hace que $CA=I$. Al existir una inversa para $A$ existe una matriz $D=A^{-1}$ que hace que $AD=I$. La matriz transpuesta de $A$ es A^T=\\left[\\begin{array}{cccc} 3 & 0 & 0 & 0\\\\ 4 & 1 & 0 & 0\\\\ 7 & 4 & 2 & 0\\\\ 8 & 6 & 4 & 1 \\end{array}\\right] la cual cumple con tener 4 posiciones pivote por lo que cumple con tener inversa.","title":"El teorema de la matriz invertible"},{"location":"chapter_02/23_Caracterizaciones_de_Matrices_Invertibles/#trasformaciones-lineales-invertibles","text":"Se dice que una transformaci\u00f3n lineal $T: \\mathbb{R}^n \\rightarrow \\mathbb{R}^n$ es invertible si existe una funci\u00f3n $S: \\mathbb{R}^n \\rightarrow \\mathbb{R}^n$ tal que S \\left( T\\left(\\boldsymbol{x} \\right)\\right)=\\boldsymbol{x} T \\left( S\\left(\\boldsymbol{x} \\right)\\right)=\\boldsymbol{x} Adem\u00e1s, como hemos definido a $T(\\boldsymbol{x})=A\\boldsymbol{x}$ S \\left( T\\left(\\boldsymbol{x} \\right)\\right)= S(A\\boldsymbol{x})=A^{-1}A\\boldsymbol{x}=I\\boldsymbol{x}=\\boldsymbol{x} TAREA SECCI\u00d3N 2.3 1, 3, 7, 33, 34, 39","title":"Trasformaciones Lineales Invertibles"},{"location":"chapter_02/25_Factorizacion_de_Matrices/","text":"2. \u00c1lgebra de Matrices 2.5 Factorizaci\u00f3n de Matrices La factorizaci\u00f3n de una matriz es una ecuaci\u00f3n que expresa $A$ como el producto de dos o m\u00e1s matices. Se puede decir que la multiplicaci\u00f3n sintetiza los datos y la factorizaci\u00f3n analiza los datos. Factorizaci\u00f3n LU Dada la matriz $A$ de $n \\times n$ deseamos encontrar $L$, la matriz triangular inferior, y $U$, la matriz triangular superior, de tal manera que L=\\left[\\begin{array}{cccc} * & 0 & \\dots & 0\\\\ * & * & \\dots & 0\\\\ \\vdots & \\vdots & \\vdots & \\vdots\\\\ * & * & \\dots & * \\end{array}\\right] \\;\\;\\;\\;\\; U=\\left[\\begin{array}{cccc} * & * & \\dots & *\\\\ 0 & * & \\dots & *\\\\ \\vdots & \\vdots & \\vdots & \\vdots\\\\ 0 & 0 & \\dots & * \\end{array}\\right] Es importante notar que $A$ debe de ser reducible a una forma escalonada $U$ sin intercambios de fila . $L$ y $U$ no son \u00fanicas, sin embargo desarrollaremos un algoritmo para obtener los mismos resultados. Construcci\u00f3n de la Factorizaci\u00f3n $A=LU$ Si se parte de una serie de matrices elementales $E_1$, $E_2$, $\\dots$ , $E_k$ y las mismas se aplican de forma sucesiva a la matriz $A$ entonces E_k \\dots E_2 E_1A=U donde $U$ es una matriz triangular superior. Al igual que se hizo en la secci\u00f3n 2.2 se puede hacer que (E_k \\dots E_2 E_1)^{-1}E_k \\dots E_2 E_1A=(E_k \\dots E_2 E_1)^{-1}U A=E_1^{-1}E_2^{-1}\\dots E_k^{-1}U Definiendo a $L=E_1^{-1}E_2^{-1}\\dots E_k^{-1}$ A=LU Ejemplo 1: Encuentre la descomposici\u00f3n $LU$ de $A$ A=\\left[\\begin{array}{cc} 4 & -16\\\\ 3 & -8 \\end{array}\\right] C\u00e1lculo de $E_1$ \\left[\\begin{array}{cc} 1 & 0\\\\ 0 & 1 \\end{array}\\right]A=\\left[\\begin{array}{cc} 4 & -16\\\\ 3 & -8 \\end{array}\\right]\\begin{array}{c} \\\\ \\ \\frac{1}{3}R_2 \\rightarrow R_2 \\end{array} \\left[\\begin{array}{cc} 1 & 0\\\\ 0 & 1/3 \\end{array}\\right]A=\\left[\\begin{array}{cc} 4 & -16\\\\ 1 & -8/3 \\end{array}\\right]=A_1 E_1= \\left[\\begin{array}{cc} 1 & 0\\\\ 0 & 1/3 \\end{array}\\right] C\u00e1lculo de $E_2$ \\left[\\begin{array}{cc} 1 & 0\\\\ 0 & 1 \\end{array}\\right]A_1=\\left[\\begin{array}{cc} 4 & -16\\\\ 1 & -8/3 \\end{array}\\right]\\begin{array}{c} \\frac{1}{4}R_1 \\rightarrow R_1 \\\\ \\ \\ \\end{array} \\left[\\begin{array}{cc} 1/4 & 0\\\\ 0 & 1 \\end{array}\\right]A_1=\\left[\\begin{array}{cc} 1 & -4\\\\ 1 & -8/3 \\end{array}\\right]=A_2 E_2=\\left[\\begin{array}{cc} 1/4 & 0\\\\ 0 & 1 \\end{array}\\right] C\u00e1lculo de $E_3$ \\left[\\begin{array}{cc} 1 & 0\\\\ 0 & 1 \\end{array}\\right]A_2=\\left[\\begin{array}{cc} 1 & -4\\\\ 1 & -8/3 \\end{array}\\right]\\begin{array}{c} \\\\ -R_1+R_2 \\rightarrow R_2 \\ \\ \\end{array} \\left[\\begin{array}{cc} 1 & 0\\\\ -1 & 1 \\end{array}\\right]A_2=\\left[\\begin{array}{cc} 1 & -4\\\\ 0 & 4/3 \\end{array}\\right]=U E_3=\\left[\\begin{array}{cc} 1 & 0\\\\ -1 & 1 \\end{array}\\right] Las matrices inversas de $E$ son E_1^{-1}=\\left[\\begin{array}{cc} 1 & 0\\\\ 0 & 3 \\end{array}\\right]\\;\\;\\; E_2^{-1}=\\left[\\begin{array}{cc} 4 & 0\\\\ 0 & 1 \\end{array}\\right] \\;\\;\\; E_3^{-1}=\\left[\\begin{array}{cc} 1 & 0\\\\ 1 & 1 \\end{array}\\right] Note que las inversas de $E_1$ y $E_2$ son matrices diagonales y $E_3$ es una matriz at\u00f3mica, por lo que sus inversas son f\u00e1ciles de encontrar. Finalmente $L=E_1^{-1}E_2^{-1}E_3^{-1}$ L=\\left[\\begin{array}{cc} 4 & 0\\\\ 3 & 3 \\end{array}\\right] Por lo que se puede escribir $A=LU$ \\left[\\begin{array}{cc} 4 & -16\\\\ 3 & -8 \\end{array}\\right]=\\left[\\begin{array}{cc} 4 & 0\\\\ 3 & 3 \\end{array}\\right]\\left[\\begin{array}{cc} 1 & -4\\\\ 0 & 4/3 \\end{array}\\right] Ejemplo 2: Encuentre la descomposici\u00f3n $LU$ de A=\\left[\\begin{array}{ccc} 1 & 2 & 0\\\\ 3 & -4 & 1\\\\ -2 & 4 & -3 \\end{array}\\right] Ejemplo 3: Encuentre la descomposici\u00f3n $LU$ de A=\\left[\\begin{array}{ccc} 1 & 4 & -3\\\\ -2 & 8 & 5\\\\ 3 & 4 & 7 \\end{array}\\right] Aplicaci\u00f3n de la Factorizaci\u00f3n $LU$ La factorizaci\u00f3n $LU$ puede ser utilizada para simplificar la resoluci\u00f3n de la ecuaci\u00f3n $A \\boldsymbol{x}=\\boldsymbol{b}$ de la siguiente manera A \\boldsymbol{x}=\\boldsymbol{b} LU \\boldsymbol{x}=\\boldsymbol{b} Haciendo $\\boldsymbol{y}=U\\boldsymbol{x}$ se obtiene $L\\boldsymbol{y}=\\boldsymbol{b}$ Por lo que quedar\u00e1n dos sistemas de ecuaciones por resolver U\\boldsymbol{x}=\\boldsymbol{y} L\\boldsymbol{y}=\\boldsymbol{b} Ejemplo 4: Dada la matriz $A$ y el vector $\\boldsymbol{b}$ encuentre la soluci\u00f3n del sistema utilizando la descomposici\u00f3n $LU$. A=\\left[\\begin{array}{ccc} 1 & 4 & -3\\\\ -2 & 8 & 5\\\\ 3 & 4 & 7 \\end{array}\\right] \\;\\;\\;\\;\\; \\boldsymbol{b}=\\left[\\begin{array}{c} -7\\\\ 27\\\\ 19 \\end{array}\\right] La descomposici\u00f3n $LU$ de la matriz $A$ se realiz\u00f3 en el Ejemplo 3 por lo que usaremos los valores obtenidos. L=\\left[\\begin{array}{ccc} 1 & 0 & 0\\\\ -2 & 1 & 0\\\\ 3 & -\\frac{1}{2} & 1 \\end{array}\\right]\\;\\;\\; U=\\left[\\begin{array}{ccc} 1 & 4 & -3\\\\ 0 & 16 & -1\\\\ 0 & 0 & \\frac{31}{2} \\end{array}\\right] Se proceder\u00e1 a resolver $L\\boldsymbol{y}=\\boldsymbol{b}$ [L \\;\\;\\boldsymbol{b}]=\\left[\\begin{array}{cccc} 1 & 0 & 0 & -7\\\\ -2 & 1 & 0 & 27\\\\ 3 & -\\frac{1}{2} & 1 & 19 \\end{array}\\right] \\sim \\left[\\begin{array}{cccc} 1 & 0 & 0 & -7\\\\ 0 & 1 & 0 & 13\\\\ 0 & 0 & 1 & \\frac{93}{2} \\end{array}\\right] \\;\\;\\;\\; \\boldsymbol{y}=\\left[\\begin{array}{c} -7\\\\ 13\\\\ \\frac{93}{2} \\end{array}\\right] Ahora se puede resolver $U\\boldsymbol{x}=\\boldsymbol{y}$ [U \\;\\;\\boldsymbol{y}]=\\left[\\begin{array}{cccc} 1 & 4 & -3 & -7\\\\ 0 & 16 & -1 & 13\\\\ 0 & 0 & \\frac{31}{2} & \\frac{93}{2} \\end{array}\\right] \\sim \\left[\\begin{array}{cccc} 1 & 0 & 0 & -2\\\\ 0 & 1 & 0 & 1\\\\ 0 & 0 & 1 & 3 \\end{array}\\right] \\;\\;\\;\\; \\boldsymbol{x}=\\left[\\begin{array}{c} -2\\\\ 1\\\\ 3 \\end{array}\\right] C\u00e1lculos Computacionales de la Factorizaci\u00f3n $LU$ para resolver ecuaciones Un flop es cualquier operaci\u00f3n aritm\u00e9tica, sea suma, resta, multiplicaci\u00f3n o divisi\u00f3n. El c\u00e1lculo de $LU$ para una matriz $A$ es de $2n^3/3$ flops , mientras que $A^{-1}$ requiere $2n^3$. Resolver $L\\boldsymbol{y}=\\boldsymbol{b}$ y $U\\boldsymbol{x}=\\boldsymbol{y}$ requiere de $2n^2$ flops . $A^{-1}$ por $\\boldsymbol{b}$ tambi\u00e9n requiere de $2n^2$ flops pero la diferencia es que cuando se calcula $A^{-1}$ pueden darse errores de redondeo. Una $A$ dispersa, matriz con mayor\u00eda de entradas cero, puede tener matrices $L$ y $U$ dispersas, sin embargo $A^{-1}$ puede ser densa. Usar $LU$ puede ser m\u00e1s r\u00e1pido que usar $A$. TAREA SECCI\u00d3N 2.5 1, 3, 5, 9, 13, 21, 26","title":"2.5 Factorizaci\u00f3n de Matrices"},{"location":"chapter_02/25_Factorizacion_de_Matrices/#2-algebra-de-matrices","text":"","title":"2. \u00c1lgebra de Matrices"},{"location":"chapter_02/25_Factorizacion_de_Matrices/#25-factorizacion-de-matrices","text":"La factorizaci\u00f3n de una matriz es una ecuaci\u00f3n que expresa $A$ como el producto de dos o m\u00e1s matices. Se puede decir que la multiplicaci\u00f3n sintetiza los datos y la factorizaci\u00f3n analiza los datos.","title":"2.5 Factorizaci\u00f3n de Matrices"},{"location":"chapter_02/25_Factorizacion_de_Matrices/#factorizacion-lu","text":"Dada la matriz $A$ de $n \\times n$ deseamos encontrar $L$, la matriz triangular inferior, y $U$, la matriz triangular superior, de tal manera que L=\\left[\\begin{array}{cccc} * & 0 & \\dots & 0\\\\ * & * & \\dots & 0\\\\ \\vdots & \\vdots & \\vdots & \\vdots\\\\ * & * & \\dots & * \\end{array}\\right] \\;\\;\\;\\;\\; U=\\left[\\begin{array}{cccc} * & * & \\dots & *\\\\ 0 & * & \\dots & *\\\\ \\vdots & \\vdots & \\vdots & \\vdots\\\\ 0 & 0 & \\dots & * \\end{array}\\right] Es importante notar que $A$ debe de ser reducible a una forma escalonada $U$ sin intercambios de fila . $L$ y $U$ no son \u00fanicas, sin embargo desarrollaremos un algoritmo para obtener los mismos resultados.","title":"Factorizaci\u00f3n LU"},{"location":"chapter_02/25_Factorizacion_de_Matrices/#construccion-de-la-factorizacion-alu","text":"Si se parte de una serie de matrices elementales $E_1$, $E_2$, $\\dots$ , $E_k$ y las mismas se aplican de forma sucesiva a la matriz $A$ entonces E_k \\dots E_2 E_1A=U donde $U$ es una matriz triangular superior. Al igual que se hizo en la secci\u00f3n 2.2 se puede hacer que (E_k \\dots E_2 E_1)^{-1}E_k \\dots E_2 E_1A=(E_k \\dots E_2 E_1)^{-1}U A=E_1^{-1}E_2^{-1}\\dots E_k^{-1}U Definiendo a $L=E_1^{-1}E_2^{-1}\\dots E_k^{-1}$ A=LU Ejemplo 1: Encuentre la descomposici\u00f3n $LU$ de $A$ A=\\left[\\begin{array}{cc} 4 & -16\\\\ 3 & -8 \\end{array}\\right] C\u00e1lculo de $E_1$ \\left[\\begin{array}{cc} 1 & 0\\\\ 0 & 1 \\end{array}\\right]A=\\left[\\begin{array}{cc} 4 & -16\\\\ 3 & -8 \\end{array}\\right]\\begin{array}{c} \\\\ \\ \\frac{1}{3}R_2 \\rightarrow R_2 \\end{array} \\left[\\begin{array}{cc} 1 & 0\\\\ 0 & 1/3 \\end{array}\\right]A=\\left[\\begin{array}{cc} 4 & -16\\\\ 1 & -8/3 \\end{array}\\right]=A_1 E_1= \\left[\\begin{array}{cc} 1 & 0\\\\ 0 & 1/3 \\end{array}\\right] C\u00e1lculo de $E_2$ \\left[\\begin{array}{cc} 1 & 0\\\\ 0 & 1 \\end{array}\\right]A_1=\\left[\\begin{array}{cc} 4 & -16\\\\ 1 & -8/3 \\end{array}\\right]\\begin{array}{c} \\frac{1}{4}R_1 \\rightarrow R_1 \\\\ \\ \\ \\end{array} \\left[\\begin{array}{cc} 1/4 & 0\\\\ 0 & 1 \\end{array}\\right]A_1=\\left[\\begin{array}{cc} 1 & -4\\\\ 1 & -8/3 \\end{array}\\right]=A_2 E_2=\\left[\\begin{array}{cc} 1/4 & 0\\\\ 0 & 1 \\end{array}\\right] C\u00e1lculo de $E_3$ \\left[\\begin{array}{cc} 1 & 0\\\\ 0 & 1 \\end{array}\\right]A_2=\\left[\\begin{array}{cc} 1 & -4\\\\ 1 & -8/3 \\end{array}\\right]\\begin{array}{c} \\\\ -R_1+R_2 \\rightarrow R_2 \\ \\ \\end{array} \\left[\\begin{array}{cc} 1 & 0\\\\ -1 & 1 \\end{array}\\right]A_2=\\left[\\begin{array}{cc} 1 & -4\\\\ 0 & 4/3 \\end{array}\\right]=U E_3=\\left[\\begin{array}{cc} 1 & 0\\\\ -1 & 1 \\end{array}\\right] Las matrices inversas de $E$ son E_1^{-1}=\\left[\\begin{array}{cc} 1 & 0\\\\ 0 & 3 \\end{array}\\right]\\;\\;\\; E_2^{-1}=\\left[\\begin{array}{cc} 4 & 0\\\\ 0 & 1 \\end{array}\\right] \\;\\;\\; E_3^{-1}=\\left[\\begin{array}{cc} 1 & 0\\\\ 1 & 1 \\end{array}\\right] Note que las inversas de $E_1$ y $E_2$ son matrices diagonales y $E_3$ es una matriz at\u00f3mica, por lo que sus inversas son f\u00e1ciles de encontrar. Finalmente $L=E_1^{-1}E_2^{-1}E_3^{-1}$ L=\\left[\\begin{array}{cc} 4 & 0\\\\ 3 & 3 \\end{array}\\right] Por lo que se puede escribir $A=LU$ \\left[\\begin{array}{cc} 4 & -16\\\\ 3 & -8 \\end{array}\\right]=\\left[\\begin{array}{cc} 4 & 0\\\\ 3 & 3 \\end{array}\\right]\\left[\\begin{array}{cc} 1 & -4\\\\ 0 & 4/3 \\end{array}\\right] Ejemplo 2: Encuentre la descomposici\u00f3n $LU$ de A=\\left[\\begin{array}{ccc} 1 & 2 & 0\\\\ 3 & -4 & 1\\\\ -2 & 4 & -3 \\end{array}\\right] Ejemplo 3: Encuentre la descomposici\u00f3n $LU$ de A=\\left[\\begin{array}{ccc} 1 & 4 & -3\\\\ -2 & 8 & 5\\\\ 3 & 4 & 7 \\end{array}\\right]","title":"Construcci\u00f3n de la Factorizaci\u00f3n $A=LU$"},{"location":"chapter_02/25_Factorizacion_de_Matrices/#aplicacion-de-la-factorizacion-lu","text":"La factorizaci\u00f3n $LU$ puede ser utilizada para simplificar la resoluci\u00f3n de la ecuaci\u00f3n $A \\boldsymbol{x}=\\boldsymbol{b}$ de la siguiente manera A \\boldsymbol{x}=\\boldsymbol{b} LU \\boldsymbol{x}=\\boldsymbol{b} Haciendo $\\boldsymbol{y}=U\\boldsymbol{x}$ se obtiene $L\\boldsymbol{y}=\\boldsymbol{b}$ Por lo que quedar\u00e1n dos sistemas de ecuaciones por resolver U\\boldsymbol{x}=\\boldsymbol{y} L\\boldsymbol{y}=\\boldsymbol{b} Ejemplo 4: Dada la matriz $A$ y el vector $\\boldsymbol{b}$ encuentre la soluci\u00f3n del sistema utilizando la descomposici\u00f3n $LU$. A=\\left[\\begin{array}{ccc} 1 & 4 & -3\\\\ -2 & 8 & 5\\\\ 3 & 4 & 7 \\end{array}\\right] \\;\\;\\;\\;\\; \\boldsymbol{b}=\\left[\\begin{array}{c} -7\\\\ 27\\\\ 19 \\end{array}\\right] La descomposici\u00f3n $LU$ de la matriz $A$ se realiz\u00f3 en el Ejemplo 3 por lo que usaremos los valores obtenidos. L=\\left[\\begin{array}{ccc} 1 & 0 & 0\\\\ -2 & 1 & 0\\\\ 3 & -\\frac{1}{2} & 1 \\end{array}\\right]\\;\\;\\; U=\\left[\\begin{array}{ccc} 1 & 4 & -3\\\\ 0 & 16 & -1\\\\ 0 & 0 & \\frac{31}{2} \\end{array}\\right] Se proceder\u00e1 a resolver $L\\boldsymbol{y}=\\boldsymbol{b}$ [L \\;\\;\\boldsymbol{b}]=\\left[\\begin{array}{cccc} 1 & 0 & 0 & -7\\\\ -2 & 1 & 0 & 27\\\\ 3 & -\\frac{1}{2} & 1 & 19 \\end{array}\\right] \\sim \\left[\\begin{array}{cccc} 1 & 0 & 0 & -7\\\\ 0 & 1 & 0 & 13\\\\ 0 & 0 & 1 & \\frac{93}{2} \\end{array}\\right] \\;\\;\\;\\; \\boldsymbol{y}=\\left[\\begin{array}{c} -7\\\\ 13\\\\ \\frac{93}{2} \\end{array}\\right] Ahora se puede resolver $U\\boldsymbol{x}=\\boldsymbol{y}$ [U \\;\\;\\boldsymbol{y}]=\\left[\\begin{array}{cccc} 1 & 4 & -3 & -7\\\\ 0 & 16 & -1 & 13\\\\ 0 & 0 & \\frac{31}{2} & \\frac{93}{2} \\end{array}\\right] \\sim \\left[\\begin{array}{cccc} 1 & 0 & 0 & -2\\\\ 0 & 1 & 0 & 1\\\\ 0 & 0 & 1 & 3 \\end{array}\\right] \\;\\;\\;\\; \\boldsymbol{x}=\\left[\\begin{array}{c} -2\\\\ 1\\\\ 3 \\end{array}\\right]","title":"Aplicaci\u00f3n de la Factorizaci\u00f3n $LU$"},{"location":"chapter_02/25_Factorizacion_de_Matrices/#calculos-computacionales-de-la-factorizacion-lu-para-resolver-ecuaciones","text":"Un flop es cualquier operaci\u00f3n aritm\u00e9tica, sea suma, resta, multiplicaci\u00f3n o divisi\u00f3n. El c\u00e1lculo de $LU$ para una matriz $A$ es de $2n^3/3$ flops , mientras que $A^{-1}$ requiere $2n^3$. Resolver $L\\boldsymbol{y}=\\boldsymbol{b}$ y $U\\boldsymbol{x}=\\boldsymbol{y}$ requiere de $2n^2$ flops . $A^{-1}$ por $\\boldsymbol{b}$ tambi\u00e9n requiere de $2n^2$ flops pero la diferencia es que cuando se calcula $A^{-1}$ pueden darse errores de redondeo. Una $A$ dispersa, matriz con mayor\u00eda de entradas cero, puede tener matrices $L$ y $U$ dispersas, sin embargo $A^{-1}$ puede ser densa. Usar $LU$ puede ser m\u00e1s r\u00e1pido que usar $A$. TAREA SECCI\u00d3N 2.5 1, 3, 5, 9, 13, 21, 26","title":"C\u00e1lculos Computacionales de la Factorizaci\u00f3n $LU$ para resolver ecuaciones"},{"location":"chapter_03/31_Introduccion_a_los_Determinantes/","text":"3. Determinantes 3.1 Introducci\u00f3n a los Determinantes Es un valor asociado a una matriz cuadrada. Para una matriz de coeficientes indica que: El sistema de ecuaciones lineales posee soluci\u00f3n \u00fanica cuando el determinante no es cero. Existen infinitas o ninguna soluci\u00f3n cuando el determinante es cero. Para una transformaci\u00f3n lineal indica que: La transformaci\u00f3n inversa existe cuando el determinante no es cero. Calculo de los Determinantes Determinante de $1 \\times 1$ A = [a_{11}] \\;\\;\\;\\;\\; \\vert A\\vert=a_{11} Determinante de $2 \\times 2$ A=\\left[\\begin{array}{cc} a_{11} & a_{12}\\\\ a_{21} & a_{22} \\end{array}\\right] \\;\\;\\;\\;\\; \\vert A \\vert = \\left\\vert \\begin{array}{cc} a_{11} & a_{12}\\\\ a_{21} & a_{22} \\end{array} \\right\\vert = a_{11}a_{22}-a_{21}a_{12} Para determinantes de orden superior, el determinante es un proceso recursivo donde se encuentran determinantes de orden inferior. Determinante de $3 \\times 3$ A=\\left [\\begin{matrix} a_{11} & a_{12} & a_{13} \\\\ a_{21} & a_{22} & a_{23} \\\\a_{31} & a_{32} & a_{33} \\end{matrix} \\right ] El determinante est\u00e1 definido como para una fila $i$ espec\u00edfica para una columna $j$ espec\u00edfica \\vert A \\vert=\\sum\\limits_{j=1}^{3}(-1)^{(i+j)}a_{i,j}\\vert A_{i,j}\\vert \\vert A \\vert=\\sum\\limits_{i=1}^{3}(-1)^{(i+j)}a_{i,j}\\vert A_{i,j}\\vert Determinante por fila Utilizando la definici\u00f3n de determinante para la fila 1, es decir con $i=1$ se puede calcular el determinante \\vert A \\vert=(-1)^{(1+1)}a_{11}\\vert A_{11}\\vert+(-1)^{(1+2)}a_{12}\\vert A_{12}\\vert + (-1)^{(1+3)}a_{13}\\vert A_{13}\\vert Siendo las sub-matrices A_{11}=\\left[\\begin{array}{cc} a_{22} & a_{23}\\\\ a_{32} & a_{33} \\end{array}\\right] \\;\\;\\;\\;\\; A_{12}=\\left[\\begin{array}{cc} a_{21} & a_{23}\\\\ a_{31} & a_{33} \\end{array}\\right] \\;\\;\\;\\;\\; A_{13}=\\left[\\begin{array}{cc} a_{21} & a_{22}\\\\ a_{31} & a_{32} \\end{array}\\right] Determinante por columna De igual manera se pudo haber seleccionado una columna como la n\u00famero 2, es decir con $j=2$, para calcular el determinante \\vert A \\vert=(-1)^{(1+2)}a_{12}\\vert A_{12}\\vert+(-1)^{(2+2)}a_{22}\\vert A_{22}\\vert + (-1)^{(3+2)}a_{32}\\vert A_{32}\\vert Donde en este caso las sub-matrices son A_{12}=\\left[\\begin{array}{cc} a_{21} & a_{23}\\\\ a_{31} & a_{33} \\end{array}\\right] \\;\\;\\;\\;\\; A_{22}=\\left[\\begin{array}{cc} a_{11} & a_{13}\\\\ a_{31} & a_{33} \\end{array}\\right] \\;\\;\\;\\;\\; A_{32}=\\left[\\begin{array}{cc} a_{11} & a_{13}\\\\ a_{21} & a_{23} \\end{array}\\right] Ejemplo 1: Encuentre el determinante de la matriz $A$ A=\\left[\\begin{array}{ccc} 3 & -1 & 8\\\\ 2 & 5 & -7\\\\ 4 & 6 & 1 \\end{array}\\right] Determinante de $n \\times n$ para una fila $i$ espec\u00edfica para una columna $j$ espec\u00edfica \\vert A \\vert=\\sum\\limits_{j=1}^{n}(-1)^{(i+j)}a_{i,j}\\vert A_{i,j}\\vert \\vert A \\vert=\\sum\\limits_{i=1}^{n}(-1)^{(i+j)}a_{i,j}\\vert A_{i,j}\\vert Se define como cofactor al t\u00e9rmino C_{i,j}=(-1)^{(i+j)}\\vert A_{i,j}\\vert por lo que el determinante en su forma m\u00e1s general est\u00e1 definido como para una fila $i$ espec\u00edfica para una columna $j$ espec\u00edfica \\vert A \\vert=\\sum\\limits_{j=1}^{n}a_{i,j}C_{i,j} \\vert A \\vert=\\sum\\limits_{i=1}^{n}a_{i,j}C_{i,j} El n\u00famero de operaciones que lleva encontrar un determinante es de $\\frac{n!}{3}$. Ejemplo 2: Encuentre el determinante de la matriz $A$ A=\\left[\\begin{array}{cccc} 6 & 0 & 0 & 5\\\\ 1 & 7 & 2 & -5\\\\ 2 & 0 & 0 & 0\\\\ 8 & 3 & 1 & 8 \\end{array}\\right] TAREA SECCI\u00d3N 3.1 1, 3, 5, 11, 13, 15, 17, 19, 21, 23, 25, 27, 33, 35","title":"3.1 Introducci\u00f3n a los Determinantes"},{"location":"chapter_03/31_Introduccion_a_los_Determinantes/#3-determinantes","text":"","title":"3. Determinantes"},{"location":"chapter_03/31_Introduccion_a_los_Determinantes/#31-introduccion-a-los-determinantes","text":"Es un valor asociado a una matriz cuadrada. Para una matriz de coeficientes indica que: El sistema de ecuaciones lineales posee soluci\u00f3n \u00fanica cuando el determinante no es cero. Existen infinitas o ninguna soluci\u00f3n cuando el determinante es cero. Para una transformaci\u00f3n lineal indica que: La transformaci\u00f3n inversa existe cuando el determinante no es cero.","title":"3.1 Introducci\u00f3n a los Determinantes"},{"location":"chapter_03/31_Introduccion_a_los_Determinantes/#calculo-de-los-determinantes","text":"","title":"Calculo de los Determinantes"},{"location":"chapter_03/31_Introduccion_a_los_Determinantes/#determinante-de-1-times-1","text":"A = [a_{11}] \\;\\;\\;\\;\\; \\vert A\\vert=a_{11}","title":"Determinante de $1 \\times 1$"},{"location":"chapter_03/31_Introduccion_a_los_Determinantes/#determinante-de-2-times-2","text":"A=\\left[\\begin{array}{cc} a_{11} & a_{12}\\\\ a_{21} & a_{22} \\end{array}\\right] \\;\\;\\;\\;\\; \\vert A \\vert = \\left\\vert \\begin{array}{cc} a_{11} & a_{12}\\\\ a_{21} & a_{22} \\end{array} \\right\\vert = a_{11}a_{22}-a_{21}a_{12} Para determinantes de orden superior, el determinante es un proceso recursivo donde se encuentran determinantes de orden inferior.","title":"Determinante de $2 \\times 2$"},{"location":"chapter_03/31_Introduccion_a_los_Determinantes/#determinante-de-3-times-3","text":"A=\\left [\\begin{matrix} a_{11} & a_{12} & a_{13} \\\\ a_{21} & a_{22} & a_{23} \\\\a_{31} & a_{32} & a_{33} \\end{matrix} \\right ] El determinante est\u00e1 definido como para una fila $i$ espec\u00edfica para una columna $j$ espec\u00edfica \\vert A \\vert=\\sum\\limits_{j=1}^{3}(-1)^{(i+j)}a_{i,j}\\vert A_{i,j}\\vert \\vert A \\vert=\\sum\\limits_{i=1}^{3}(-1)^{(i+j)}a_{i,j}\\vert A_{i,j}\\vert Determinante por fila Utilizando la definici\u00f3n de determinante para la fila 1, es decir con $i=1$ se puede calcular el determinante \\vert A \\vert=(-1)^{(1+1)}a_{11}\\vert A_{11}\\vert+(-1)^{(1+2)}a_{12}\\vert A_{12}\\vert + (-1)^{(1+3)}a_{13}\\vert A_{13}\\vert Siendo las sub-matrices A_{11}=\\left[\\begin{array}{cc} a_{22} & a_{23}\\\\ a_{32} & a_{33} \\end{array}\\right] \\;\\;\\;\\;\\; A_{12}=\\left[\\begin{array}{cc} a_{21} & a_{23}\\\\ a_{31} & a_{33} \\end{array}\\right] \\;\\;\\;\\;\\; A_{13}=\\left[\\begin{array}{cc} a_{21} & a_{22}\\\\ a_{31} & a_{32} \\end{array}\\right] Determinante por columna De igual manera se pudo haber seleccionado una columna como la n\u00famero 2, es decir con $j=2$, para calcular el determinante \\vert A \\vert=(-1)^{(1+2)}a_{12}\\vert A_{12}\\vert+(-1)^{(2+2)}a_{22}\\vert A_{22}\\vert + (-1)^{(3+2)}a_{32}\\vert A_{32}\\vert Donde en este caso las sub-matrices son A_{12}=\\left[\\begin{array}{cc} a_{21} & a_{23}\\\\ a_{31} & a_{33} \\end{array}\\right] \\;\\;\\;\\;\\; A_{22}=\\left[\\begin{array}{cc} a_{11} & a_{13}\\\\ a_{31} & a_{33} \\end{array}\\right] \\;\\;\\;\\;\\; A_{32}=\\left[\\begin{array}{cc} a_{11} & a_{13}\\\\ a_{21} & a_{23} \\end{array}\\right] Ejemplo 1: Encuentre el determinante de la matriz $A$ A=\\left[\\begin{array}{ccc} 3 & -1 & 8\\\\ 2 & 5 & -7\\\\ 4 & 6 & 1 \\end{array}\\right]","title":"Determinante de $3 \\times 3$"},{"location":"chapter_03/31_Introduccion_a_los_Determinantes/#determinante-de-n-times-n","text":"para una fila $i$ espec\u00edfica para una columna $j$ espec\u00edfica \\vert A \\vert=\\sum\\limits_{j=1}^{n}(-1)^{(i+j)}a_{i,j}\\vert A_{i,j}\\vert \\vert A \\vert=\\sum\\limits_{i=1}^{n}(-1)^{(i+j)}a_{i,j}\\vert A_{i,j}\\vert Se define como cofactor al t\u00e9rmino C_{i,j}=(-1)^{(i+j)}\\vert A_{i,j}\\vert por lo que el determinante en su forma m\u00e1s general est\u00e1 definido como para una fila $i$ espec\u00edfica para una columna $j$ espec\u00edfica \\vert A \\vert=\\sum\\limits_{j=1}^{n}a_{i,j}C_{i,j} \\vert A \\vert=\\sum\\limits_{i=1}^{n}a_{i,j}C_{i,j} El n\u00famero de operaciones que lleva encontrar un determinante es de $\\frac{n!}{3}$. Ejemplo 2: Encuentre el determinante de la matriz $A$ A=\\left[\\begin{array}{cccc} 6 & 0 & 0 & 5\\\\ 1 & 7 & 2 & -5\\\\ 2 & 0 & 0 & 0\\\\ 8 & 3 & 1 & 8 \\end{array}\\right] TAREA SECCI\u00d3N 3.1 1, 3, 5, 11, 13, 15, 17, 19, 21, 23, 25, 27, 33, 35","title":"Determinante de $n \\times n$"},{"location":"chapter_03/32_Propiedades_de_los_Determinantes/","text":"3. Determinantes 3.2 Propiedades de los Determinantes Operaciones de Fila Existen tres propiedades importantes de los determinantes de las matrices Si un m\u00faltiplo de una fila de $A$ se suma a otra fila para producir una matriz $B$, entonces $\\vert B \\vert=\\vert A \\vert$. Las operaciones de la forma $kR_b+R_d \\rightarrow R_d$ siendo $R_b$ la fila base y $R_d$ la fila destino, y $k$ un escalar permiten construir estas matrices. Matrices equivalentes tendr\u00e1n el mismo determinante. Ejemplo 1: Dada la matriz $A$ encuentre su forma escalonada $B$ y calcule el determinante de ambas matrices. A=\\left[\\begin{array}{ccc} 1 & 3 & 5\\\\ 2 & 1 & 1\\\\ 3 & 4 & 2 \\end{array}\\right] Si una fila de $A$ se multiplica por $k$ para producir $B$, entonces $\\vert B \\vert=k\\vert A \\vert$. Las operaciones de la forma $kR_d \\rightarrow R_d$ permiten construir estas matrices. Ejemplo 2: Dada la matriz $B$ encuentre su determinante si a esta matriz se le aplica la siguiente operaci\u00f3n de fila $3R_2 \\rightarrow R_2$. \\left[\\begin{array}{ccc} 1 & 3 & 5\\\\ 0 & -5 & -9\\\\ 0 & 0 & -4 \\end{array}\\right] Si dos filas de A se intercambian para producir $B$, entonces $\\vert B \\vert = -\\vert A \\vert$. Ejemplo 3: Dada la matriz $B$ compruebe la propiedad de intercambio de filas de los determinantes. \\left[\\begin{array}{ccc} 1 & 3 & 5\\\\ 0 & -5 & -9\\\\ 0 & 0 & -4 \\end{array}\\right] Si se construye una matriz con diagonal superior $U$ a trav\u00e9s de $r$ intercambios de filas, entonces U=\\left[\\begin{array}{cccc} u_{11} & * & \\dots & *\\\\ * & u_{22} & \\dots & *\\\\ \\vdots & \\vdots & \\vdots & \\vdots\\\\ * & * & \\dots & u_{nn} \\end{array}\\right]\\;\\;\\;\\;\\; \\vert U \\vert = (-1)^r (u_{11}u_{22}\\cdots u_{nn}) Operaciones de Columna Determinante de matriz Transpuesta $\\vert A \\vert = \\vert A^T \\vert$ A=\\left[\\begin{array}{ccc} a_{11} & a_{12} & a_{13}\\\\ a_{21} & a_{22} & a_{23}\\\\ a_{31} & a_{32} & a_{33} \\end{array}\\right] \\vert A \\vert = a_{11}\\left\\vert\\begin{array}{cc} a_{22} & a_{23}\\\\ a_{32} & a_{33} \\end{array}\\right\\vert -a_{12}\\left\\vert\\begin{array}{cc} a_{21} & a_{23}\\\\ a_{31} & a_{33} \\end{array}\\right\\vert +a_{13}\\left\\vert\\begin{array}{cc} a_{21} & a_{22}\\\\ a_{31} & a_{32} \\end{array}\\right\\vert A^T= \\left[\\begin{array}{ccc} a_{11} & a_{21} & a_{31}\\\\ a_{12} & a_{22} & a_{32}\\\\ a_{13} & a_{23} & a_{33} \\end{array}\\right] \\vert A^T \\vert = a_{11}\\left\\vert\\begin{array}{cc} a_{22} & a_{32}\\\\ a_{23} & a_{33} \\end{array}\\right\\vert -a_{12}\\left\\vert\\begin{array}{cc} a_{21} & a_{31}\\\\ a_{23} & a_{33} \\end{array}\\right\\vert +a_{13}\\left\\vert\\begin{array}{cc} a_{21} & a_{31}\\\\ a_{22} & a_{32} \\end{array}\\right\\vert Determinantes y Productos Matriciales Si $A$ y $B$ son matrices de $n \\times n$, entonces $ \\vert AB \\vert = \\vert A \\vert \\vert B \\vert$. Ejemplo 4: Sean las matrices at\u00f3micas $A$ y $B$ encuentre $ \\vert AB \\vert = \\vert A \\vert \\vert B \\vert$. A = \\left[\\begin{array}{ccc} 1 & 0 & 0\\\\ 5 & 1 & 0\\\\ 0 & 0 & 1 \\end{array}\\right] \\;\\;\\;\\;\\; B=\\left[\\begin{array}{ccc} 1 & 0 & 0\\\\ 0 & 1 & 0\\\\ 0 & 6 & 1 \\end{array}\\right] TAREA SECCI\u00d3N 3.2 1, 3, 5, 9, 11, 13, 15, 17, 23, 25, 31, 37","title":"3.2 Propiedades de los Determinantes"},{"location":"chapter_03/32_Propiedades_de_los_Determinantes/#3-determinantes","text":"","title":"3. Determinantes"},{"location":"chapter_03/32_Propiedades_de_los_Determinantes/#32-propiedades-de-los-determinantes","text":"","title":"3.2 Propiedades de los Determinantes"},{"location":"chapter_03/32_Propiedades_de_los_Determinantes/#operaciones-de-fila","text":"Existen tres propiedades importantes de los determinantes de las matrices","title":"Operaciones de Fila"},{"location":"chapter_03/32_Propiedades_de_los_Determinantes/#si-un-multiplo-de-una-fila-de-a-se-suma-a-otra-fila-para-producir-una-matriz-b-entonces-vert-b-vertvert-a-vert","text":"Las operaciones de la forma $kR_b+R_d \\rightarrow R_d$ siendo $R_b$ la fila base y $R_d$ la fila destino, y $k$ un escalar permiten construir estas matrices. Matrices equivalentes tendr\u00e1n el mismo determinante. Ejemplo 1: Dada la matriz $A$ encuentre su forma escalonada $B$ y calcule el determinante de ambas matrices. A=\\left[\\begin{array}{ccc} 1 & 3 & 5\\\\ 2 & 1 & 1\\\\ 3 & 4 & 2 \\end{array}\\right]","title":"Si un m\u00faltiplo de una fila de $A$ se suma a otra fila para producir una matriz $B$, entonces $\\vert B \\vert=\\vert A \\vert$."},{"location":"chapter_03/32_Propiedades_de_los_Determinantes/#si-una-fila-de-a-se-multiplica-por-k-para-producir-b-entonces-vert-b-vertkvert-a-vert","text":"Las operaciones de la forma $kR_d \\rightarrow R_d$ permiten construir estas matrices. Ejemplo 2: Dada la matriz $B$ encuentre su determinante si a esta matriz se le aplica la siguiente operaci\u00f3n de fila $3R_2 \\rightarrow R_2$. \\left[\\begin{array}{ccc} 1 & 3 & 5\\\\ 0 & -5 & -9\\\\ 0 & 0 & -4 \\end{array}\\right]","title":"Si una fila de $A$ se multiplica por $k$ para producir $B$, entonces $\\vert B \\vert=k\\vert A \\vert$."},{"location":"chapter_03/32_Propiedades_de_los_Determinantes/#si-dos-filas-de-a-se-intercambian-para-producir-b-entonces-vert-b-vert-vert-a-vert","text":"Ejemplo 3: Dada la matriz $B$ compruebe la propiedad de intercambio de filas de los determinantes. \\left[\\begin{array}{ccc} 1 & 3 & 5\\\\ 0 & -5 & -9\\\\ 0 & 0 & -4 \\end{array}\\right]","title":"Si dos filas de A se intercambian para producir $B$, entonces $\\vert B \\vert = -\\vert A \\vert$."},{"location":"chapter_03/32_Propiedades_de_los_Determinantes/#si-se-construye-una-matriz-con-diagonal-superior-u-a-traves-de-r-intercambios-de-filas-entonces","text":"U=\\left[\\begin{array}{cccc} u_{11} & * & \\dots & *\\\\ * & u_{22} & \\dots & *\\\\ \\vdots & \\vdots & \\vdots & \\vdots\\\\ * & * & \\dots & u_{nn} \\end{array}\\right]\\;\\;\\;\\;\\; \\vert U \\vert = (-1)^r (u_{11}u_{22}\\cdots u_{nn})","title":"Si se construye una matriz con diagonal superior $U$ a trav\u00e9s de $r$ intercambios de filas, entonces"},{"location":"chapter_03/32_Propiedades_de_los_Determinantes/#operaciones-de-columna","text":"","title":"Operaciones de Columna"},{"location":"chapter_03/32_Propiedades_de_los_Determinantes/#determinante-de-matriz-transpuesta-vert-a-vert-vert-at-vert","text":"A=\\left[\\begin{array}{ccc} a_{11} & a_{12} & a_{13}\\\\ a_{21} & a_{22} & a_{23}\\\\ a_{31} & a_{32} & a_{33} \\end{array}\\right] \\vert A \\vert = a_{11}\\left\\vert\\begin{array}{cc} a_{22} & a_{23}\\\\ a_{32} & a_{33} \\end{array}\\right\\vert -a_{12}\\left\\vert\\begin{array}{cc} a_{21} & a_{23}\\\\ a_{31} & a_{33} \\end{array}\\right\\vert +a_{13}\\left\\vert\\begin{array}{cc} a_{21} & a_{22}\\\\ a_{31} & a_{32} \\end{array}\\right\\vert A^T= \\left[\\begin{array}{ccc} a_{11} & a_{21} & a_{31}\\\\ a_{12} & a_{22} & a_{32}\\\\ a_{13} & a_{23} & a_{33} \\end{array}\\right] \\vert A^T \\vert = a_{11}\\left\\vert\\begin{array}{cc} a_{22} & a_{32}\\\\ a_{23} & a_{33} \\end{array}\\right\\vert -a_{12}\\left\\vert\\begin{array}{cc} a_{21} & a_{31}\\\\ a_{23} & a_{33} \\end{array}\\right\\vert +a_{13}\\left\\vert\\begin{array}{cc} a_{21} & a_{31}\\\\ a_{22} & a_{32} \\end{array}\\right\\vert","title":"Determinante de matriz Transpuesta $\\vert A \\vert = \\vert A^T \\vert$"},{"location":"chapter_03/32_Propiedades_de_los_Determinantes/#determinantes-y-productos-matriciales","text":"","title":"Determinantes y Productos Matriciales"},{"location":"chapter_03/32_Propiedades_de_los_Determinantes/#si-a-y-b-son-matrices-de-n-times-n-entonces-vert-ab-vert-vert-a-vert-vert-b-vert","text":"Ejemplo 4: Sean las matrices at\u00f3micas $A$ y $B$ encuentre $ \\vert AB \\vert = \\vert A \\vert \\vert B \\vert$. A = \\left[\\begin{array}{ccc} 1 & 0 & 0\\\\ 5 & 1 & 0\\\\ 0 & 0 & 1 \\end{array}\\right] \\;\\;\\;\\;\\; B=\\left[\\begin{array}{ccc} 1 & 0 & 0\\\\ 0 & 1 & 0\\\\ 0 & 6 & 1 \\end{array}\\right] TAREA SECCI\u00d3N 3.2 1, 3, 5, 9, 11, 13, 15, 17, 23, 25, 31, 37","title":"Si $A$ y $B$ son matrices de $n \\times n$, entonces $ \\vert AB \\vert = \\vert A \\vert \\vert B \\vert$."},{"location":"chapter_03/33_%C3%81rea_Volumen_Regla_de_Cramer_Matriz_Adjunta_Transformaciones_Lineales/","text":"3. Determinantes 3.3 \u00c1rea-Volumen, Regla de Cramer, Matriz Adjunta y Transformaciones Lineales Determinante como \u00c1rea y Volumen Matriz de $2 \\times 2$ Para una matriz $A$ de $2 \\times 2$ dada como A=\\left[\\begin{array}{cc} a & 0\\\\ 0 & d \\end{array}\\right]=[\\boldsymbol{u}, \\boldsymbol{v}] representada en la siguiente figura Se puede observar que el valor absoluto del determinante de $A$ ser\u00e1 el \u00e1rea del paralelogramo \\mathrm{abs}(\\vert A \\vert) = \\mathrm{abs}(ad) En el caso de que el paralelogramo fuera definido por la matriz $A$ A=\\left[\\begin{array}{cc} a & c\\\\ b & d \\end{array}\\right]=[\\boldsymbol{u}, \\boldsymbol{v}] De igual manera, el valor absoluto del determinante de $A$ ser\u00e1 el \u00e1rea del paralelogramo \\mathrm{abs}(\\vert A \\vert) = \\mathrm{abs}(ad-bc) Ejemplo 1: Demuestre que el \u00e1rea del paralelogramo dado por $A$ A=\\left[\\begin{array}{cc} a & c\\\\ b & d \\end{array}\\right] se encuentra definido como $\\mathrm{abs}(\\vert A \\vert)$. Matriz de $3 \\times 3$ Para una matriz $A$ de $ 3\\times 3$ dada como A=\\left[\\begin{array}{ccc} a & 0 & 0\\\\ 0 & b & 0\\\\ 0 & 0 & c \\end{array}\\right] Geom\u00e9tricamente representar\u00eda un paralelep\u00edpedo de lados con longitud $a$, $b$ y $c$ como se muestra en la figura Al calcular el valor absoluto del determinante de $A$ \\mathrm{abs}(\\vert A \\vert) = \\mathrm{abs}(abc) se observa que el mismo es el volumen del paralelep\u00edpedo generado. Regla de Cramer Suponga que posee una matriz $A=[\\boldsymbol{a_1}, \\boldsymbol{a_2}, \\dots ,\\boldsymbol{a_n}]$ y existe un vector $\\boldsymbol{b}$ que cumple con $A\\boldsymbol{x}=\\boldsymbol{b}$. Adem\u00e1s se define la matriz aumentada A_i(b)=[\\boldsymbol{a_1}, \\boldsymbol{a_2}, \\dots, \\boldsymbol{b}, \\dots, \\boldsymbol{a_n}] en donde $\\boldsymbol{b}$ se encuentra posicionado en la $i$-\u00e9sima columna. La Regla de Cramer establece que x_i=\\frac{\\vert A_i(b) \\vert}{\\vert A \\vert} Ejemplo 2: Utilice la Regla de Cramer para encontrar la soluci\u00f3n al sistema de ecuaciones lineales 4x_1+x_2=6 5x_1+2x_2=7 Matriz Adjunta $\\mathrm{adj}A$ Recuerde que al t\u00e9rmino $C_{i,j}$ se le denomin\u00f3 cofactor, y estaba dado por C_{i,j}=(-1)^{(i+j)}\\vert A_{i,j}\\vert La matriz de cofactores $C$ esta definida como C = \\left[\\begin{array}{cccc} C_{11} & C_{12} & \\cdots & C_{\\mathrm{1n}}\\\\ C_{21} & C_{22} & \\cdots & C_{2n}\\\\ \\vdots & \\vdots & \\vdots & \\vdots\\\\ C_{\\mathrm{n1}} & C_{\\mathrm{n2}} & \\cdots & C_{\\mathrm{nn}} \\end{array}\\right] La matriz transpuesta de cofactores, $C^T$, se le conoce como la matriz adjunta \\mathrm{adj}A = C^T = \\left[\\begin{array}{cccc} C_{11} & C_{21} & \\cdots & C_{\\mathrm{n1}}\\\\ C_{12} & C_{22} & \\cdots & C_{\\mathrm{n2}}\\\\ \\vdots & \\vdots & \\vdots & \\vdots\\\\ C_{\\mathrm{1n}} & C_{\\mathrm{2n}} & \\cdots & C_{\\mathrm{nn}} \\end{array}\\right] Ejemplo 3: Encuentre la matriz $\\mathrm{adj}A$ si A=\\left[\\begin{array}{ccc} 2 & 1 & 3\\\\ 1 & -1 & 1\\\\ 1 & 4 & -2 \\end{array}\\right] Si se conoce $\\mathrm{adj}A$ es posible encontrar $A^{-1}$ como A^{-1}=\\frac{1}{\\vert A \\vert}\\mathrm{adj}A Ejemplo 4: Encuentre la matriz inversa de $A$ del Ejemplo 3 por medio de $\\mathrm{adj}A$. Transformaciones Lineales Sea $T:\\mathbb{R}^2 \\rightarrow \\mathbb{R}^2$ una transformaci\u00f3n lineal determinada por una matriz $A$ de $2 \\times 2$. Si $S$ es un paralelogramo en $\\mathbb{R}^2$, entonces {\u00e1rea de $T(S)$} $=$ $\\mathrm{abs}\\vert A \\vert \\cdot ${\u00e1rea de $S$} Si $T$ est\u00e1 determinada por una matriz A de $3 \\times 3$, y si $S$ es un paralelep\u00edpedo en $\\mathbb{R}^3$, entonces {volumen de $T(S)$} $=$ $\\mathrm{abs}\\vert A \\vert \\cdot ${volumen de $S$} Ejemplo 5: Dados los vectores $u$ y $v$ que generan el paralelogramo de la figura, si se aplica la transformaci\u00f3n $T:\\mathbb{R}^2 \\rightarrow \\mathbb{R}^2$ para generar los vectores $w$ y $a$ respectivamente. \u00bfCu\u00e1l es el valor del determinante de la matriz $A$? Se debe de cumplir con \\left\\vert\\boldsymbol{w} \\;\\;\\boldsymbol{a} \\right \\vert = \\vert A \\vert\\left\\vert\\boldsymbol{u} \\;\\;\\boldsymbol{v} \\right \\vert \\left\\vert \\begin{matrix} 2 & 0\\\\ 0 & 2 \\end{matrix} \\right \\vert=\\vert A \\vert\\left\\vert \\begin{matrix} 1 & 0\\\\ 0 & 1 \\end{matrix} \\right \\vert 4 = \\vert A \\vert \\cdot 1 Por lo tanto $\\vert A \\vert = 4$ Ejemplo 6: El siguiente ejemplo muestra como el concepto de Transformaci\u00f3n Lineal puede ser aplicada para normalizar los datos de un sistema y as\u00ed realizar una adecuada implementaci\u00f3n del algoritmo K-Means. Este ejemplo se encuentra en el archivo statistics/K-Means.ipynb del repositorio de binder. TAREA SECCI\u00d3N 3.3 1, 3, 5, 9, 11, 13, 19, 21, 23","title":"3.3 \u00c1rea-Volumen, Regla de Cramer, Matriz Adjunta y Transformaciones Lineales"},{"location":"chapter_03/33_%C3%81rea_Volumen_Regla_de_Cramer_Matriz_Adjunta_Transformaciones_Lineales/#3-determinantes","text":"","title":"3. Determinantes"},{"location":"chapter_03/33_%C3%81rea_Volumen_Regla_de_Cramer_Matriz_Adjunta_Transformaciones_Lineales/#33-area-volumen-regla-de-cramer-matriz-adjunta-y-transformaciones-lineales","text":"","title":"3.3 \u00c1rea-Volumen, Regla de Cramer, Matriz Adjunta y Transformaciones Lineales"},{"location":"chapter_03/33_%C3%81rea_Volumen_Regla_de_Cramer_Matriz_Adjunta_Transformaciones_Lineales/#determinante-como-area-y-volumen","text":"","title":"Determinante como \u00c1rea y Volumen"},{"location":"chapter_03/33_%C3%81rea_Volumen_Regla_de_Cramer_Matriz_Adjunta_Transformaciones_Lineales/#matriz-de-2-times-2","text":"Para una matriz $A$ de $2 \\times 2$ dada como A=\\left[\\begin{array}{cc} a & 0\\\\ 0 & d \\end{array}\\right]=[\\boldsymbol{u}, \\boldsymbol{v}] representada en la siguiente figura Se puede observar que el valor absoluto del determinante de $A$ ser\u00e1 el \u00e1rea del paralelogramo \\mathrm{abs}(\\vert A \\vert) = \\mathrm{abs}(ad) En el caso de que el paralelogramo fuera definido por la matriz $A$ A=\\left[\\begin{array}{cc} a & c\\\\ b & d \\end{array}\\right]=[\\boldsymbol{u}, \\boldsymbol{v}] De igual manera, el valor absoluto del determinante de $A$ ser\u00e1 el \u00e1rea del paralelogramo \\mathrm{abs}(\\vert A \\vert) = \\mathrm{abs}(ad-bc) Ejemplo 1: Demuestre que el \u00e1rea del paralelogramo dado por $A$ A=\\left[\\begin{array}{cc} a & c\\\\ b & d \\end{array}\\right] se encuentra definido como $\\mathrm{abs}(\\vert A \\vert)$.","title":"Matriz de $2 \\times 2$"},{"location":"chapter_03/33_%C3%81rea_Volumen_Regla_de_Cramer_Matriz_Adjunta_Transformaciones_Lineales/#matriz-de-3-times-3","text":"Para una matriz $A$ de $ 3\\times 3$ dada como A=\\left[\\begin{array}{ccc} a & 0 & 0\\\\ 0 & b & 0\\\\ 0 & 0 & c \\end{array}\\right] Geom\u00e9tricamente representar\u00eda un paralelep\u00edpedo de lados con longitud $a$, $b$ y $c$ como se muestra en la figura Al calcular el valor absoluto del determinante de $A$ \\mathrm{abs}(\\vert A \\vert) = \\mathrm{abs}(abc) se observa que el mismo es el volumen del paralelep\u00edpedo generado.","title":"Matriz de $3 \\times 3$"},{"location":"chapter_03/33_%C3%81rea_Volumen_Regla_de_Cramer_Matriz_Adjunta_Transformaciones_Lineales/#regla-de-cramer","text":"Suponga que posee una matriz $A=[\\boldsymbol{a_1}, \\boldsymbol{a_2}, \\dots ,\\boldsymbol{a_n}]$ y existe un vector $\\boldsymbol{b}$ que cumple con $A\\boldsymbol{x}=\\boldsymbol{b}$. Adem\u00e1s se define la matriz aumentada A_i(b)=[\\boldsymbol{a_1}, \\boldsymbol{a_2}, \\dots, \\boldsymbol{b}, \\dots, \\boldsymbol{a_n}] en donde $\\boldsymbol{b}$ se encuentra posicionado en la $i$-\u00e9sima columna. La Regla de Cramer establece que x_i=\\frac{\\vert A_i(b) \\vert}{\\vert A \\vert} Ejemplo 2: Utilice la Regla de Cramer para encontrar la soluci\u00f3n al sistema de ecuaciones lineales 4x_1+x_2=6 5x_1+2x_2=7","title":"Regla de Cramer"},{"location":"chapter_03/33_%C3%81rea_Volumen_Regla_de_Cramer_Matriz_Adjunta_Transformaciones_Lineales/#matriz-adjunta-mathrmadja","text":"Recuerde que al t\u00e9rmino $C_{i,j}$ se le denomin\u00f3 cofactor, y estaba dado por C_{i,j}=(-1)^{(i+j)}\\vert A_{i,j}\\vert La matriz de cofactores $C$ esta definida como C = \\left[\\begin{array}{cccc} C_{11} & C_{12} & \\cdots & C_{\\mathrm{1n}}\\\\ C_{21} & C_{22} & \\cdots & C_{2n}\\\\ \\vdots & \\vdots & \\vdots & \\vdots\\\\ C_{\\mathrm{n1}} & C_{\\mathrm{n2}} & \\cdots & C_{\\mathrm{nn}} \\end{array}\\right] La matriz transpuesta de cofactores, $C^T$, se le conoce como la matriz adjunta \\mathrm{adj}A = C^T = \\left[\\begin{array}{cccc} C_{11} & C_{21} & \\cdots & C_{\\mathrm{n1}}\\\\ C_{12} & C_{22} & \\cdots & C_{\\mathrm{n2}}\\\\ \\vdots & \\vdots & \\vdots & \\vdots\\\\ C_{\\mathrm{1n}} & C_{\\mathrm{2n}} & \\cdots & C_{\\mathrm{nn}} \\end{array}\\right] Ejemplo 3: Encuentre la matriz $\\mathrm{adj}A$ si A=\\left[\\begin{array}{ccc} 2 & 1 & 3\\\\ 1 & -1 & 1\\\\ 1 & 4 & -2 \\end{array}\\right] Si se conoce $\\mathrm{adj}A$ es posible encontrar $A^{-1}$ como A^{-1}=\\frac{1}{\\vert A \\vert}\\mathrm{adj}A Ejemplo 4: Encuentre la matriz inversa de $A$ del Ejemplo 3 por medio de $\\mathrm{adj}A$.","title":"Matriz Adjunta $\\mathrm{adj}A$"},{"location":"chapter_03/33_%C3%81rea_Volumen_Regla_de_Cramer_Matriz_Adjunta_Transformaciones_Lineales/#transformaciones-lineales","text":"Sea $T:\\mathbb{R}^2 \\rightarrow \\mathbb{R}^2$ una transformaci\u00f3n lineal determinada por una matriz $A$ de $2 \\times 2$. Si $S$ es un paralelogramo en $\\mathbb{R}^2$, entonces {\u00e1rea de $T(S)$} $=$ $\\mathrm{abs}\\vert A \\vert \\cdot ${\u00e1rea de $S$} Si $T$ est\u00e1 determinada por una matriz A de $3 \\times 3$, y si $S$ es un paralelep\u00edpedo en $\\mathbb{R}^3$, entonces {volumen de $T(S)$} $=$ $\\mathrm{abs}\\vert A \\vert \\cdot ${volumen de $S$} Ejemplo 5: Dados los vectores $u$ y $v$ que generan el paralelogramo de la figura, si se aplica la transformaci\u00f3n $T:\\mathbb{R}^2 \\rightarrow \\mathbb{R}^2$ para generar los vectores $w$ y $a$ respectivamente. \u00bfCu\u00e1l es el valor del determinante de la matriz $A$? Se debe de cumplir con \\left\\vert\\boldsymbol{w} \\;\\;\\boldsymbol{a} \\right \\vert = \\vert A \\vert\\left\\vert\\boldsymbol{u} \\;\\;\\boldsymbol{v} \\right \\vert \\left\\vert \\begin{matrix} 2 & 0\\\\ 0 & 2 \\end{matrix} \\right \\vert=\\vert A \\vert\\left\\vert \\begin{matrix} 1 & 0\\\\ 0 & 1 \\end{matrix} \\right \\vert 4 = \\vert A \\vert \\cdot 1 Por lo tanto $\\vert A \\vert = 4$ Ejemplo 6: El siguiente ejemplo muestra como el concepto de Transformaci\u00f3n Lineal puede ser aplicada para normalizar los datos de un sistema y as\u00ed realizar una adecuada implementaci\u00f3n del algoritmo K-Means. Este ejemplo se encuentra en el archivo statistics/K-Means.ipynb del repositorio de binder. TAREA SECCI\u00d3N 3.3 1, 3, 5, 9, 11, 13, 19, 21, 23","title":"Transformaciones Lineales"},{"location":"chapter_04/41_Espacios_y_Subespacios_Vectoriales/","text":"4. Espacios Vectoriales Se denomina espacio vectorial al conjunto de todas las entradas posibles de un sistema. 4.1 Espacios y Sub-Espacios Vectoriales Un Espacio Vectorial cumple con: Ser un conjunto no vac\u00edo $V$ de objetos, llamados vectores. Se definen dos operaciones: Suma de vectores Multiplicaci\u00f3n de vectores Axiomas de los Espacios Vectoriales Los espacios vectoriales deben de cumplir con estos 10 axiomas. Sean $\\boldsymbol{u}$, $\\boldsymbol{v}$ vectores y $c$, $d$ escalares. $\\boldsymbol{u} + \\boldsymbol{v}$ est\u00e1 en $V$ $\\boldsymbol{u} + \\boldsymbol{v}=\\boldsymbol{v} + \\boldsymbol{u}$ $(\\boldsymbol{u} + \\boldsymbol{v})+\\boldsymbol{w}=\\boldsymbol{u} + (\\boldsymbol{v}+\\boldsymbol{w})$ $\\boldsymbol{u} + \\boldsymbol{0} = \\boldsymbol{u}$ $\\boldsymbol{u} + (-\\boldsymbol{u}) = \\boldsymbol{0}$ $c\\boldsymbol{u}$ est\u00e1 en $V$ $c(\\boldsymbol{u} + \\boldsymbol{v}) = c\\boldsymbol{u} + c\\boldsymbol{v}$ $(c+d)\\boldsymbol{u} = c\\boldsymbol{u} + d\\boldsymbol{u}$ $c(d\\boldsymbol{u}) = (cd)\\boldsymbol{u}$ $\\boldsymbol{1}\\boldsymbol{u}=\\boldsymbol{u}$ Espacio de Se\u00f1ales Discretas en el Tiempo Una se\u00f1al discreta o se\u00f1al de tiempo discreto es una serie de tiempo que consiste en una secuencia de valores. A diferencia de una se\u00f1al de tiempo continuo, una se\u00f1al de tiempo discreto no es funci\u00f3n de un argumento continuo; sin embargo, puede haber sido obtenido por muestreo de una se\u00f1al de tiempo continuo. Wikipedia La figura muestra un ejemplo de una se\u00f1al de tiempo discreta paraa una se\u00f1al de audio muestreada a $44100$ $Hz$. Decimos que una se\u00f1al discreta en el tiempo se encuentra definida en un espacio $\\mathbb{S}$, el cual consiste en los n\u00fameros doblemente infinitos (negativos y positivos). Esta se\u00f1al puede ser escrita como una secuencia de n\u00fameros \\{ y_k \\} = (\\dots, y_{-2}, y_{-1}, y_0, y_{1}, y_{2}, \\dots) En el caso de la se\u00f1al de audio podr\u00edamos definir dos secuencias \\{ l_k \\} = (\\dots, l_{-2}, l_{-1}, l_0, l_{1}, l_{2}, \\dots) \\{ r_k \\} = (\\dots, r_{-2}, r_{-1}, r_0, r_{1}, r_{2}, \\dots) Donde ${ l_k }$ y ${ r_k }$ son las secuencias de audio del canal izquierdo y derecho respectivamente. Para comprobar que $\\mathbb{S}$ realmente es un espacio para ${ l_k }$ y ${ r_k }$ se deben de cumplir el axioma 1 y 6, pues el resto de axiomas podr\u00e1n ser comprobados como consecuencia de estos dos en particular. Axioma 1 \\{ l_k \\}+\\{ r_k \\}= \\{l_k+ r_k \\} = (\\dots, \\; l_{-2}+r_{-2}, \\; l_{-1}+r_{-1}, \\; l_0+r_0, \\; l_{1}+r_{1}, \\; l_{2}+r_{2}, \\;\\dots) En este caso todos los valores siguen estando en el espacio $\\mathbb{S}$ Axioma 6 Esto aplica tanto para ${ l_k }$ como para ${ r_k }$ c\\{ l_k \\} = (\\dots, cl_{-2}, cl_{-1}, cl_0, cl_{1}, cl_{2}, \\dots) Todos los valores siguen estando en el espacio $\\mathbb{S}$. Ejemplo 1: El siguiente ejemplo muestra como el concepto de Espacio Vectorial puede ser aplicada para comprender las se\u00f1ales discretas en el tiempo. Este ejemplo se encuentra en el archivo signal_processing/fourier_analysis.ipynb del repositorio de binder. Espacio Vectorial de un Polinomio Para $n \\gt 0$, el conjunto $\\mathbb{P}_n$ de polinomios de grado $n$ o menor consiste en todos los polinomios de la forma \\boldsymbol{p}(t)=a_0+a_1t+a_2t^2+\\dots+a_nt^n donde $a_0, a_1, \\dots , a_n$ y $t$ son n\u00fameros reales. El grado de $\\boldsymbol{p}$ es la mayor potencia en $t$, cuyo coeficiente no es cero. Si $\\boldsymbol{p}(t)=a_0 \\neq 0$ decimos que el grado es cero. Si $\\boldsymbol{p}(t)=0$ decimos que es el polinomio cero y su grado no est\u00e1 defenido. Al igual como se hizo en el caso de las se\u00f1ales discretas, podemos comprobar que $\\mathbb{P}$ es realmente un espacio si se cumplen todos los axiomas. Demostraremos los axiomas 1 y 6 pues el resto ser\u00e1 consecuencia de los mismos. Sea s(t)=b_0+b_1t+b_2t^2+\\dots+b_nt^n donde $b_0, b_1, \\dots , b_n$ y $t$ son n\u00fameros reales. Axioma 1 Se cumple que $\\boldsymbol{p} + \\boldsymbol{s}$ se encuentra en $\\mathbb{P}$. \\boldsymbol{p}(t)+\\boldsymbol{s}(t)=(a_0+b_0)+(a_1+b_1)t+(a_2+b_2)t^2+\\dots+(a_n+b_n)t^n Axioma 6 Se cumple que $c\\boldsymbol{p}$ se encuentra en $\\mathbb{P}$. c\\boldsymbol{p}(t)=ca_0+ca_1t+ca_2t^2+\\dots+ca_nt^n con $c$ escalar. Sub-Espacios Es un subconjunto $H$ de $V$ que cumple con tres propiedades: El vector cero de $V$ est\u00e1 en $H$ $\\boldsymbol{u}$ y $\\boldsymbol{v}$ est\u00e1n en $H$ as\u00ed como $\\boldsymbol{u} + \\boldsymbol{v}$ tambi\u00e9n est\u00e1n en $H$ Por cada $\\boldsymbol{u}$ en $H$ el producto $c\\boldsymbol{u}$ tambi\u00e9n est\u00e1 en $H$ Cada sub-espacio es un espacio vectorial. Todo espacio vectorial es un sub-espacio vectorial. \"what? the hell you say\" by satanoid is licensed under CC BY 2.0 El t\u00e9rmino sub-espacio se utiliza cuando al menos dos espacios vectoriales est\u00e1n en mente, con uno dentro del otro, y la frase sub-espacio de $V$ identifica a $V$ como el espacio m\u00e1s grande. Ejemplo 2: Determine si lo que se indica es verdadero o falso: El espacio $\\mathbb{R}^2$ es un sub-espacio de $\\mathbb{R}^3$ El espacio generado por $Gen\\{\\boldsymbol{v_1}, \\boldsymbol{v_2}\\}$ es un sub-espacio de $\\mathbb{R}^3$: Si $\\boldsymbol{v_1}$ y $\\boldsymbol{v_2}$ en $\\mathbb{R}^3$ Si $\\boldsymbol{v_1}$ y $\\boldsymbol{v_2}$ en $\\mathbb{R}^2$ Si $\\boldsymbol{v}$ en $\\mathbb{R}^2$, $Gen\\{\\boldsymbol{v}\\}$ es un sub-espacio de $\\mathbb{R}^2$ Teorema 1 Si $\\boldsymbol{v_1}, \\boldsymbol{v_2}, \\dots , \\boldsymbol{v_p}$ est\u00e1 en un espacio vectorial $V$, entonces Gen \\{ \\boldsymbol{v_1}, \\boldsymbol{v_2}, \\dots , \\boldsymbol{v_p}\\} es un subespacio de $V$. Ejemplo 3: Sea $W$ el conjunto de todos los vectores de la forma W=\\left[\\begin{array}{c} 2\\,s+4\\,t\\\\ 2\\,s\\\\ 2\\,s-3\\,t\\\\ 5\\,t \\end{array}\\right] Desmuestre que $W$ es un sub-espacio de $\\mathbb{R}^4$ Ejemplo 4: Sean los vectores $\\boldsymbol{v_1}$, $\\boldsymbol{v_2}$, $\\boldsymbol{v_3}$ y $\\boldsymbol{w}$ \\boldsymbol{v_1}=\\left[\\begin{array}{c} 1\\\\ 0\\\\ -1 \\end{array}\\right]\\;\\;\\; \\boldsymbol{v_2}=\\left[\\begin{array}{c} 2\\\\ 1\\\\ 3 \\end{array}\\right] \\;\\;\\; \\boldsymbol{v_3}=\\left[\\begin{array}{c} 4\\\\ 2\\\\ 6 \\end{array}\\right] \\;\\;\\; \\boldsymbol{w}=\\left[\\begin{array}{c} 3\\\\ 1\\\\ 2 \\end{array}\\right] \u00bfEst\u00e1 $\\boldsymbol{w}$ en {$\\boldsymbol{v_1}, \\boldsymbol{v_2}, \\boldsymbol{v_3}$}? \u00bfCu\u00e1ntos vectores se encuentran en {$\\boldsymbol{v_1}, \\boldsymbol{v_2}, \\boldsymbol{v_3}$}? \u00bfPuede ser $\\boldsymbol{w}$ un espacio generado por {$\\boldsymbol{v_1}, \\boldsymbol{v_2}, \\boldsymbol{v_3}$}?\u00bfCu\u00e1ntos vectores estan en este espacio? Ejemplo 5: Suponga que tiene la funci\u00f3n y(t)=C_1\\cos{(t)}+C_2 \\sin{(t)} donde $C_1$, $C_2$ y $t$ son variables. Demuestre que el conjunto de todas las funciones descritas por la ecuaci\u00f3n es un espacio vectorial. Link en GeoGebra Un ejemplo de un caso pr\u00e1ctico es la modulaci\u00f3n digital por desplazamiento de fase, PSK. Si deseas saber m\u00e1s puedes leer ac\u00e1 Wikipedia TAREA SECCI\u00d3N 4.1 1, 2, 5, 9, 11, 14, 17","title":"4.1 Espacios y Sub-Espacios Vectoriales"},{"location":"chapter_04/41_Espacios_y_Subespacios_Vectoriales/#4-espacios-vectoriales","text":"Se denomina espacio vectorial al conjunto de todas las entradas posibles de un sistema.","title":"4. Espacios Vectoriales"},{"location":"chapter_04/41_Espacios_y_Subespacios_Vectoriales/#41-espacios-y-sub-espacios-vectoriales","text":"Un Espacio Vectorial cumple con: Ser un conjunto no vac\u00edo $V$ de objetos, llamados vectores. Se definen dos operaciones: Suma de vectores Multiplicaci\u00f3n de vectores","title":"4.1 Espacios y Sub-Espacios Vectoriales"},{"location":"chapter_04/41_Espacios_y_Subespacios_Vectoriales/#axiomas-de-los-espacios-vectoriales","text":"Los espacios vectoriales deben de cumplir con estos 10 axiomas. Sean $\\boldsymbol{u}$, $\\boldsymbol{v}$ vectores y $c$, $d$ escalares. $\\boldsymbol{u} + \\boldsymbol{v}$ est\u00e1 en $V$ $\\boldsymbol{u} + \\boldsymbol{v}=\\boldsymbol{v} + \\boldsymbol{u}$ $(\\boldsymbol{u} + \\boldsymbol{v})+\\boldsymbol{w}=\\boldsymbol{u} + (\\boldsymbol{v}+\\boldsymbol{w})$ $\\boldsymbol{u} + \\boldsymbol{0} = \\boldsymbol{u}$ $\\boldsymbol{u} + (-\\boldsymbol{u}) = \\boldsymbol{0}$ $c\\boldsymbol{u}$ est\u00e1 en $V$ $c(\\boldsymbol{u} + \\boldsymbol{v}) = c\\boldsymbol{u} + c\\boldsymbol{v}$ $(c+d)\\boldsymbol{u} = c\\boldsymbol{u} + d\\boldsymbol{u}$ $c(d\\boldsymbol{u}) = (cd)\\boldsymbol{u}$ $\\boldsymbol{1}\\boldsymbol{u}=\\boldsymbol{u}$","title":"Axiomas de los Espacios Vectoriales"},{"location":"chapter_04/41_Espacios_y_Subespacios_Vectoriales/#espacio-de-senales-discretas-en-el-tiempo","text":"Una se\u00f1al discreta o se\u00f1al de tiempo discreto es una serie de tiempo que consiste en una secuencia de valores. A diferencia de una se\u00f1al de tiempo continuo, una se\u00f1al de tiempo discreto no es funci\u00f3n de un argumento continuo; sin embargo, puede haber sido obtenido por muestreo de una se\u00f1al de tiempo continuo. Wikipedia La figura muestra un ejemplo de una se\u00f1al de tiempo discreta paraa una se\u00f1al de audio muestreada a $44100$ $Hz$. Decimos que una se\u00f1al discreta en el tiempo se encuentra definida en un espacio $\\mathbb{S}$, el cual consiste en los n\u00fameros doblemente infinitos (negativos y positivos). Esta se\u00f1al puede ser escrita como una secuencia de n\u00fameros \\{ y_k \\} = (\\dots, y_{-2}, y_{-1}, y_0, y_{1}, y_{2}, \\dots) En el caso de la se\u00f1al de audio podr\u00edamos definir dos secuencias \\{ l_k \\} = (\\dots, l_{-2}, l_{-1}, l_0, l_{1}, l_{2}, \\dots) \\{ r_k \\} = (\\dots, r_{-2}, r_{-1}, r_0, r_{1}, r_{2}, \\dots) Donde ${ l_k }$ y ${ r_k }$ son las secuencias de audio del canal izquierdo y derecho respectivamente. Para comprobar que $\\mathbb{S}$ realmente es un espacio para ${ l_k }$ y ${ r_k }$ se deben de cumplir el axioma 1 y 6, pues el resto de axiomas podr\u00e1n ser comprobados como consecuencia de estos dos en particular. Axioma 1 \\{ l_k \\}+\\{ r_k \\}= \\{l_k+ r_k \\} = (\\dots, \\; l_{-2}+r_{-2}, \\; l_{-1}+r_{-1}, \\; l_0+r_0, \\; l_{1}+r_{1}, \\; l_{2}+r_{2}, \\;\\dots) En este caso todos los valores siguen estando en el espacio $\\mathbb{S}$ Axioma 6 Esto aplica tanto para ${ l_k }$ como para ${ r_k }$ c\\{ l_k \\} = (\\dots, cl_{-2}, cl_{-1}, cl_0, cl_{1}, cl_{2}, \\dots) Todos los valores siguen estando en el espacio $\\mathbb{S}$. Ejemplo 1: El siguiente ejemplo muestra como el concepto de Espacio Vectorial puede ser aplicada para comprender las se\u00f1ales discretas en el tiempo. Este ejemplo se encuentra en el archivo signal_processing/fourier_analysis.ipynb del repositorio de binder.","title":"Espacio de Se\u00f1ales Discretas en el Tiempo"},{"location":"chapter_04/41_Espacios_y_Subespacios_Vectoriales/#espacio-vectorial-de-un-polinomio","text":"Para $n \\gt 0$, el conjunto $\\mathbb{P}_n$ de polinomios de grado $n$ o menor consiste en todos los polinomios de la forma \\boldsymbol{p}(t)=a_0+a_1t+a_2t^2+\\dots+a_nt^n donde $a_0, a_1, \\dots , a_n$ y $t$ son n\u00fameros reales. El grado de $\\boldsymbol{p}$ es la mayor potencia en $t$, cuyo coeficiente no es cero. Si $\\boldsymbol{p}(t)=a_0 \\neq 0$ decimos que el grado es cero. Si $\\boldsymbol{p}(t)=0$ decimos que es el polinomio cero y su grado no est\u00e1 defenido. Al igual como se hizo en el caso de las se\u00f1ales discretas, podemos comprobar que $\\mathbb{P}$ es realmente un espacio si se cumplen todos los axiomas. Demostraremos los axiomas 1 y 6 pues el resto ser\u00e1 consecuencia de los mismos. Sea s(t)=b_0+b_1t+b_2t^2+\\dots+b_nt^n donde $b_0, b_1, \\dots , b_n$ y $t$ son n\u00fameros reales. Axioma 1 Se cumple que $\\boldsymbol{p} + \\boldsymbol{s}$ se encuentra en $\\mathbb{P}$. \\boldsymbol{p}(t)+\\boldsymbol{s}(t)=(a_0+b_0)+(a_1+b_1)t+(a_2+b_2)t^2+\\dots+(a_n+b_n)t^n Axioma 6 Se cumple que $c\\boldsymbol{p}$ se encuentra en $\\mathbb{P}$. c\\boldsymbol{p}(t)=ca_0+ca_1t+ca_2t^2+\\dots+ca_nt^n con $c$ escalar.","title":"Espacio Vectorial de un Polinomio"},{"location":"chapter_04/41_Espacios_y_Subespacios_Vectoriales/#sub-espacios","text":"Es un subconjunto $H$ de $V$ que cumple con tres propiedades: El vector cero de $V$ est\u00e1 en $H$ $\\boldsymbol{u}$ y $\\boldsymbol{v}$ est\u00e1n en $H$ as\u00ed como $\\boldsymbol{u} + \\boldsymbol{v}$ tambi\u00e9n est\u00e1n en $H$ Por cada $\\boldsymbol{u}$ en $H$ el producto $c\\boldsymbol{u}$ tambi\u00e9n est\u00e1 en $H$ Cada sub-espacio es un espacio vectorial. Todo espacio vectorial es un sub-espacio vectorial. \"what? the hell you say\" by satanoid is licensed under CC BY 2.0 El t\u00e9rmino sub-espacio se utiliza cuando al menos dos espacios vectoriales est\u00e1n en mente, con uno dentro del otro, y la frase sub-espacio de $V$ identifica a $V$ como el espacio m\u00e1s grande. Ejemplo 2: Determine si lo que se indica es verdadero o falso: El espacio $\\mathbb{R}^2$ es un sub-espacio de $\\mathbb{R}^3$ El espacio generado por $Gen\\{\\boldsymbol{v_1}, \\boldsymbol{v_2}\\}$ es un sub-espacio de $\\mathbb{R}^3$: Si $\\boldsymbol{v_1}$ y $\\boldsymbol{v_2}$ en $\\mathbb{R}^3$ Si $\\boldsymbol{v_1}$ y $\\boldsymbol{v_2}$ en $\\mathbb{R}^2$ Si $\\boldsymbol{v}$ en $\\mathbb{R}^2$, $Gen\\{\\boldsymbol{v}\\}$ es un sub-espacio de $\\mathbb{R}^2$ Teorema 1 Si $\\boldsymbol{v_1}, \\boldsymbol{v_2}, \\dots , \\boldsymbol{v_p}$ est\u00e1 en un espacio vectorial $V$, entonces Gen \\{ \\boldsymbol{v_1}, \\boldsymbol{v_2}, \\dots , \\boldsymbol{v_p}\\} es un subespacio de $V$. Ejemplo 3: Sea $W$ el conjunto de todos los vectores de la forma W=\\left[\\begin{array}{c} 2\\,s+4\\,t\\\\ 2\\,s\\\\ 2\\,s-3\\,t\\\\ 5\\,t \\end{array}\\right] Desmuestre que $W$ es un sub-espacio de $\\mathbb{R}^4$ Ejemplo 4: Sean los vectores $\\boldsymbol{v_1}$, $\\boldsymbol{v_2}$, $\\boldsymbol{v_3}$ y $\\boldsymbol{w}$ \\boldsymbol{v_1}=\\left[\\begin{array}{c} 1\\\\ 0\\\\ -1 \\end{array}\\right]\\;\\;\\; \\boldsymbol{v_2}=\\left[\\begin{array}{c} 2\\\\ 1\\\\ 3 \\end{array}\\right] \\;\\;\\; \\boldsymbol{v_3}=\\left[\\begin{array}{c} 4\\\\ 2\\\\ 6 \\end{array}\\right] \\;\\;\\; \\boldsymbol{w}=\\left[\\begin{array}{c} 3\\\\ 1\\\\ 2 \\end{array}\\right] \u00bfEst\u00e1 $\\boldsymbol{w}$ en {$\\boldsymbol{v_1}, \\boldsymbol{v_2}, \\boldsymbol{v_3}$}? \u00bfCu\u00e1ntos vectores se encuentran en {$\\boldsymbol{v_1}, \\boldsymbol{v_2}, \\boldsymbol{v_3}$}? \u00bfPuede ser $\\boldsymbol{w}$ un espacio generado por {$\\boldsymbol{v_1}, \\boldsymbol{v_2}, \\boldsymbol{v_3}$}?\u00bfCu\u00e1ntos vectores estan en este espacio? Ejemplo 5: Suponga que tiene la funci\u00f3n y(t)=C_1\\cos{(t)}+C_2 \\sin{(t)} donde $C_1$, $C_2$ y $t$ son variables. Demuestre que el conjunto de todas las funciones descritas por la ecuaci\u00f3n es un espacio vectorial. Link en GeoGebra Un ejemplo de un caso pr\u00e1ctico es la modulaci\u00f3n digital por desplazamiento de fase, PSK. Si deseas saber m\u00e1s puedes leer ac\u00e1 Wikipedia TAREA SECCI\u00d3N 4.1 1, 2, 5, 9, 11, 14, 17","title":"Sub-Espacios"},{"location":"chapter_04/42_Espacios_Nulo_Columnas_Transformaciones_Lineales/","text":"4. Espacios Vectoriales 4.2 Espacios Nulos, Espacios Columna y Transformaciones Lineales Espacio Nulo El espacio Nulo de una matriz $A$ de $m \\times n$, denotado como $\\mathbf{Nul}A$, es el conjunto de todas las soluciones a la ecuaci\u00f3n homog\u00e9nea A\\boldsymbol{x}=\\boldsymbol{0} En notaci\u00f3n de conjuntos se define como \\mathbf{Nul}A=\\left\\{\\boldsymbol{x}:\\boldsymbol{x} \\in \\mathbb{R}^n \\;\\;\\;\\wedge \\;\\;\\; A\\boldsymbol{x}=0\\right\\} Determinar que un vector $\\boldsymbol{u}$ pertenece a $\\mathbf{Nul}A$ equivale a resolver $A\\boldsymbol{x}=\\boldsymbol{0}$, y encontrar una soluci\u00f3n expl\u00edcita. Ejemplo 1: Encuentre una soluci\u00f3n expl\u00edcita para $\\mathbf{Nul}A$, haciendo una lista de vectores que generan el espacio nulo. A=\\left[\\begin{array}{ccccc} 1 & 3 & -4 & -3 & 1\\\\ 0 & 1 & -3 & 1 & 0\\\\ 0 & 0 & 0 & 0 & 0 \\end{array}\\right] Espacio Columna El espacio Columna de una matriz $A$ de $m \\times n$, denotado como $\\mathbf{Col}A$, es el conjunto de todas las combinaciones lineales de las columnas de $A$. \\mathbf{Col}A=\\mathbf{Gen}\\{\\boldsymbol{a_1}, \\boldsymbol{a_2},\\dots,\\boldsymbol{a_n} \\} Est\u00e1 en un sub-espacio $\\mathbb{R}^m$ siempre y cuando la ecuaci\u00f3n $A\\boldsymbol{x}=\\boldsymbol{b}$ tiene una soluci\u00f3n para cada $\\boldsymbol{b}$ en $\\mathbb{R}^m$. \\mathbf{Col}A=\\left\\{\\boldsymbol{b}:\\boldsymbol{b}=A\\boldsymbol{x} \\;\\;\\;\\exists \\;\\;\\; \\boldsymbol{x}\\in\\mathbb{R}^n \\right\\} Ejemplo 2: Encuentre una matriz $A$ tal que el conjunto dado sea \\mathbf{Col}A=\\left \\{\\left[\\begin{array}{c} 2\\,s+t\\\\ r-s+2\\,t\\\\ 3\\,r+s\\\\ 2\\,r-s-t \\end{array}\\right]\\right \\} Contraste entre $\\mathbf{Nul}A$ y $\\mathbf{Col}A$ Estos dos espacios son muy diferentes, para ello veremos un ejemplo. Ejemplo 3: Dada la matriz $A$ determine el espacio de $\\mathbf{Col}A$ y $\\mathbf{Nul}A$ A=\\left[\\begin{array}{cccc} 2 & 4 & -2 & 1\\\\ -2 & -5 & 7 & 3\\\\ 3 & 7 & -8 & 6 \\end{array}\\right] Cuando una matriz no es cuadrada los vectores en $\\mathbf{Nul}A$ y $\\mathbf{Col}A$ viven en universos distintos. Cuando una matriz es cuadrada los vectores en $\\mathbf{Nul}A$ y $\\mathbf{Col}A$ tienen el vector cero en com\u00fan y tal vez alg\u00fan otro. Ejemplo 4: Dada la matriz $A$ y los vectores $\\boldsymbol{u}$ y $\\boldsymbol{v}$ determine: A=\\left[\\begin{array}{ccc} 1 & 5 & -6\\\\ 2 & 4 & 1\\\\ -3 & 1 & 2 \\end{array}\\right] \\;\\;\\; \\boldsymbol{u}=\\left[\\begin{array}{c} -1\\\\ 4\\\\ 3 \\end{array}\\right]\\;\\;\\; \\boldsymbol{v}=\\left[\\begin{array}{c} 1\\\\ 1\\\\ 1 \\end{array}\\right] Determine si $\\boldsymbol{u}$ est\u00e1 en $\\mathbf{Nul}A$ Determine si $\\boldsymbol{v}$ est\u00e1 en $\\mathbf{Col}A$ Transformaciones Lineales Cuando hablamos de transformaciones lineales el n\u00facleo equivale a encontrar $\\mathbf{Nul}A$ y el rango a $\\mathbf{Col}A$. TAREA SECCI\u00d3N 4.2 1, 3, 5, 7, 13, 16, 17, 20, 24, 17","title":"4.2 Espacios Nulos, Espacios Columna y Transformaciones Lineales"},{"location":"chapter_04/42_Espacios_Nulo_Columnas_Transformaciones_Lineales/#4-espacios-vectoriales","text":"","title":"4. Espacios Vectoriales"},{"location":"chapter_04/42_Espacios_Nulo_Columnas_Transformaciones_Lineales/#42-espacios-nulos-espacios-columna-y-transformaciones-lineales","text":"","title":"4.2 Espacios Nulos, Espacios Columna y Transformaciones Lineales"},{"location":"chapter_04/42_Espacios_Nulo_Columnas_Transformaciones_Lineales/#espacio-nulo","text":"El espacio Nulo de una matriz $A$ de $m \\times n$, denotado como $\\mathbf{Nul}A$, es el conjunto de todas las soluciones a la ecuaci\u00f3n homog\u00e9nea A\\boldsymbol{x}=\\boldsymbol{0} En notaci\u00f3n de conjuntos se define como \\mathbf{Nul}A=\\left\\{\\boldsymbol{x}:\\boldsymbol{x} \\in \\mathbb{R}^n \\;\\;\\;\\wedge \\;\\;\\; A\\boldsymbol{x}=0\\right\\} Determinar que un vector $\\boldsymbol{u}$ pertenece a $\\mathbf{Nul}A$ equivale a resolver $A\\boldsymbol{x}=\\boldsymbol{0}$, y encontrar una soluci\u00f3n expl\u00edcita. Ejemplo 1: Encuentre una soluci\u00f3n expl\u00edcita para $\\mathbf{Nul}A$, haciendo una lista de vectores que generan el espacio nulo. A=\\left[\\begin{array}{ccccc} 1 & 3 & -4 & -3 & 1\\\\ 0 & 1 & -3 & 1 & 0\\\\ 0 & 0 & 0 & 0 & 0 \\end{array}\\right]","title":"Espacio Nulo"},{"location":"chapter_04/42_Espacios_Nulo_Columnas_Transformaciones_Lineales/#espacio-columna","text":"El espacio Columna de una matriz $A$ de $m \\times n$, denotado como $\\mathbf{Col}A$, es el conjunto de todas las combinaciones lineales de las columnas de $A$. \\mathbf{Col}A=\\mathbf{Gen}\\{\\boldsymbol{a_1}, \\boldsymbol{a_2},\\dots,\\boldsymbol{a_n} \\} Est\u00e1 en un sub-espacio $\\mathbb{R}^m$ siempre y cuando la ecuaci\u00f3n $A\\boldsymbol{x}=\\boldsymbol{b}$ tiene una soluci\u00f3n para cada $\\boldsymbol{b}$ en $\\mathbb{R}^m$. \\mathbf{Col}A=\\left\\{\\boldsymbol{b}:\\boldsymbol{b}=A\\boldsymbol{x} \\;\\;\\;\\exists \\;\\;\\; \\boldsymbol{x}\\in\\mathbb{R}^n \\right\\} Ejemplo 2: Encuentre una matriz $A$ tal que el conjunto dado sea \\mathbf{Col}A=\\left \\{\\left[\\begin{array}{c} 2\\,s+t\\\\ r-s+2\\,t\\\\ 3\\,r+s\\\\ 2\\,r-s-t \\end{array}\\right]\\right \\}","title":"Espacio Columna"},{"location":"chapter_04/42_Espacios_Nulo_Columnas_Transformaciones_Lineales/#contraste-entre-mathbfnula-y-mathbfcola","text":"Estos dos espacios son muy diferentes, para ello veremos un ejemplo. Ejemplo 3: Dada la matriz $A$ determine el espacio de $\\mathbf{Col}A$ y $\\mathbf{Nul}A$ A=\\left[\\begin{array}{cccc} 2 & 4 & -2 & 1\\\\ -2 & -5 & 7 & 3\\\\ 3 & 7 & -8 & 6 \\end{array}\\right] Cuando una matriz no es cuadrada los vectores en $\\mathbf{Nul}A$ y $\\mathbf{Col}A$ viven en universos distintos. Cuando una matriz es cuadrada los vectores en $\\mathbf{Nul}A$ y $\\mathbf{Col}A$ tienen el vector cero en com\u00fan y tal vez alg\u00fan otro. Ejemplo 4: Dada la matriz $A$ y los vectores $\\boldsymbol{u}$ y $\\boldsymbol{v}$ determine: A=\\left[\\begin{array}{ccc} 1 & 5 & -6\\\\ 2 & 4 & 1\\\\ -3 & 1 & 2 \\end{array}\\right] \\;\\;\\; \\boldsymbol{u}=\\left[\\begin{array}{c} -1\\\\ 4\\\\ 3 \\end{array}\\right]\\;\\;\\; \\boldsymbol{v}=\\left[\\begin{array}{c} 1\\\\ 1\\\\ 1 \\end{array}\\right] Determine si $\\boldsymbol{u}$ est\u00e1 en $\\mathbf{Nul}A$ Determine si $\\boldsymbol{v}$ est\u00e1 en $\\mathbf{Col}A$","title":"Contraste entre $\\mathbf{Nul}A$ y $\\mathbf{Col}A$"},{"location":"chapter_04/42_Espacios_Nulo_Columnas_Transformaciones_Lineales/#transformaciones-lineales","text":"Cuando hablamos de transformaciones lineales el n\u00facleo equivale a encontrar $\\mathbf{Nul}A$ y el rango a $\\mathbf{Col}A$. TAREA SECCI\u00d3N 4.2 1, 3, 5, 7, 13, 16, 17, 20, 24, 17","title":"Transformaciones Lineales"},{"location":"chapter_04/43_Conjuntos_Linealmente_Independientes/","text":"4. Espacios Vectoriales 4.3 Conjuntos Linealmente Independientes Independencia Respecto a la Soluci\u00f3n de la Ecuaci\u00f3n Homog\u00e9nea Sea un conjunto indexado de vectores {$\\boldsymbol{v_1}, \\boldsymbol{v_2}, \\dots,\\boldsymbol{v_p}$} en $V$ que cumple con la ecuaci\u00f3n vectorial, conocida como relaci\u00f3n de dependencia lineal c_1\\boldsymbol{v_1}+c_2\\boldsymbol{v_2}+\\dots+c_p\\boldsymbol{v_p}=\\boldsymbol{0} Ser\u00e1 linealmente independiente si la ecuaci\u00f3n vectorial tiene solamente soluci\u00f3n trivial Ser\u00e1 linealmente dependiente si tiene soluci\u00f3n no trivial . Independencia Respecto a los Vectores que Componen un Conjunto de Vectores Un conjunto que contiene un \u00fanico vector $\\boldsymbol{v}$ es linealmente independiente si y solo si $\\boldsymbol{v} \\neq \\boldsymbol{0}$ . Un conjunto de dos vectores es linealmente dependiente si y solo si uno de los vectores es m\u00faltiplo del otro . Cualquier conjunto de vectores que contenga al vector cero es linealmente dependiente . Teorema Un conjunto indexado {$\\boldsymbol{v_1}, \\dots,\\boldsymbol{v_p}$} de dos o m\u00e1s vectores, con $\\boldsymbol{v_1} \\neq \\boldsymbol{0}$ , es linealmente dependiente si y solo si alguna $\\boldsymbol{v_j}$ (con $j>0$) es una combinaci\u00f3n lineal de los vectores anteriores, $\\boldsymbol{v_1}, \\dots,\\boldsymbol{v_{j-1}}$. from Imgflip Meme Generator Ejemplo 1: Determine si el conjunto de vectores {$\\boldsymbol{p_1}, \\boldsymbol{p_2},\\boldsymbol{p_3}$} es linealmente independiente \\boldsymbol{p_1}(t)=1 \\;\\;\\;\\boldsymbol{p_2}(t)=t \\;\\;\\;\\boldsymbol{p_3}(t)=4-4t Bases Si $H$ es un sub-espacio de $V$ y el conjunto indexado de vectores $\\boldsymbol{\\beta}=${$\\boldsymbol{b_1}, \\boldsymbol{b_2},\\dots,\\boldsymbol{b_p}$ } en $V$ es una base de $H$ si $\\boldsymbol{\\beta}$ es un conjunto linealmente independiente El sub-espacio generado por $\\boldsymbol{\\beta}$ coincide con $H$, es decir $H=Gen${$\\boldsymbol{b_1}, \\boldsymbol{b_2},\\dots,\\boldsymbol{b_p}$} Ejemplo 2: Sea la matriz identidad $I_3$ determine si es una base para $\\mathbb{R}^3$ I_3=\\left[\\begin{array}{ccc} 1 & 0 & 0\\\\ 0 & 1 & 0\\\\ 0 & 0 & 1 \\end{array}\\right] Se puede observar que cada vector de $I_3$ son linealmente independientes por lo que la matriz identidad $I_3$ es una base para $\\mathbb{R}^3$. Esta base es muy especial y recibe el nombre de Base Est\u00e1ndar para $\\mathbb{R}^3$ . Ejemplo 3: Sean los vectores $\\boldsymbol{v_1}$, $\\boldsymbol{v_2}$ y $\\boldsymbol{v_3}$ determine si {$\\boldsymbol{v_1},\\boldsymbol{v_2},\\boldsymbol{v_3}$} es una base para $\\mathbb{R}^3$. \\boldsymbol{v_1}=\\left[\\begin{array}{c} 2\\\\ -1\\\\ 1 \\end{array}\\right]\\;\\;\\; \\boldsymbol{v_2}=\\left[\\begin{array}{c} 2\\\\ -3\\\\ 2 \\end{array}\\right] \\;\\;\\; \\boldsymbol{v_3}=\\left[\\begin{array}{c} -8\\\\ 5\\\\ 4 \\end{array}\\right] Ejemplo 4: Sea $S=${$\\boldsymbol{1}, \\boldsymbol{t},\\boldsymbol{t}^2,\\dots,\\boldsymbol{t}^n$}. Compruebe que $S$ es una base para $\\mathbb{P}_n$ . Para determinar que $S$ es una base para $\\mathbb{P}_n$ se debe de cumplir que c_0\\cdot \\boldsymbol{1} + c_1\\boldsymbol{t}+c_2\\boldsymbol{t}^2+\\dots+c_p\\boldsymbol{t}^n=\\boldsymbol{0} El teorema fundamental del \u00e1lgebra estable que un polinomio tendr\u00e1 $n$ ceros complejos, sin embargo como $\\mathbb{P}_n$ est\u00e1 restringido a los n\u00fameros reales, la \u00fanica soluci\u00f3n ser\u00e1 el vector cero, por lo que $S$ es una base para $\\mathbb{P}_n$. Conjunto Generador Una base es un conjunto de vectores eficientes que no contiene vectores innecesarios. El Conjunto Generador es la combinaci\u00f3n lineal de vectores en una base que permite describir un espacio de la forma m\u00e1s compacta posible. Teorema del Conjunto Generador Sean $S=${$\\boldsymbol{v_1}, \\boldsymbol{v_2}, \\dots,\\boldsymbol{v_p}$} un conjunto en $V$ y $H=Gen${$\\boldsymbol{v_1}, \\boldsymbol{v_2}, \\dots,\\boldsymbol{v_p}$} Si uno de los vectores de $S$ es una combinaci\u00f3n lineal de los vectores restantes de $S$, el conjunto formado por todos los vectores de $S$ exceptuando el que es combinaci\u00f3n lineal, a\u00fan generar\u00e1 a $H$. Si $H \\neq \\boldsymbol{0}$, existe alg\u00fan subconjunto de $S$ que es una base de $H$. Ejemplo 5: Dados los vectores $\\boldsymbol{v_1}$, $\\boldsymbol{v_2}$, $\\boldsymbol{v_3}$ y sea $H=Gen${$\\boldsymbol{v_1},\\boldsymbol{v_2},\\boldsymbol{v_3}$} encuentre una base para $H$. \\boldsymbol{v_1}=\\left[\\begin{array}{c} 4\\\\ -3\\\\ 7 \\end{array}\\right]= \\;\\;\\; \\boldsymbol{v_2}= \\left[\\begin{array}{c} 1\\\\ 9\\\\ -2 \\end{array}\\right] \\;\\;\\; \\boldsymbol{v_3}=\\left[\\begin{array}{c} 7\\\\ 11\\\\ 6 \\end{array}\\right] Bases para $\\mathbf{Nul}A$ Cuando $\\mathbf{Nul}A$ contiene vectores distintos de cero siempre produce un un conjunto linealmente independiente, por lo que produce una base para $\\mathbf{Nul}A$. Bases para $\\mathbf{Col}A$ Las columnas pivote de una matriz $A$ forman una base para $\\mathbf{Col}A$. Ejemplo 6: Dada la matriz $A$ encuentre una base para $\\mathbf{Col}A$ A=\\left[ \\boldsymbol{a_1} \\;\\; \\boldsymbol{a_2} \\;\\; \\boldsymbol{a_3} \\;\\; \\boldsymbol{a_4} \\;\\; \\boldsymbol{a_5} \\;\\;\\right]=\\left[\\begin{array}{ccccc} 1 & 2 & 3 & -4 & 8\\\\ 1 & 2 & 0 & 2 & 8\\\\ 2 & 4 & -3 & 10 & 9\\\\ 3 & 6 & 0 & 6 & 9 \\end{array}\\right]\\;\\;\\;\\ \\sim \\;\\;\\; B=\\left[\\begin{array}{ccccc} 1 & 2 & 0 & 2 & 0\\\\ 0 & 0 & 1 & -2 & 0\\\\ 0 & 0 & 0 & 0 & 1\\\\ 0 & 0 & 0 & 0 & 0 \\end{array}\\right] Al observar $B$ se puede concluir que las columnas 1, 3 y 5 de $A$ contienen pivotes, por lo que S=\\{\\boldsymbol{a_1}, \\boldsymbol{a_3}, \\boldsymbol{a_5}\\}=\\left\\{\\left[\\begin{array}{c} 1\\\\ 1\\\\ 2\\\\ 3 \\end{array}\\right], \\left[\\begin{array}{c} 3\\\\ 0\\\\ -3\\\\ 0 \\end{array}\\right], \\left[\\begin{array}{c} 8\\\\ 8\\\\ 9\\\\ 9 \\end{array}\\right] \\right\\} Perspectivas para ver una Base Una base es un conjunto generador, por lo que es el conjunto m\u00e1s peque\u00f1o posible para describir un espacio. Una base es un conjunto de vectores linealmente independientes lo m\u00e1s grande posible. TAREA SECCI\u00d3N 4.3 3, 5, 8, 15, 20, 25, 29, 35","title":"4.3 Conjuntos Linealmente Independientes"},{"location":"chapter_04/43_Conjuntos_Linealmente_Independientes/#4-espacios-vectoriales","text":"","title":"4. Espacios Vectoriales"},{"location":"chapter_04/43_Conjuntos_Linealmente_Independientes/#43-conjuntos-linealmente-independientes","text":"","title":"4.3 Conjuntos Linealmente Independientes"},{"location":"chapter_04/43_Conjuntos_Linealmente_Independientes/#independencia-respecto-a-la-solucion-de-la-ecuacion-homogenea","text":"Sea un conjunto indexado de vectores {$\\boldsymbol{v_1}, \\boldsymbol{v_2}, \\dots,\\boldsymbol{v_p}$} en $V$ que cumple con la ecuaci\u00f3n vectorial, conocida como relaci\u00f3n de dependencia lineal c_1\\boldsymbol{v_1}+c_2\\boldsymbol{v_2}+\\dots+c_p\\boldsymbol{v_p}=\\boldsymbol{0} Ser\u00e1 linealmente independiente si la ecuaci\u00f3n vectorial tiene solamente soluci\u00f3n trivial Ser\u00e1 linealmente dependiente si tiene soluci\u00f3n no trivial .","title":"Independencia Respecto a la Soluci\u00f3n de la Ecuaci\u00f3n Homog\u00e9nea"},{"location":"chapter_04/43_Conjuntos_Linealmente_Independientes/#independencia-respecto-a-los-vectores-que-componen-un-conjunto-de-vectores","text":"Un conjunto que contiene un \u00fanico vector $\\boldsymbol{v}$ es linealmente independiente si y solo si $\\boldsymbol{v} \\neq \\boldsymbol{0}$ . Un conjunto de dos vectores es linealmente dependiente si y solo si uno de los vectores es m\u00faltiplo del otro . Cualquier conjunto de vectores que contenga al vector cero es linealmente dependiente . Teorema Un conjunto indexado {$\\boldsymbol{v_1}, \\dots,\\boldsymbol{v_p}$} de dos o m\u00e1s vectores, con $\\boldsymbol{v_1} \\neq \\boldsymbol{0}$ , es linealmente dependiente si y solo si alguna $\\boldsymbol{v_j}$ (con $j>0$) es una combinaci\u00f3n lineal de los vectores anteriores, $\\boldsymbol{v_1}, \\dots,\\boldsymbol{v_{j-1}}$. from Imgflip Meme Generator Ejemplo 1: Determine si el conjunto de vectores {$\\boldsymbol{p_1}, \\boldsymbol{p_2},\\boldsymbol{p_3}$} es linealmente independiente \\boldsymbol{p_1}(t)=1 \\;\\;\\;\\boldsymbol{p_2}(t)=t \\;\\;\\;\\boldsymbol{p_3}(t)=4-4t","title":"Independencia Respecto a los Vectores que Componen un Conjunto de Vectores"},{"location":"chapter_04/43_Conjuntos_Linealmente_Independientes/#bases","text":"Si $H$ es un sub-espacio de $V$ y el conjunto indexado de vectores $\\boldsymbol{\\beta}=${$\\boldsymbol{b_1}, \\boldsymbol{b_2},\\dots,\\boldsymbol{b_p}$ } en $V$ es una base de $H$ si $\\boldsymbol{\\beta}$ es un conjunto linealmente independiente El sub-espacio generado por $\\boldsymbol{\\beta}$ coincide con $H$, es decir $H=Gen${$\\boldsymbol{b_1}, \\boldsymbol{b_2},\\dots,\\boldsymbol{b_p}$} Ejemplo 2: Sea la matriz identidad $I_3$ determine si es una base para $\\mathbb{R}^3$ I_3=\\left[\\begin{array}{ccc} 1 & 0 & 0\\\\ 0 & 1 & 0\\\\ 0 & 0 & 1 \\end{array}\\right] Se puede observar que cada vector de $I_3$ son linealmente independientes por lo que la matriz identidad $I_3$ es una base para $\\mathbb{R}^3$. Esta base es muy especial y recibe el nombre de Base Est\u00e1ndar para $\\mathbb{R}^3$ . Ejemplo 3: Sean los vectores $\\boldsymbol{v_1}$, $\\boldsymbol{v_2}$ y $\\boldsymbol{v_3}$ determine si {$\\boldsymbol{v_1},\\boldsymbol{v_2},\\boldsymbol{v_3}$} es una base para $\\mathbb{R}^3$. \\boldsymbol{v_1}=\\left[\\begin{array}{c} 2\\\\ -1\\\\ 1 \\end{array}\\right]\\;\\;\\; \\boldsymbol{v_2}=\\left[\\begin{array}{c} 2\\\\ -3\\\\ 2 \\end{array}\\right] \\;\\;\\; \\boldsymbol{v_3}=\\left[\\begin{array}{c} -8\\\\ 5\\\\ 4 \\end{array}\\right] Ejemplo 4: Sea $S=${$\\boldsymbol{1}, \\boldsymbol{t},\\boldsymbol{t}^2,\\dots,\\boldsymbol{t}^n$}. Compruebe que $S$ es una base para $\\mathbb{P}_n$ . Para determinar que $S$ es una base para $\\mathbb{P}_n$ se debe de cumplir que c_0\\cdot \\boldsymbol{1} + c_1\\boldsymbol{t}+c_2\\boldsymbol{t}^2+\\dots+c_p\\boldsymbol{t}^n=\\boldsymbol{0} El teorema fundamental del \u00e1lgebra estable que un polinomio tendr\u00e1 $n$ ceros complejos, sin embargo como $\\mathbb{P}_n$ est\u00e1 restringido a los n\u00fameros reales, la \u00fanica soluci\u00f3n ser\u00e1 el vector cero, por lo que $S$ es una base para $\\mathbb{P}_n$.","title":"Bases"},{"location":"chapter_04/43_Conjuntos_Linealmente_Independientes/#conjunto-generador","text":"Una base es un conjunto de vectores eficientes que no contiene vectores innecesarios. El Conjunto Generador es la combinaci\u00f3n lineal de vectores en una base que permite describir un espacio de la forma m\u00e1s compacta posible.","title":"Conjunto Generador"},{"location":"chapter_04/43_Conjuntos_Linealmente_Independientes/#teorema-del-conjunto-generador","text":"Sean $S=${$\\boldsymbol{v_1}, \\boldsymbol{v_2}, \\dots,\\boldsymbol{v_p}$} un conjunto en $V$ y $H=Gen${$\\boldsymbol{v_1}, \\boldsymbol{v_2}, \\dots,\\boldsymbol{v_p}$} Si uno de los vectores de $S$ es una combinaci\u00f3n lineal de los vectores restantes de $S$, el conjunto formado por todos los vectores de $S$ exceptuando el que es combinaci\u00f3n lineal, a\u00fan generar\u00e1 a $H$. Si $H \\neq \\boldsymbol{0}$, existe alg\u00fan subconjunto de $S$ que es una base de $H$. Ejemplo 5: Dados los vectores $\\boldsymbol{v_1}$, $\\boldsymbol{v_2}$, $\\boldsymbol{v_3}$ y sea $H=Gen${$\\boldsymbol{v_1},\\boldsymbol{v_2},\\boldsymbol{v_3}$} encuentre una base para $H$. \\boldsymbol{v_1}=\\left[\\begin{array}{c} 4\\\\ -3\\\\ 7 \\end{array}\\right]= \\;\\;\\; \\boldsymbol{v_2}= \\left[\\begin{array}{c} 1\\\\ 9\\\\ -2 \\end{array}\\right] \\;\\;\\; \\boldsymbol{v_3}=\\left[\\begin{array}{c} 7\\\\ 11\\\\ 6 \\end{array}\\right]","title":"Teorema del Conjunto Generador"},{"location":"chapter_04/43_Conjuntos_Linealmente_Independientes/#bases-para-mathbfnula","text":"Cuando $\\mathbf{Nul}A$ contiene vectores distintos de cero siempre produce un un conjunto linealmente independiente, por lo que produce una base para $\\mathbf{Nul}A$.","title":"Bases para $\\mathbf{Nul}A$"},{"location":"chapter_04/43_Conjuntos_Linealmente_Independientes/#bases-para-mathbfcola","text":"Las columnas pivote de una matriz $A$ forman una base para $\\mathbf{Col}A$. Ejemplo 6: Dada la matriz $A$ encuentre una base para $\\mathbf{Col}A$ A=\\left[ \\boldsymbol{a_1} \\;\\; \\boldsymbol{a_2} \\;\\; \\boldsymbol{a_3} \\;\\; \\boldsymbol{a_4} \\;\\; \\boldsymbol{a_5} \\;\\;\\right]=\\left[\\begin{array}{ccccc} 1 & 2 & 3 & -4 & 8\\\\ 1 & 2 & 0 & 2 & 8\\\\ 2 & 4 & -3 & 10 & 9\\\\ 3 & 6 & 0 & 6 & 9 \\end{array}\\right]\\;\\;\\;\\ \\sim \\;\\;\\; B=\\left[\\begin{array}{ccccc} 1 & 2 & 0 & 2 & 0\\\\ 0 & 0 & 1 & -2 & 0\\\\ 0 & 0 & 0 & 0 & 1\\\\ 0 & 0 & 0 & 0 & 0 \\end{array}\\right] Al observar $B$ se puede concluir que las columnas 1, 3 y 5 de $A$ contienen pivotes, por lo que S=\\{\\boldsymbol{a_1}, \\boldsymbol{a_3}, \\boldsymbol{a_5}\\}=\\left\\{\\left[\\begin{array}{c} 1\\\\ 1\\\\ 2\\\\ 3 \\end{array}\\right], \\left[\\begin{array}{c} 3\\\\ 0\\\\ -3\\\\ 0 \\end{array}\\right], \\left[\\begin{array}{c} 8\\\\ 8\\\\ 9\\\\ 9 \\end{array}\\right] \\right\\}","title":"Bases para $\\mathbf{Col}A$"},{"location":"chapter_04/43_Conjuntos_Linealmente_Independientes/#perspectivas-para-ver-una-base","text":"Una base es un conjunto generador, por lo que es el conjunto m\u00e1s peque\u00f1o posible para describir un espacio. Una base es un conjunto de vectores linealmente independientes lo m\u00e1s grande posible. TAREA SECCI\u00d3N 4.3 3, 5, 8, 15, 20, 25, 29, 35","title":"Perspectivas para ver una Base"},{"location":"chapter_04/44_Sistemas_de_Coordenadas/","text":"4. Espacios Vectoriales 4.4 Sistemas de Coordenadas Una de las razones m\u00e1s importantes para especificar una base $\\boldsymbol{\\beta}$ para un espacio vectorial $V$ es imponer un sistema de coordenadas. Si tenemos una base $\\boldsymbol{\\beta}=[\\boldsymbol{b_1}, \\boldsymbol{b_2},\\dots,\\boldsymbol{b_p}]$ para un espacio $V$, para cada $\\boldsymbol{x}$ en $V$ existe un conjunto de escalares $c_1$, $c_2$, $\\dots$ , $c_n$ tal que \\boldsymbol{x} = c_1\\boldsymbol{b_1}+c_2\\boldsymbol{b_2}+\\cdots+c_n\\boldsymbol{b_n} Siendo estos mismos pesos $c_1$, $c_2$, $\\dots$ , $c_n$ las coordenadas de $\\boldsymbol{x}$ respecto de la base $\\boldsymbol{\\beta}$. Las $\\boldsymbol{\\beta}$-coordenadas de $\\boldsymbol{x}$. \\left[\\boldsymbol{x}\\right]_\\beta=\\left[\\begin{array}{c} c_{1}\\\\ c_{2}\\\\ \\vdots\\\\ c_{n} \\end{array}\\right] $\\boldsymbol{x} \\rightarrow \\left[\\boldsymbol{x}\\right]_\\beta$ es el mapeo de coordenadas. A\\left[\\boldsymbol{x}\\right]_\\beta=\\boldsymbol{x} Ejemplo 1: Encuentre el vector $\\boldsymbol{x}$ determinado por el vector de coordenadas $\\left[\\boldsymbol{x}\\right]_\\beta$ y la base $\\beta$. \\beta=\\left\\{\\left[\\begin{array}{c} 1\\\\ -2\\\\ 3 \\end{array}\\right], \\left[\\begin{array}{c} 5\\\\ 0\\\\ -2 \\end{array}\\right], \\left[\\begin{array}{c} 4\\\\ -3\\\\ 0 \\end{array}\\right]\\right\\} \\;\\;\\; \\left[\\boldsymbol{x}\\right]_\\beta=\\left[\\begin{array}{c} 1\\\\ 0\\\\ -2 \\end{array}\\right] Ejemplo 2: Encuentre el vector de coordenadas $\\left[\\boldsymbol{x}\\right]_\\beta$ de $\\boldsymbol{x}$ respecto de la base $\\beta$. \\boldsymbol{b_1}=\\left[\\begin{array}{c} 1\\\\ -4 \\end{array}\\right] \\;\\;\\; \\boldsymbol{b_2}= \\left[\\begin{array}{c} 2\\\\ -3 \\end{array}\\right]\\;\\;\\; \\boldsymbol{x}=\\left[\\begin{array}{c} -1\\\\ -6 \\end{array}\\right] Coordenadas en $\\mathbb{R}^n$ Ejemplo 3: Encuentre $\\left[\\boldsymbol{x}\\right]_\\beta$ e interprete los resultados obtenidos dada la base $\\beta$ y el vector $\\boldsymbol{x}$ \\beta = \\left\\{\\left[\\begin{array}{c} 2\\\\ 1 \\end{array}\\right] , \\left[\\begin{array}{c} -1\\\\ 1 \\end{array}\\right] \\right\\} \\;\\;\\; \\boldsymbol{x}=\\left[\\begin{array}{c} 4\\\\ 5 \\end{array}\\right] Una transformaci\u00f3n lineal uno a uno de un espacio vectorial $V$ en un espacio vectorial $W$ se llama isomorfismo de $V$ en $W$. Es interesante notar que la notaci\u00f3n y terminolog\u00eda para $V$ y $W$ puede ser distinta, pero al observarlos son indistinguibles. Cada c\u00e1lculo en $V$ se reproduce con exactitud en $W$ y viceversa. Ejemplo 4: Encuentre $\\left[\\boldsymbol{x}\\right]_\\beta$ dada la base $\\beta$ y el vector $\\boldsymbol{x}$ \\beta = \\left\\{\\left[\\begin{array}{c} 3\\\\ 6\\\\ 2 \\end{array}\\right] , \\left[\\begin{array}{c} -1\\\\ 0\\\\ 1 \\end{array}\\right] \\right\\} \\;\\;\\; \\boldsymbol{x}=\\left[\\begin{array}{c} 3\\\\ 12\\\\ 7 \\end{array}\\right] TAREA SECCI\u00d3N 4.4 1, 3, 5, 7, 10, 11, 13, 17, 21, 25, 27, 29","title":"4.4 Sistemas de Coordenadas"},{"location":"chapter_04/44_Sistemas_de_Coordenadas/#4-espacios-vectoriales","text":"","title":"4. Espacios Vectoriales"},{"location":"chapter_04/44_Sistemas_de_Coordenadas/#44-sistemas-de-coordenadas","text":"","title":"4.4 Sistemas de Coordenadas"},{"location":"chapter_04/44_Sistemas_de_Coordenadas/#_1","text":"Una de las razones m\u00e1s importantes para especificar una base $\\boldsymbol{\\beta}$ para un espacio vectorial $V$ es imponer un sistema de coordenadas. Si tenemos una base $\\boldsymbol{\\beta}=[\\boldsymbol{b_1}, \\boldsymbol{b_2},\\dots,\\boldsymbol{b_p}]$ para un espacio $V$, para cada $\\boldsymbol{x}$ en $V$ existe un conjunto de escalares $c_1$, $c_2$, $\\dots$ , $c_n$ tal que \\boldsymbol{x} = c_1\\boldsymbol{b_1}+c_2\\boldsymbol{b_2}+\\cdots+c_n\\boldsymbol{b_n} Siendo estos mismos pesos $c_1$, $c_2$, $\\dots$ , $c_n$ las coordenadas de $\\boldsymbol{x}$ respecto de la base $\\boldsymbol{\\beta}$. Las $\\boldsymbol{\\beta}$-coordenadas de $\\boldsymbol{x}$. \\left[\\boldsymbol{x}\\right]_\\beta=\\left[\\begin{array}{c} c_{1}\\\\ c_{2}\\\\ \\vdots\\\\ c_{n} \\end{array}\\right] $\\boldsymbol{x} \\rightarrow \\left[\\boldsymbol{x}\\right]_\\beta$ es el mapeo de coordenadas. A\\left[\\boldsymbol{x}\\right]_\\beta=\\boldsymbol{x} Ejemplo 1: Encuentre el vector $\\boldsymbol{x}$ determinado por el vector de coordenadas $\\left[\\boldsymbol{x}\\right]_\\beta$ y la base $\\beta$. \\beta=\\left\\{\\left[\\begin{array}{c} 1\\\\ -2\\\\ 3 \\end{array}\\right], \\left[\\begin{array}{c} 5\\\\ 0\\\\ -2 \\end{array}\\right], \\left[\\begin{array}{c} 4\\\\ -3\\\\ 0 \\end{array}\\right]\\right\\} \\;\\;\\; \\left[\\boldsymbol{x}\\right]_\\beta=\\left[\\begin{array}{c} 1\\\\ 0\\\\ -2 \\end{array}\\right] Ejemplo 2: Encuentre el vector de coordenadas $\\left[\\boldsymbol{x}\\right]_\\beta$ de $\\boldsymbol{x}$ respecto de la base $\\beta$. \\boldsymbol{b_1}=\\left[\\begin{array}{c} 1\\\\ -4 \\end{array}\\right] \\;\\;\\; \\boldsymbol{b_2}= \\left[\\begin{array}{c} 2\\\\ -3 \\end{array}\\right]\\;\\;\\; \\boldsymbol{x}=\\left[\\begin{array}{c} -1\\\\ -6 \\end{array}\\right]","title":""},{"location":"chapter_04/44_Sistemas_de_Coordenadas/#coordenadas-en-mathbbrn","text":"Ejemplo 3: Encuentre $\\left[\\boldsymbol{x}\\right]_\\beta$ e interprete los resultados obtenidos dada la base $\\beta$ y el vector $\\boldsymbol{x}$ \\beta = \\left\\{\\left[\\begin{array}{c} 2\\\\ 1 \\end{array}\\right] , \\left[\\begin{array}{c} -1\\\\ 1 \\end{array}\\right] \\right\\} \\;\\;\\; \\boldsymbol{x}=\\left[\\begin{array}{c} 4\\\\ 5 \\end{array}\\right] Una transformaci\u00f3n lineal uno a uno de un espacio vectorial $V$ en un espacio vectorial $W$ se llama isomorfismo de $V$ en $W$. Es interesante notar que la notaci\u00f3n y terminolog\u00eda para $V$ y $W$ puede ser distinta, pero al observarlos son indistinguibles. Cada c\u00e1lculo en $V$ se reproduce con exactitud en $W$ y viceversa. Ejemplo 4: Encuentre $\\left[\\boldsymbol{x}\\right]_\\beta$ dada la base $\\beta$ y el vector $\\boldsymbol{x}$ \\beta = \\left\\{\\left[\\begin{array}{c} 3\\\\ 6\\\\ 2 \\end{array}\\right] , \\left[\\begin{array}{c} -1\\\\ 0\\\\ 1 \\end{array}\\right] \\right\\} \\;\\;\\; \\boldsymbol{x}=\\left[\\begin{array}{c} 3\\\\ 12\\\\ 7 \\end{array}\\right] TAREA SECCI\u00d3N 4.4 1, 3, 5, 7, 10, 11, 13, 17, 21, 25, 27, 29","title":"Coordenadas en $\\mathbb{R}^n$"},{"location":"chapter_04/45_La_Dimension_de_un_Espacio_Vectorial/","text":"4. Espacios Vectoriales 4.5 La Dimensi\u00f3n de un Espacio Vectorial Cuando se tiene una base $\\beta=${$\\boldsymbol{b_1}, \\boldsymbol{b_2},\\dots,\\boldsymbol{b_n}$} para un espacio vectorial $V$, cualquier conjunto que contenga m\u00e1s de $n$ vectores debe de ser linealmente dependiente, es decir, cualquier conjunto linealmente independiente en $V$ no tiene m\u00e1s de $n$ vectores. Si $V$ es generado por un conjunto finito, se dice que $V$ tiene dimensi\u00f3n finita. La dimensi\u00f3n de $V$, $\\mathbf{dim}V$, es el n\u00famero de vectores para una base en $V$. Si $V$ no es generado por un conjunto finito, $V$ tiene dimensi\u00f3n infinita. La base est\u00e1ndar para $\\mathbb{R}^n$ contiene $n$ vectores, por lo que $\\mathbf{dim}\\mathbb{R}^n=n$ . La base polinomial est\u00e1ndar $\\mathbb{P}^n$ contiene $n+1$ vectores, por lo que $\\mathbf{dim}\\mathbb{P}_n=n+1$ . Por ejemplo si $\\beta=${$\\boldsymbol{1}, \\boldsymbol{t},\\boldsymbol{t^2}$}, $\\;\\;\\;\\mathbf{dim}\\mathbb{P}_2=3$ Dimensiones del Sub-espacio $\\mathbb{R}^3$ Los sub-espacios de $\\mathbb{R}^3$ se pueden clasificar por dimensiones de la siguiente manera Sub-espacio de Dimensi\u00f3n Caracter\u00edstica Cero Solo el sub-espacio cero. Uno Cualquier sub-espacio generado por un vector distinto de cero. El sub-espacio es una recta que pasa por el origen. Dos Cualquier sub-espacio generado por dos vectores linealmente independientes. El sub-espacio es un plano que pasa por el origen. Tres Solo el propio $\\mathbb{R}^3$. Tres vectores cualesquiera que sean linealmente independientes. Ejemplo 1: Encuentre la dimensi\u00f3n del sub-espacio de todos los vectores en $\\mathbb{R}^3$ cuyas entradas primera y tercera son iguales. Sub-espacio de Dimensi\u00f3n Finita Si $H$ es un sub-espacio de un espacio vectorial $V$ que es de dimensi\u00f3n finita, entonces \\mathbf{dim}H \\leq \\mathbf{dim}V Se puede decir que el conjunto base de $H$ es menor o igual que el conjunto base de $V$. Teorema de la Base Sea $V$ un espacio vectorial de dimensi\u00f3n $p$ que es mayor o igual a uno.. Cualquier conjunto linealmente independiente de exactamente $p$ elementos en $V$ es una base para $V$. Cualquier conjunto de exactamente $p$ elementos que genera a $V$ es una base para $V$. En resumen, el teorema de la base busca determinar si el conjunto de vectores que componen a $V$ son linealmente independientes para establecer que los mismos generan a $V$ y son una base. Ejemplo 2: Encuentre una base para el sub-espacio e indique su dimensi\u00f3n. \\left\\{\\left[\\begin{array}{c} p-2\\,q\\\\ 2\\,p+5\\,r\\\\ 2\\,r-2\\,q\\\\ 6\\,r-3\\,p \\end{array}\\right] \\right\\}: p,q,r \\in \\mathbb{R} Ejemplo 3: Encuentre una base para el sub-espacio e indique su dimensi\u00f3n. \\left\\{(a,b,c):a-3b+c=0,\\;\\;\\; b-2c=0,\\;\\;\\; 2b-c=0 \\right\\} Dimensiones de $\\mathbf{Nul}A$ y $\\mathbf{Col}A$ La dimensi\u00f3n de $\\mathbf{Nul}A$ es el n\u00famero de variables libres en la ecuaci\u00f3n $A\\boldsymbol{x}=\\boldsymbol{0}$. La dimensi\u00f3n de $\\mathbf{Col}A$ es el n\u00famero de columnas pivote de $A$. Ejemplo 4: Determine las dimensiones de $\\mathbf{Nul}A$ y $\\mathbf{Col}A$ si A=\\left[\\begin{array}{ccccc} 1 & -6 & 9 & -2 & 0\\\\ 0 & 1 & 2 & 5 & -4\\\\ 0 & 0 & 0 & 1 & 5\\\\ 0 & 0 & 0 & 0 & 1 \\end{array}\\right] En este ejemplo se puede observar que existen $4$ columnas pivote para $A$ por lo que $\\mathbf{dim}(\\mathbf{Col}A)=4$; y existe solo una variable libre, por lo que $\\mathbf{dim}(\\mathbf{Nul}A)=1$. TAREA SECCI\u00d3N 4.5 3, 6, 10, 11, 14, 17","title":"4.5 La Dimensi\u00f3n de un Espacio Vectorial"},{"location":"chapter_04/45_La_Dimension_de_un_Espacio_Vectorial/#4-espacios-vectoriales","text":"","title":"4. Espacios Vectoriales"},{"location":"chapter_04/45_La_Dimension_de_un_Espacio_Vectorial/#45-la-dimension-de-un-espacio-vectorial","text":"","title":"4.5 La Dimensi\u00f3n de un Espacio Vectorial"},{"location":"chapter_04/45_La_Dimension_de_un_Espacio_Vectorial/#_1","text":"Cuando se tiene una base $\\beta=${$\\boldsymbol{b_1}, \\boldsymbol{b_2},\\dots,\\boldsymbol{b_n}$} para un espacio vectorial $V$, cualquier conjunto que contenga m\u00e1s de $n$ vectores debe de ser linealmente dependiente, es decir, cualquier conjunto linealmente independiente en $V$ no tiene m\u00e1s de $n$ vectores. Si $V$ es generado por un conjunto finito, se dice que $V$ tiene dimensi\u00f3n finita. La dimensi\u00f3n de $V$, $\\mathbf{dim}V$, es el n\u00famero de vectores para una base en $V$. Si $V$ no es generado por un conjunto finito, $V$ tiene dimensi\u00f3n infinita. La base est\u00e1ndar para $\\mathbb{R}^n$ contiene $n$ vectores, por lo que $\\mathbf{dim}\\mathbb{R}^n=n$ . La base polinomial est\u00e1ndar $\\mathbb{P}^n$ contiene $n+1$ vectores, por lo que $\\mathbf{dim}\\mathbb{P}_n=n+1$ . Por ejemplo si $\\beta=${$\\boldsymbol{1}, \\boldsymbol{t},\\boldsymbol{t^2}$}, $\\;\\;\\;\\mathbf{dim}\\mathbb{P}_2=3$","title":""},{"location":"chapter_04/45_La_Dimension_de_un_Espacio_Vectorial/#dimensiones-del-sub-espacio-mathbbr3","text":"Los sub-espacios de $\\mathbb{R}^3$ se pueden clasificar por dimensiones de la siguiente manera Sub-espacio de Dimensi\u00f3n Caracter\u00edstica Cero Solo el sub-espacio cero. Uno Cualquier sub-espacio generado por un vector distinto de cero. El sub-espacio es una recta que pasa por el origen. Dos Cualquier sub-espacio generado por dos vectores linealmente independientes. El sub-espacio es un plano que pasa por el origen. Tres Solo el propio $\\mathbb{R}^3$. Tres vectores cualesquiera que sean linealmente independientes. Ejemplo 1: Encuentre la dimensi\u00f3n del sub-espacio de todos los vectores en $\\mathbb{R}^3$ cuyas entradas primera y tercera son iguales.","title":"Dimensiones del Sub-espacio $\\mathbb{R}^3$"},{"location":"chapter_04/45_La_Dimension_de_un_Espacio_Vectorial/#sub-espacio-de-dimension-finita","text":"Si $H$ es un sub-espacio de un espacio vectorial $V$ que es de dimensi\u00f3n finita, entonces \\mathbf{dim}H \\leq \\mathbf{dim}V Se puede decir que el conjunto base de $H$ es menor o igual que el conjunto base de $V$.","title":"Sub-espacio de Dimensi\u00f3n Finita"},{"location":"chapter_04/45_La_Dimension_de_un_Espacio_Vectorial/#teorema-de-la-base","text":"Sea $V$ un espacio vectorial de dimensi\u00f3n $p$ que es mayor o igual a uno.. Cualquier conjunto linealmente independiente de exactamente $p$ elementos en $V$ es una base para $V$. Cualquier conjunto de exactamente $p$ elementos que genera a $V$ es una base para $V$. En resumen, el teorema de la base busca determinar si el conjunto de vectores que componen a $V$ son linealmente independientes para establecer que los mismos generan a $V$ y son una base. Ejemplo 2: Encuentre una base para el sub-espacio e indique su dimensi\u00f3n. \\left\\{\\left[\\begin{array}{c} p-2\\,q\\\\ 2\\,p+5\\,r\\\\ 2\\,r-2\\,q\\\\ 6\\,r-3\\,p \\end{array}\\right] \\right\\}: p,q,r \\in \\mathbb{R} Ejemplo 3: Encuentre una base para el sub-espacio e indique su dimensi\u00f3n. \\left\\{(a,b,c):a-3b+c=0,\\;\\;\\; b-2c=0,\\;\\;\\; 2b-c=0 \\right\\}","title":"Teorema de la Base"},{"location":"chapter_04/45_La_Dimension_de_un_Espacio_Vectorial/#dimensiones-de-mathbfnula-y-mathbfcola","text":"La dimensi\u00f3n de $\\mathbf{Nul}A$ es el n\u00famero de variables libres en la ecuaci\u00f3n $A\\boldsymbol{x}=\\boldsymbol{0}$. La dimensi\u00f3n de $\\mathbf{Col}A$ es el n\u00famero de columnas pivote de $A$. Ejemplo 4: Determine las dimensiones de $\\mathbf{Nul}A$ y $\\mathbf{Col}A$ si A=\\left[\\begin{array}{ccccc} 1 & -6 & 9 & -2 & 0\\\\ 0 & 1 & 2 & 5 & -4\\\\ 0 & 0 & 0 & 1 & 5\\\\ 0 & 0 & 0 & 0 & 1 \\end{array}\\right] En este ejemplo se puede observar que existen $4$ columnas pivote para $A$ por lo que $\\mathbf{dim}(\\mathbf{Col}A)=4$; y existe solo una variable libre, por lo que $\\mathbf{dim}(\\mathbf{Nul}A)=1$. TAREA SECCI\u00d3N 4.5 3, 6, 10, 11, 14, 17","title":"Dimensiones de $\\mathbf{Nul}A$ y $\\mathbf{Col}A$"},{"location":"chapter_04/46_Rango/","text":"4. Espacios Vectoriales 4.6 Rango Suponga que tiene una matriz $A$ de $m \\times n$. Cada fila de $A$ tiene $n$ entradas y por lo tanto se puede identificar con un vector en $\\mathbb{R^n}$. El conjunto de todas las combinaciones lineales de los vectores fila se denomina Espacio Fila de $A$, \\mathbf{Fila}A . Cada fila tiene $n$ entradas por lo que cada $\\mathbf{Fila}A$ es un sub-espacio de $\\mathbb{R^n}$. Dada una matriz $A$, el espacio columna de $A^T$ se relaciona con el espacio fila de $A$ por medio de \\mathbf{Col}A^T=\\mathbf{Fila}A Ejemplo 1: Sea la matriz $A$ determine el espacio fila de $A$. A=\\left[\\begin{array}{ccccc} 1 & 3 & 4 & -1 & 2\\\\ 2 & 6 & 6 & 0 & -3\\\\ 3 & 9 & 3 & 6 & -3\\\\ 3 & 9 & 0 & 9 & 0 \\end{array}\\right] En este caso podemos definir a r_1=(1, 3, 4, -1,2) r_2=(2, 6, 6, 0, -3) r_3=(3, 9, 3,6, \u22123) r_4=(3, 9, 0, 9, 0) Por lo que el espacio fila de $A$ ser\u00e1 el sub-espacio generado de $\\mathbb{R^5}$ generado por {$r_1, r_2, r_3, r_4$}. Teorema Si dos matrices $A$ y $B$ son equivalentes por filas, entonces sus espacios fila son iguales. Si $B$ est\u00e1 en forma escalonada, las filas de $B$ diferentes de cero forman una base para el espacio fila de $A$, as\u00ed como para el de $B$. Ejemplo 2: Encuentre bases para el espacio fila, espacio columna y espacio nulo de la matriz $A$ del Ejemplo 1 . Teorema del Rango Las dimensiones del espacio columna y el espacio fila de una matriz $A$ de $m \\times n$ son iguales. Esta dimensi\u00f3n se conoce como Rango de $A$ y es igual al n\u00famero de posiciones pivote en $A$ y satisface la ecuaci\u00f3n \\mathbf{rango}\\;\\;A + \\mathbf{dim}(\\mathbf{Nul}A)=n \\mathbf{dim}(\\mathbf{Col}A) + \\mathbf{dim}(\\mathbf{Nul}A)=n Ejemplo 3: \u00bfCu\u00e1l es la dimensi\u00f3n del espacio columna de $A$? si El espacio nulo de una matriz $A$ de $8 \\times 7$ es de dimensi\u00f3n $2$. El espacio nulo de una matriz $A$ de $4 \\times 7$ es de dimensi\u00f3n $2$. TAREA SECCI\u00d3N 4.6 3, 5, 7, 13, 21, 28","title":"4.6 Rango"},{"location":"chapter_04/46_Rango/#4-espacios-vectoriales","text":"","title":"4. Espacios Vectoriales"},{"location":"chapter_04/46_Rango/#46-rango","text":"Suponga que tiene una matriz $A$ de $m \\times n$. Cada fila de $A$ tiene $n$ entradas y por lo tanto se puede identificar con un vector en $\\mathbb{R^n}$. El conjunto de todas las combinaciones lineales de los vectores fila se denomina Espacio Fila de $A$, \\mathbf{Fila}A . Cada fila tiene $n$ entradas por lo que cada $\\mathbf{Fila}A$ es un sub-espacio de $\\mathbb{R^n}$. Dada una matriz $A$, el espacio columna de $A^T$ se relaciona con el espacio fila de $A$ por medio de \\mathbf{Col}A^T=\\mathbf{Fila}A Ejemplo 1: Sea la matriz $A$ determine el espacio fila de $A$. A=\\left[\\begin{array}{ccccc} 1 & 3 & 4 & -1 & 2\\\\ 2 & 6 & 6 & 0 & -3\\\\ 3 & 9 & 3 & 6 & -3\\\\ 3 & 9 & 0 & 9 & 0 \\end{array}\\right] En este caso podemos definir a r_1=(1, 3, 4, -1,2) r_2=(2, 6, 6, 0, -3) r_3=(3, 9, 3,6, \u22123) r_4=(3, 9, 0, 9, 0) Por lo que el espacio fila de $A$ ser\u00e1 el sub-espacio generado de $\\mathbb{R^5}$ generado por {$r_1, r_2, r_3, r_4$}. Teorema Si dos matrices $A$ y $B$ son equivalentes por filas, entonces sus espacios fila son iguales. Si $B$ est\u00e1 en forma escalonada, las filas de $B$ diferentes de cero forman una base para el espacio fila de $A$, as\u00ed como para el de $B$. Ejemplo 2: Encuentre bases para el espacio fila, espacio columna y espacio nulo de la matriz $A$ del Ejemplo 1 .","title":"4.6 Rango"},{"location":"chapter_04/46_Rango/#teorema-del-rango","text":"Las dimensiones del espacio columna y el espacio fila de una matriz $A$ de $m \\times n$ son iguales. Esta dimensi\u00f3n se conoce como Rango de $A$ y es igual al n\u00famero de posiciones pivote en $A$ y satisface la ecuaci\u00f3n \\mathbf{rango}\\;\\;A + \\mathbf{dim}(\\mathbf{Nul}A)=n \\mathbf{dim}(\\mathbf{Col}A) + \\mathbf{dim}(\\mathbf{Nul}A)=n Ejemplo 3: \u00bfCu\u00e1l es la dimensi\u00f3n del espacio columna de $A$? si El espacio nulo de una matriz $A$ de $8 \\times 7$ es de dimensi\u00f3n $2$. El espacio nulo de una matriz $A$ de $4 \\times 7$ es de dimensi\u00f3n $2$. TAREA SECCI\u00d3N 4.6 3, 5, 7, 13, 21, 28","title":"Teorema del Rango"},{"location":"chapter_04/49_Cadenas_de_Markov/","text":"4. Espacios Vectoriales 4.9 Cadenas de Markov Las Cadenas de Markov son un modelo probabil\u00edstico que se utiliza para describir un experimento que se realiza muchas veces de la misma manera, cuando el resultado de cada ensayo del experimento ser\u00e1 uno de varios posibles resultados especificados, y depende solo del ensayo anterior inmediato. Ejemplo 1: El clima en cierta ciudad es bueno, regular o malo en un d\u00eda determinado. Si el clima es bueno hoy, hay un 40% de probabilidad de que sea bueno ma\u00f1ana, un 30% de probabilidad de que sea regular, y un 30% de que sea malo. Si el clima es regular hoy, existe un 50% de probabilidad de que sea bueno ma\u00f1ana, y un 20% de probabilidad de que sea regular. Por \u00faltimo, si el clima es malo hoy, existe un 30% de probabilidad de que sea bueno ma\u00f1ana y un 40% de que sea regular. Este problema nos servir\u00e1 para definir algunos conceptos de Cadenas de Markov, por lo que estudiaremos en tres partes: Matriz Estoc\u00e1stica, Vector de Probabilidad y Cadena de Markov Probabilidad a Posteriori Ecuaci\u00f3n en Diferencias y Vector de Estado 1. Matriz Estoc\u00e1stica, Vector de Probabilidad y Cadena de Markov En el Ejemplo 1 es necesario definir lo que se nos presenta como una matriz por lo que a partir del enunciado se puede construir como \\begin{array}{ccccc} & Hoy & \\\\ \\mathbf{Bueno} & \\mathbf{Regular} & \\mathbf{Malo} \\\\ 0.40 & 0.50 & 0.30 & \\mathbf{Bueno}\\\\ 0.30 & 0.20 & 0.40 & \\mathbf{Regular} & Manana\\\\ 0.30 & 0.30 & 0.30 & \\mathbf{Malo}\\end{array} A partir de esta matriz podemos definir los siguientes t\u00e9rminos: Vector de Probabilidad : Son vectores que poseen entradas no negativas que representan valores probabil\u00edsticos, donde la suma de todas sus entradas es igual a $1$. El vector $\\boldsymbol{p_1}$ de la matriz anterior es un ejemplo de vector de probabilidad \\boldsymbol{p_1}=\\left[\\begin{array}{c} 4\\\\ 3\\\\ 3 \\end{array}\\right] Matriz Estoc\u00e1stica : Es una matriz cuadrada cuyas columnas son vectores de probabilidad. La matriz que se encontr\u00f3 anteriormente es una matriz estoc\u00e1stica. Cadena de Markov : Es una secuencia de vectores de probabilidad de $\\boldsymbol{x_0}, \\boldsymbol{x_1}, \\boldsymbol{x_2}, \\dots, \\boldsymbol{x_k}$ junto a la matriz estoc\u00e1stica $P$ tal que \\boldsymbol{x_1}=P\\boldsymbol{x_0} \\boldsymbol{x_2}=P\\boldsymbol{x_1} \\vdots \\boldsymbol{x_{k+1}}=P\\boldsymbol{x_k} 2. Probabilidad a Posteriori Se conoce como la probabilidad condicional que es asignada despu\u00e9s de que la evidencia es tomada en cuenta. Wikipedia Con la informaci\u00f3n de la matriz estoc\u00e1stica, Si se dijese que hay una probabilidad del 50% de que haya un buen clima y un 50% de clima regular. \u00bfCu\u00e1les son las probabilidades que el clima sea malo ma\u00f1ana? Si los pron\u00f3sticos para el lunes son \\boldsymbol{x_1}=\\left[\\begin{array}{c} 0\\\\ 0.60\\\\ 0.40 \\end{array}\\right] \u00bfCu\u00e1les son las probabilidades de tener un buen clima el mi\u00e9rcoles? 3. Ecuaci\u00f3n en Diferencias y Vector de Estado A la ecuaci\u00f3n \\boldsymbol{x_{k+1}}= P\\boldsymbol{x};\\;\\;\\;k=0,1,2,\\dots se le denomina Ecuaci\u00f3n en Diferencias y a $\\boldsymbol{x_k}$ se le denomina Vector de Estado . Veamos que sucede con los valores de $\\boldsymbol{x_0}, \\boldsymbol{x_1}, \\boldsymbol{x_2}, \\dots, \\boldsymbol{x_n}$ cuando se repiten muchos experimentos Cuando el vector $\\boldsymbol{x}$ se estabiliza, se dice que ha llegado al estado estable $\\boldsymbol{q}$. Se puede observar que ya no hay cambio entre mediciones suscesivas. En general un vector de estado estable cumple con P\\boldsymbol{q}=\\boldsymbol{q} Determinaci\u00f3n del Vector de Estado Estable Para determinar el vector de estado estable se parte de lo siguiente P\\boldsymbol{x}=\\boldsymbol{x} P\\boldsymbol{x}-\\boldsymbol{x}=\\boldsymbol{0} P\\boldsymbol{x}-I\\boldsymbol{x}=\\boldsymbol{0} (P-I)\\boldsymbol{x}=\\boldsymbol{0} Ejemplo 2: Determine el vector de estado estable del Ejemplo 1 . Teorema Si $P$ es una matriz estoc\u00e1stica regular de $n \\times n$ , $P$ tiene un \u00fanico vector de estado estable $\\boldsymbol{q}$. Si $\\boldsymbol{x_0}$ es cualquier estado inicial y $\\boldsymbol{x_{k+1}}=P\\boldsymbol{x_k}$ para $k=0,1,2,\\dots$ la cadena de Markov converge a $\\boldsymbol{q}$ conforme $k \\rightarrow \\infty$. Puede notar que al final el estado inicial no afecta el estado final a largo plazo. Nota Num\u00e9rica Observe que la ecuaci\u00f3n en diferencias se pudo haber escrito como \\boldsymbol{x_1}=P\\boldsymbol{x_0} \\boldsymbol{x_2}=P\\boldsymbol{x_1}=P(P\\boldsymbol{x_0})=P^2 \\boldsymbol{x_0} \\vdots \\boldsymbol{x_{k+1}}=P^{k+1}\\boldsymbol{x_0} Sin embargo, aunque es lo mismo, encontrar $P^{k+1}$ es m\u00e1s complicado que trabajar de forma recursiva. Tarea Extra: Resuelva el siguiente problema, puede apoyarse usando alg\u00fan lenguaje de programaci\u00f3n. En Guatemala existieron 3 operadores principales de telefon\u00eda m\u00f3vil: Tigo, Claro y Telef\u00f3nica. Los porcentajes de abonados que pose\u00eda cada operador en el mercado eran del 48% para Tigo, del 31% para Claro, y del 21% para Telef\u00f3nica. Luego de un estudio de mercado se concluy\u00f3 lo siguiente: un usuario de Tigo ten\u00eda una probabilidad del 60% de permanecer en Tigo, 20% de pasarse a Claro, y 20% de pasarse a Telef\u00f3nica. Si en ese entonces un usuario era cliente de Claro ten\u00eda una probabilidad del 50% de mantenerse en Claro, un 30% de cambiarse a Tigo, y un 20% de pasarse a Telef\u00f3nica. Si el usuario era cliente de Telef\u00f3nica la probabilidad de que permaneciera en Telef\u00f3nica era del 40%, un 30% de que cambiara a Tigo, y un 30% de que cambiara a Claro. Encuentre la matriz estoc\u00e1stica que modelaba el comportamiento de los clientes de telefon\u00eda m\u00f3vil en Guatemala. Determine el comportamiento a largo plazo que tendr\u00e1n los usuarios de telefon\u00eda m\u00f3vil en Guatemala. \u00bfCu\u00e1l ser\u00e1 la empresa de telefon\u00eda que ten\u00eda mayor crecimiento a largo plazo? Si Telef\u00f3nica fue comprado por Claro, indique como cambia el crecimiento de Tigo y Claro. TAREA SECCI\u00d3N 4.9 1, 2, 3, 5, 9, 16, Tarea Extra","title":"4.9 Cadenas de Markov"},{"location":"chapter_04/49_Cadenas_de_Markov/#4-espacios-vectoriales","text":"","title":"4. Espacios Vectoriales"},{"location":"chapter_04/49_Cadenas_de_Markov/#49-cadenas-de-markov","text":"Las Cadenas de Markov son un modelo probabil\u00edstico que se utiliza para describir un experimento que se realiza muchas veces de la misma manera, cuando el resultado de cada ensayo del experimento ser\u00e1 uno de varios posibles resultados especificados, y depende solo del ensayo anterior inmediato. Ejemplo 1: El clima en cierta ciudad es bueno, regular o malo en un d\u00eda determinado. Si el clima es bueno hoy, hay un 40% de probabilidad de que sea bueno ma\u00f1ana, un 30% de probabilidad de que sea regular, y un 30% de que sea malo. Si el clima es regular hoy, existe un 50% de probabilidad de que sea bueno ma\u00f1ana, y un 20% de probabilidad de que sea regular. Por \u00faltimo, si el clima es malo hoy, existe un 30% de probabilidad de que sea bueno ma\u00f1ana y un 40% de que sea regular. Este problema nos servir\u00e1 para definir algunos conceptos de Cadenas de Markov, por lo que estudiaremos en tres partes: Matriz Estoc\u00e1stica, Vector de Probabilidad y Cadena de Markov Probabilidad a Posteriori Ecuaci\u00f3n en Diferencias y Vector de Estado","title":"4.9 Cadenas de Markov"},{"location":"chapter_04/49_Cadenas_de_Markov/#1-matriz-estocastica-vector-de-probabilidad-y-cadena-de-markov","text":"En el Ejemplo 1 es necesario definir lo que se nos presenta como una matriz por lo que a partir del enunciado se puede construir como \\begin{array}{ccccc} & Hoy & \\\\ \\mathbf{Bueno} & \\mathbf{Regular} & \\mathbf{Malo} \\\\ 0.40 & 0.50 & 0.30 & \\mathbf{Bueno}\\\\ 0.30 & 0.20 & 0.40 & \\mathbf{Regular} & Manana\\\\ 0.30 & 0.30 & 0.30 & \\mathbf{Malo}\\end{array} A partir de esta matriz podemos definir los siguientes t\u00e9rminos: Vector de Probabilidad : Son vectores que poseen entradas no negativas que representan valores probabil\u00edsticos, donde la suma de todas sus entradas es igual a $1$. El vector $\\boldsymbol{p_1}$ de la matriz anterior es un ejemplo de vector de probabilidad \\boldsymbol{p_1}=\\left[\\begin{array}{c} 4\\\\ 3\\\\ 3 \\end{array}\\right] Matriz Estoc\u00e1stica : Es una matriz cuadrada cuyas columnas son vectores de probabilidad. La matriz que se encontr\u00f3 anteriormente es una matriz estoc\u00e1stica. Cadena de Markov : Es una secuencia de vectores de probabilidad de $\\boldsymbol{x_0}, \\boldsymbol{x_1}, \\boldsymbol{x_2}, \\dots, \\boldsymbol{x_k}$ junto a la matriz estoc\u00e1stica $P$ tal que \\boldsymbol{x_1}=P\\boldsymbol{x_0} \\boldsymbol{x_2}=P\\boldsymbol{x_1} \\vdots \\boldsymbol{x_{k+1}}=P\\boldsymbol{x_k}","title":"1. Matriz Estoc\u00e1stica, Vector de Probabilidad y Cadena de Markov"},{"location":"chapter_04/49_Cadenas_de_Markov/#2-probabilidad-a-posteriori","text":"Se conoce como la probabilidad condicional que es asignada despu\u00e9s de que la evidencia es tomada en cuenta. Wikipedia Con la informaci\u00f3n de la matriz estoc\u00e1stica, Si se dijese que hay una probabilidad del 50% de que haya un buen clima y un 50% de clima regular. \u00bfCu\u00e1les son las probabilidades que el clima sea malo ma\u00f1ana? Si los pron\u00f3sticos para el lunes son \\boldsymbol{x_1}=\\left[\\begin{array}{c} 0\\\\ 0.60\\\\ 0.40 \\end{array}\\right] \u00bfCu\u00e1les son las probabilidades de tener un buen clima el mi\u00e9rcoles?","title":"2. Probabilidad a Posteriori"},{"location":"chapter_04/49_Cadenas_de_Markov/#3-ecuacion-en-diferencias-y-vector-de-estado","text":"A la ecuaci\u00f3n \\boldsymbol{x_{k+1}}= P\\boldsymbol{x};\\;\\;\\;k=0,1,2,\\dots se le denomina Ecuaci\u00f3n en Diferencias y a $\\boldsymbol{x_k}$ se le denomina Vector de Estado . Veamos que sucede con los valores de $\\boldsymbol{x_0}, \\boldsymbol{x_1}, \\boldsymbol{x_2}, \\dots, \\boldsymbol{x_n}$ cuando se repiten muchos experimentos Cuando el vector $\\boldsymbol{x}$ se estabiliza, se dice que ha llegado al estado estable $\\boldsymbol{q}$. Se puede observar que ya no hay cambio entre mediciones suscesivas. En general un vector de estado estable cumple con P\\boldsymbol{q}=\\boldsymbol{q}","title":"3. Ecuaci\u00f3n en Diferencias y Vector de Estado"},{"location":"chapter_04/49_Cadenas_de_Markov/#determinacion-del-vector-de-estado-estable","text":"Para determinar el vector de estado estable se parte de lo siguiente P\\boldsymbol{x}=\\boldsymbol{x} P\\boldsymbol{x}-\\boldsymbol{x}=\\boldsymbol{0} P\\boldsymbol{x}-I\\boldsymbol{x}=\\boldsymbol{0} (P-I)\\boldsymbol{x}=\\boldsymbol{0} Ejemplo 2: Determine el vector de estado estable del Ejemplo 1 . Teorema Si $P$ es una matriz estoc\u00e1stica regular de $n \\times n$ , $P$ tiene un \u00fanico vector de estado estable $\\boldsymbol{q}$. Si $\\boldsymbol{x_0}$ es cualquier estado inicial y $\\boldsymbol{x_{k+1}}=P\\boldsymbol{x_k}$ para $k=0,1,2,\\dots$ la cadena de Markov converge a $\\boldsymbol{q}$ conforme $k \\rightarrow \\infty$. Puede notar que al final el estado inicial no afecta el estado final a largo plazo.","title":"Determinaci\u00f3n del Vector de Estado Estable"},{"location":"chapter_04/49_Cadenas_de_Markov/#nota-numerica","text":"Observe que la ecuaci\u00f3n en diferencias se pudo haber escrito como \\boldsymbol{x_1}=P\\boldsymbol{x_0} \\boldsymbol{x_2}=P\\boldsymbol{x_1}=P(P\\boldsymbol{x_0})=P^2 \\boldsymbol{x_0} \\vdots \\boldsymbol{x_{k+1}}=P^{k+1}\\boldsymbol{x_0} Sin embargo, aunque es lo mismo, encontrar $P^{k+1}$ es m\u00e1s complicado que trabajar de forma recursiva. Tarea Extra: Resuelva el siguiente problema, puede apoyarse usando alg\u00fan lenguaje de programaci\u00f3n. En Guatemala existieron 3 operadores principales de telefon\u00eda m\u00f3vil: Tigo, Claro y Telef\u00f3nica. Los porcentajes de abonados que pose\u00eda cada operador en el mercado eran del 48% para Tigo, del 31% para Claro, y del 21% para Telef\u00f3nica. Luego de un estudio de mercado se concluy\u00f3 lo siguiente: un usuario de Tigo ten\u00eda una probabilidad del 60% de permanecer en Tigo, 20% de pasarse a Claro, y 20% de pasarse a Telef\u00f3nica. Si en ese entonces un usuario era cliente de Claro ten\u00eda una probabilidad del 50% de mantenerse en Claro, un 30% de cambiarse a Tigo, y un 20% de pasarse a Telef\u00f3nica. Si el usuario era cliente de Telef\u00f3nica la probabilidad de que permaneciera en Telef\u00f3nica era del 40%, un 30% de que cambiara a Tigo, y un 30% de que cambiara a Claro. Encuentre la matriz estoc\u00e1stica que modelaba el comportamiento de los clientes de telefon\u00eda m\u00f3vil en Guatemala. Determine el comportamiento a largo plazo que tendr\u00e1n los usuarios de telefon\u00eda m\u00f3vil en Guatemala. \u00bfCu\u00e1l ser\u00e1 la empresa de telefon\u00eda que ten\u00eda mayor crecimiento a largo plazo? Si Telef\u00f3nica fue comprado por Claro, indique como cambia el crecimiento de Tigo y Claro. TAREA SECCI\u00d3N 4.9 1, 2, 3, 5, 9, 16, Tarea Extra","title":"Nota Num\u00e9rica"},{"location":"chapter_05/51_Vectores_Propios_Valores_Propios/","text":"5. Vectores Propios y Valores Propios 5.1 Vectores Propios y Valores Propios Para entender el concepto de vectores y valores propios considere los vectores $\\boldsymbol{v}$ y $\\boldsymbol{u}$ que son multiplicados por la matriz $A$ como se muestra en la figura A=\\left[\\begin{array}{cc} 3 & -2\\\\ 1 & 0 \\end{array}\\right] \\;\\;\\; \\boldsymbol{u}=\\left[\\begin{array}{c} -1\\\\ 1 \\end{array}\\right] \\;\\;\\; \\boldsymbol{v}=\\left[\\begin{array}{c} 2\\\\ 1 \\end{array}\\right] Observe que los vectores resultantes son \\boldsymbol{u_1}=\\left[\\begin{array}{c} -5\\\\ -1 \\end{array}\\right] \\;\\;\\; \\boldsymbol{v_1}=\\left[\\begin{array}{c} 4\\\\ 2 \\end{array}\\right] Gr\u00e1ficamente puede notar que, a diferencia de $\\boldsymbol{u}$, el vector $\\boldsymbol{v}$ no cambia de direcci\u00f3n cuando es multiplicado con $A$. Incluso puede notar que esta igualdad se cumple A\\boldsymbol{v}=2\\boldsymbol{v} . En este caso decimos que $\\boldsymbol{v}$ es un vector propio de $A$, y $2$ es un valor propio de $A$. Vector Propio Es un vector $\\boldsymbol{x}$ distinto de cero tal que dada la matriz $A$ de $n \\times n$ cumple con $A\\boldsymbol{x}=\\lambda \\boldsymbol{x}$. Valor Propio Es un escalar $\\lambda$ que cumple con ser soluci\u00f3n no trivial a la ecuaci\u00f3n $A\\boldsymbol{x}=\\lambda \\boldsymbol{x}$. Ejemplo 1: Determine si el vector $\\boldsymbol{u}$ es un vector propio de $A$ A=\\left[\\begin{array}{cc} 5 & 2\\\\ 3 & 6 \\end{array}\\right] \\;\\;\\; \\boldsymbol{u}=\\left[\\begin{array}{c} -1\\\\ 1 \\end{array}\\right] Ejemplo 2: Determine si $\\lambda=4$ es un valor propio de la matriz $A$ A=\\left[\\begin{array}{ccc} 3 & 0 & -1\\\\ 2 & 3 & 1\\\\ -3 & 4 & 5 \\end{array}\\right] Ejemplo 3: Sea $\\lambda = 3$ un valor propio para $A$. Determine una base para el vector propio de $A$ y $\\lambda$. A=\\left[\\begin{array}{ccc} 4 & 0 & -1\\\\ 3 & 0 & 3\\\\ 2 & -2 & 5 \\end{array}\\right] Teorema 1 Los valores propios de una matriz triangular son las entradas sobre su diagonal principal. Ejemplo 4: Indique los valores propios de las matrices $A$ y $B$ A=\\left[\\begin{array}{ccc} 3 & 0 & 0\\\\ 1 & 0 & 0\\\\ -2 & 5 & 4 \\end{array}\\right] \\;\\;\\; B=\\left[\\begin{array}{ccc} 5 & 0 & 0\\\\ 0 & 0 & 0\\\\ -1 & 0 & 3 \\end{array}\\right] Seg\u00fan el Teorema 1, para la matriz $A$ sus valores propios son $\\lambda=3, 0, 4$. Seg\u00fan el Teorema 1, para la matriz $B$ sus valores propios son $\\lambda=5, 0, 3$. Nota: Cero es un valor propio si y solo si la matriz no es invertible. Teorema 2 Si $\\boldsymbol{v_1}, \\boldsymbol{v_2}, \\dots,\\boldsymbol{v_r}$ son vectores propios que corresponden a distintos valores propios $\\lambda_1, \\lambda_2, \\dots,\\lambda_r$ de una matriz $A$ de $n \\times n$, entonces el conjunto {$\\boldsymbol{v_1}, \\boldsymbol{v_2}, \\dots,\\boldsymbol{v_r}$} es linealmente independiente. Espacio Propio Al conjunto de todas las soluciones $(A-\\lambda I)\\boldsymbol{x}=\\boldsymbol{0}$ se denomina espacio propio de $A$ correspondiente a $\\lambda$. Ejemplo 5: Dada la matriz $A$ determine un conjunto de vectores propios linealmente independientes, es decir el espacio propio de $A$. A=\\left[\\begin{array}{ccc} 3 & 0 & 0\\\\ 1 & 0 & 0\\\\ -2 & 5 & 4 \\end{array}\\right] Del ejemplo anterior sabemos que los valores propios de $A$ son $\\lambda=3, 0, 4$. Los vectores propios se obtienen a continuaci\u00f3n Para $\\lambda_1 = 3$ Se debe de cumplir la ecuaci\u00f3n $(A-\\lambda_1 I)\\boldsymbol{v_1}=\\boldsymbol{0}$, por lo que A-\\lambda_1 I=\\left[\\begin{array}{ccc} 3 & 0 & 0\\\\ 1 & 0 & 0\\\\ -2 & 5 & 4 \\end{array}\\right]-3\\left[\\begin{array}{ccc} 1 & 0 & 0\\\\ 0 & 1 & 0\\\\ 0 & 0 & 1 \\end{array}\\right]=\\left[\\begin{array}{ccc} 0 & 0 & 0\\\\ 1 & -3 & 0\\\\ -2 & 5 & 1 \\end{array}\\right] \\sim \\left[\\begin{array}{ccc} 1 & 0 & -3\\\\ 0 & 1 & -1\\\\ 0 & 0 & 0 \\end{array}\\right] \\boldsymbol{v_1}=\\left[\\begin{array}{c} 3\\\\ 1\\\\ 1 \\end{array}\\right] Para $\\lambda_2 = 0$ Se debe de cumplir la ecuaci\u00f3n $(A-\\lambda_2 I)\\boldsymbol{v_2}= A\\boldsymbol{v_2}=\\boldsymbol{0}$, por lo que A=\\left[\\begin{array}{ccc} 3 & 0 & 0\\\\ 1 & 0 & 0\\\\ -2 & 5 & 4 \\end{array}\\right] \\sim \\left[\\begin{array}{ccc} 1 & 0 & 0\\\\ 0 & 1 & \\frac{4}{5}\\\\ 0 & 0 & 0 \\end{array}\\right] \\boldsymbol{v_2}=\\left[\\begin{array}{c} 0\\\\ -\\frac{4}{5}\\\\ 1 \\end{array}\\right]=\\left[\\begin{array}{c} 0\\\\ -4\\\\ 5 \\end{array}\\right] Como se observa, con $\\boldsymbol{v_2}$ se procedi\u00f3 a multiplicar por $5$ para dejar los coeficientes de forma entera, aunque no siempre es posible realizar esto. Para $\\lambda_3 = 4$ Se debe de cumplir la ecuaci\u00f3n $(A-\\lambda_3 I)\\boldsymbol{v_3}= \\boldsymbol{0}$, por lo que A-\\lambda_3 I=\\left[\\begin{array}{ccc} 3 & 0 & 0\\\\ 1 & 0 & 0\\\\ -2 & 5 & 4 \\end{array}\\right]-4\\left[\\begin{array}{ccc} 1 & 0 & 0\\\\ 0 & 1 & 0\\\\ 0 & 0 & 1 \\end{array}\\right]=\\left[\\begin{array}{ccc} -1 & 0 & 0\\\\ 1 & -4 & 0\\\\ -2 & 5 & 0 \\end{array}\\right] \\sim \\left[\\begin{array}{ccc} 1 & 0 & 0\\\\ 0 & 1 & 0\\\\ 0 & 0 & 0 \\end{array}\\right] \\boldsymbol{v_3}=\\left[\\begin{array}{c} 0\\\\ 0\\\\ 1 \\end{array}\\right] El conjunto de vectores propios linealmente independientes ser\u00e1 \\beta = \\left\\{\\boldsymbol{v_1}, \\boldsymbol{v_2}, \\boldsymbol{v_3} \\right\\} = \\left\\{ \\left[\\begin{array}{c} 3\\\\ 1\\\\ 1 \\end{array}\\right], \\left[\\begin{array}{c} 0\\\\ -4\\\\ 5 \\end{array}\\right], \\left[\\begin{array}{c} 0\\\\ 0\\\\ 1 \\end{array}\\right] \\right\\} Vectores propios y ecuaciones en diferencias Dada la ecuaci\u00f3n recursiva \\boldsymbol{x_{k+1}}=A\\boldsymbol{x_k} La forma m\u00e1s sencilla de construir una soluci\u00f3n de la ecuaci\u00f3n recursiva es tomar un vector propio $\\boldsymbol{x_0}$ y su correspondiente valor propio $\\lambda$, y hacer \\boldsymbol{x_k}=\\lambda^k\\boldsymbol{x_0};\\;\\;\\; k=1,2,\\dots Se puede comprobar que esta soluci\u00f3n es una secuencia dado que \\boldsymbol{x_{k+1}}=A\\boldsymbol{x_k}=A(\\lambda^k\\boldsymbol{x_0})=\\lambda(\\lambda^k\\boldsymbol{x_0})=\\lambda^{k+1}\\boldsymbol{x_0} Ejemplo 6: Sean $\\boldsymbol{u}$ y $\\boldsymbol{v}$ vectores propios de una matriz $A$, con valores propios correspondientes $\\lambda$ y $\\mu$. Sean ademas $C_1$ y $C_2$ escalares que satisfacen la ecuaci\u00f3n \\boldsymbol{x_k}=C_1 \\lambda^k \\boldsymbol{u} + C_2 \\mu^k \\boldsymbol{v};\\;\\;\\; k=1,2,\\dots Determine $\\boldsymbol{x_{k+1}}$ Se puede encontrar $\\boldsymbol{x_{k+1}}$ de la siguiente sabiendo que \\boldsymbol{x_{k+1}}=A\\boldsymbol{x_k} Por lo que \\boldsymbol{x_{k+1}}=A(C_1 \\lambda^k \\boldsymbol{u} + C_2 \\mu^k \\boldsymbol{v}) \\boldsymbol{x_{k+1}}=C_1 \\lambda^k A\\boldsymbol{u} + C_2 \\mu^k A\\boldsymbol{v} Como $\\boldsymbol{u}$ tiene asociado $\\lambda$ y $\\boldsymbol{v}$ tiene a $\\mu$ como valores propios respectivamente, se puede escribir \\boldsymbol{x_{k+1}}=C_1 \\lambda^k \\lambda\\boldsymbol{u} + C_2 \\mu^k \\mu\\boldsymbol{v} \\boldsymbol{x_{k+1}}=C_1 \\lambda^{k+1}\\boldsymbol{u} + C_2 \\mu^{k+1}\\boldsymbol{v} TAREA SECCI\u00d3N 5.1 3, 5, 7, 9, 11, 13, 15, 17, 18, 19, 34, 35","title":"5.1 Vectores Propios y Valores Propios"},{"location":"chapter_05/51_Vectores_Propios_Valores_Propios/#5-vectores-propios-y-valores-propios","text":"","title":"5. Vectores Propios y Valores Propios"},{"location":"chapter_05/51_Vectores_Propios_Valores_Propios/#51-vectores-propios-y-valores-propios","text":"Para entender el concepto de vectores y valores propios considere los vectores $\\boldsymbol{v}$ y $\\boldsymbol{u}$ que son multiplicados por la matriz $A$ como se muestra en la figura A=\\left[\\begin{array}{cc} 3 & -2\\\\ 1 & 0 \\end{array}\\right] \\;\\;\\; \\boldsymbol{u}=\\left[\\begin{array}{c} -1\\\\ 1 \\end{array}\\right] \\;\\;\\; \\boldsymbol{v}=\\left[\\begin{array}{c} 2\\\\ 1 \\end{array}\\right] Observe que los vectores resultantes son \\boldsymbol{u_1}=\\left[\\begin{array}{c} -5\\\\ -1 \\end{array}\\right] \\;\\;\\; \\boldsymbol{v_1}=\\left[\\begin{array}{c} 4\\\\ 2 \\end{array}\\right] Gr\u00e1ficamente puede notar que, a diferencia de $\\boldsymbol{u}$, el vector $\\boldsymbol{v}$ no cambia de direcci\u00f3n cuando es multiplicado con $A$. Incluso puede notar que esta igualdad se cumple A\\boldsymbol{v}=2\\boldsymbol{v} . En este caso decimos que $\\boldsymbol{v}$ es un vector propio de $A$, y $2$ es un valor propio de $A$.","title":"5.1 Vectores Propios y Valores Propios"},{"location":"chapter_05/51_Vectores_Propios_Valores_Propios/#vector-propio","text":"Es un vector $\\boldsymbol{x}$ distinto de cero tal que dada la matriz $A$ de $n \\times n$ cumple con $A\\boldsymbol{x}=\\lambda \\boldsymbol{x}$.","title":"Vector Propio"},{"location":"chapter_05/51_Vectores_Propios_Valores_Propios/#valor-propio","text":"Es un escalar $\\lambda$ que cumple con ser soluci\u00f3n no trivial a la ecuaci\u00f3n $A\\boldsymbol{x}=\\lambda \\boldsymbol{x}$. Ejemplo 1: Determine si el vector $\\boldsymbol{u}$ es un vector propio de $A$ A=\\left[\\begin{array}{cc} 5 & 2\\\\ 3 & 6 \\end{array}\\right] \\;\\;\\; \\boldsymbol{u}=\\left[\\begin{array}{c} -1\\\\ 1 \\end{array}\\right] Ejemplo 2: Determine si $\\lambda=4$ es un valor propio de la matriz $A$ A=\\left[\\begin{array}{ccc} 3 & 0 & -1\\\\ 2 & 3 & 1\\\\ -3 & 4 & 5 \\end{array}\\right] Ejemplo 3: Sea $\\lambda = 3$ un valor propio para $A$. Determine una base para el vector propio de $A$ y $\\lambda$. A=\\left[\\begin{array}{ccc} 4 & 0 & -1\\\\ 3 & 0 & 3\\\\ 2 & -2 & 5 \\end{array}\\right] Teorema 1 Los valores propios de una matriz triangular son las entradas sobre su diagonal principal. Ejemplo 4: Indique los valores propios de las matrices $A$ y $B$ A=\\left[\\begin{array}{ccc} 3 & 0 & 0\\\\ 1 & 0 & 0\\\\ -2 & 5 & 4 \\end{array}\\right] \\;\\;\\; B=\\left[\\begin{array}{ccc} 5 & 0 & 0\\\\ 0 & 0 & 0\\\\ -1 & 0 & 3 \\end{array}\\right] Seg\u00fan el Teorema 1, para la matriz $A$ sus valores propios son $\\lambda=3, 0, 4$. Seg\u00fan el Teorema 1, para la matriz $B$ sus valores propios son $\\lambda=5, 0, 3$. Nota: Cero es un valor propio si y solo si la matriz no es invertible. Teorema 2 Si $\\boldsymbol{v_1}, \\boldsymbol{v_2}, \\dots,\\boldsymbol{v_r}$ son vectores propios que corresponden a distintos valores propios $\\lambda_1, \\lambda_2, \\dots,\\lambda_r$ de una matriz $A$ de $n \\times n$, entonces el conjunto {$\\boldsymbol{v_1}, \\boldsymbol{v_2}, \\dots,\\boldsymbol{v_r}$} es linealmente independiente.","title":"Valor Propio"},{"location":"chapter_05/51_Vectores_Propios_Valores_Propios/#espacio-propio","text":"Al conjunto de todas las soluciones $(A-\\lambda I)\\boldsymbol{x}=\\boldsymbol{0}$ se denomina espacio propio de $A$ correspondiente a $\\lambda$. Ejemplo 5: Dada la matriz $A$ determine un conjunto de vectores propios linealmente independientes, es decir el espacio propio de $A$. A=\\left[\\begin{array}{ccc} 3 & 0 & 0\\\\ 1 & 0 & 0\\\\ -2 & 5 & 4 \\end{array}\\right] Del ejemplo anterior sabemos que los valores propios de $A$ son $\\lambda=3, 0, 4$. Los vectores propios se obtienen a continuaci\u00f3n Para $\\lambda_1 = 3$ Se debe de cumplir la ecuaci\u00f3n $(A-\\lambda_1 I)\\boldsymbol{v_1}=\\boldsymbol{0}$, por lo que A-\\lambda_1 I=\\left[\\begin{array}{ccc} 3 & 0 & 0\\\\ 1 & 0 & 0\\\\ -2 & 5 & 4 \\end{array}\\right]-3\\left[\\begin{array}{ccc} 1 & 0 & 0\\\\ 0 & 1 & 0\\\\ 0 & 0 & 1 \\end{array}\\right]=\\left[\\begin{array}{ccc} 0 & 0 & 0\\\\ 1 & -3 & 0\\\\ -2 & 5 & 1 \\end{array}\\right] \\sim \\left[\\begin{array}{ccc} 1 & 0 & -3\\\\ 0 & 1 & -1\\\\ 0 & 0 & 0 \\end{array}\\right] \\boldsymbol{v_1}=\\left[\\begin{array}{c} 3\\\\ 1\\\\ 1 \\end{array}\\right] Para $\\lambda_2 = 0$ Se debe de cumplir la ecuaci\u00f3n $(A-\\lambda_2 I)\\boldsymbol{v_2}= A\\boldsymbol{v_2}=\\boldsymbol{0}$, por lo que A=\\left[\\begin{array}{ccc} 3 & 0 & 0\\\\ 1 & 0 & 0\\\\ -2 & 5 & 4 \\end{array}\\right] \\sim \\left[\\begin{array}{ccc} 1 & 0 & 0\\\\ 0 & 1 & \\frac{4}{5}\\\\ 0 & 0 & 0 \\end{array}\\right] \\boldsymbol{v_2}=\\left[\\begin{array}{c} 0\\\\ -\\frac{4}{5}\\\\ 1 \\end{array}\\right]=\\left[\\begin{array}{c} 0\\\\ -4\\\\ 5 \\end{array}\\right] Como se observa, con $\\boldsymbol{v_2}$ se procedi\u00f3 a multiplicar por $5$ para dejar los coeficientes de forma entera, aunque no siempre es posible realizar esto. Para $\\lambda_3 = 4$ Se debe de cumplir la ecuaci\u00f3n $(A-\\lambda_3 I)\\boldsymbol{v_3}= \\boldsymbol{0}$, por lo que A-\\lambda_3 I=\\left[\\begin{array}{ccc} 3 & 0 & 0\\\\ 1 & 0 & 0\\\\ -2 & 5 & 4 \\end{array}\\right]-4\\left[\\begin{array}{ccc} 1 & 0 & 0\\\\ 0 & 1 & 0\\\\ 0 & 0 & 1 \\end{array}\\right]=\\left[\\begin{array}{ccc} -1 & 0 & 0\\\\ 1 & -4 & 0\\\\ -2 & 5 & 0 \\end{array}\\right] \\sim \\left[\\begin{array}{ccc} 1 & 0 & 0\\\\ 0 & 1 & 0\\\\ 0 & 0 & 0 \\end{array}\\right] \\boldsymbol{v_3}=\\left[\\begin{array}{c} 0\\\\ 0\\\\ 1 \\end{array}\\right] El conjunto de vectores propios linealmente independientes ser\u00e1 \\beta = \\left\\{\\boldsymbol{v_1}, \\boldsymbol{v_2}, \\boldsymbol{v_3} \\right\\} = \\left\\{ \\left[\\begin{array}{c} 3\\\\ 1\\\\ 1 \\end{array}\\right], \\left[\\begin{array}{c} 0\\\\ -4\\\\ 5 \\end{array}\\right], \\left[\\begin{array}{c} 0\\\\ 0\\\\ 1 \\end{array}\\right] \\right\\}","title":"Espacio Propio"},{"location":"chapter_05/51_Vectores_Propios_Valores_Propios/#vectores-propios-y-ecuaciones-en-diferencias","text":"Dada la ecuaci\u00f3n recursiva \\boldsymbol{x_{k+1}}=A\\boldsymbol{x_k} La forma m\u00e1s sencilla de construir una soluci\u00f3n de la ecuaci\u00f3n recursiva es tomar un vector propio $\\boldsymbol{x_0}$ y su correspondiente valor propio $\\lambda$, y hacer \\boldsymbol{x_k}=\\lambda^k\\boldsymbol{x_0};\\;\\;\\; k=1,2,\\dots Se puede comprobar que esta soluci\u00f3n es una secuencia dado que \\boldsymbol{x_{k+1}}=A\\boldsymbol{x_k}=A(\\lambda^k\\boldsymbol{x_0})=\\lambda(\\lambda^k\\boldsymbol{x_0})=\\lambda^{k+1}\\boldsymbol{x_0} Ejemplo 6: Sean $\\boldsymbol{u}$ y $\\boldsymbol{v}$ vectores propios de una matriz $A$, con valores propios correspondientes $\\lambda$ y $\\mu$. Sean ademas $C_1$ y $C_2$ escalares que satisfacen la ecuaci\u00f3n \\boldsymbol{x_k}=C_1 \\lambda^k \\boldsymbol{u} + C_2 \\mu^k \\boldsymbol{v};\\;\\;\\; k=1,2,\\dots Determine $\\boldsymbol{x_{k+1}}$ Se puede encontrar $\\boldsymbol{x_{k+1}}$ de la siguiente sabiendo que \\boldsymbol{x_{k+1}}=A\\boldsymbol{x_k} Por lo que \\boldsymbol{x_{k+1}}=A(C_1 \\lambda^k \\boldsymbol{u} + C_2 \\mu^k \\boldsymbol{v}) \\boldsymbol{x_{k+1}}=C_1 \\lambda^k A\\boldsymbol{u} + C_2 \\mu^k A\\boldsymbol{v} Como $\\boldsymbol{u}$ tiene asociado $\\lambda$ y $\\boldsymbol{v}$ tiene a $\\mu$ como valores propios respectivamente, se puede escribir \\boldsymbol{x_{k+1}}=C_1 \\lambda^k \\lambda\\boldsymbol{u} + C_2 \\mu^k \\mu\\boldsymbol{v} \\boldsymbol{x_{k+1}}=C_1 \\lambda^{k+1}\\boldsymbol{u} + C_2 \\mu^{k+1}\\boldsymbol{v} TAREA SECCI\u00d3N 5.1 3, 5, 7, 9, 11, 13, 15, 17, 18, 19, 34, 35","title":"Vectores propios y ecuaciones en diferencias"},{"location":"chapter_05/52_La_Ecuacion_Caracteristica/","text":"5. Vectores Propios y Valores Propios 5.2 La Ecuaci\u00f3n Caracter\u00edstica Un escalar $\\lambda$ es un valor propio de una matriz $A$ de $n \\times n$ si y solo si $\\lambda$ satisface la ecuaci\u00f3n caracter\u00edstica \\vert A-\\lambda I \\vert = 0 Ejemplo 1: Encuentre los valores propios para $A$ A=\\left[\\begin{array}{ccc} 3 & 1 & 1\\\\ 0 & 5 & 0\\\\ -2 & 0 & 7 \\end{array}\\right] Para encontrar los valores propios de $A$ se debe de calcular $\\vert A-\\lambda I \\vert = 0$ por lo que se tiene A-\\lambda I =\\left[\\begin{array}{ccc} 3-\\lambda & 1 & 1\\\\ 0 & 5-\\lambda & 0\\\\ -2 & 0 & 7-\\lambda \\end{array}\\right] Seleccionando el coeficiente $5-\\lambda$ para calcular el determinante, el mismo se reduce a \\vert A-\\lambda I \\vert = (-1)^{2+2}(5-\\lambda)\\left\\vert\\begin{array}{cc} 3-\\lambda & 1\\\\ -2 & 7-\\lambda \\end{array}\\right\\vert=(5-\\lambda)[(3-\\lambda)(7-\\lambda)+2]=0 (5-\\lambda)(\\lambda^2-10\\lambda+23)=0 Los valores que cumplen con esta ecuaci\u00f3n ser\u00e1n \\lambda=5, \\;\\;\\;\\lambda=5-\\sqrt2, \\;\\;\\; \\lambda=5+\\sqrt2 Nota: Al desarrollo de $(5-\\lambda)(\\lambda^2-10\\lambda+23)$ en $-\\lambda^3+15\\lambda^2-73\\lambda+115$ se le denomina polinomio caracter\u00edstico . Multiplicidad de los Vectores Propios La multiplicidad algebraica de un valor propio $\\lambda$ es siempre mayor o igual que la dimensi\u00f3n del espacio correspondiente a $\\lambda$. Dimensi\u00f3n del Espacio Correspondiente a $\\lambda$ La dimensi\u00f3n del espacio correspondiente a $\\lambda$ se refiere al numero de vectores propios asociados a $\\lambda$. Ejemplo 2: De termine $h$ tal que el espacio propio para $\\lambda=4$ sea bidimensional dada la matriz $A$ A=\\left[\\begin{array}{cccc} 4 & 2 & 3 & 3\\\\ 0 & 2 & h & 3\\\\ 0 & 0 & 4 & 14\\\\ 0 & 0 & 0 & 2 \\end{array}\\right] Este problema plantea que se encuentre la soluci\u00f3n a la ecuaci\u00f3n $(A-4I)\\boldsymbol{x}=\\boldsymbol{0}$ y que la misma tenga dos variables libres. Dado que se est\u00e1 restringido a un valor $h$ en $A$ se buscar\u00e1 llevar a una forma escalonada la expresi\u00f3n $A-4I$ y analizar los posibles resultados. A-4I=\\left[\\begin{array}{cccc} 4 & 2 & 3 & 3\\\\ 0 & 2 & h & 3\\\\ 0 & 0 & 4 & 14\\\\ 0 & 0 & 0 & 2 \\end{array}\\right]-4\\left[\\begin{array}{cccc} 1 & 0 & 0 & 0\\\\ 0 & 1 & 0 & 0\\\\ 0 & 0 & 1 & 0\\\\ 0 & 0 & 0 & 1 \\end{array}\\right]=\\left[\\begin{array}{cccc} 0 & 2 & 3 & 3\\\\ 0 & -2 & h & 3\\\\ 0 & 0 & 0 & 14\\\\ 0 & 0 & 0 & -2 \\end{array}\\right] \\sim \\left[\\begin{array}{cccc} 0 & 2 & 3 & 0\\\\ 0 & 0 & h+3 & 0\\\\ 0 & 0 & 0 & 1\\\\ 0 & 0 & 0 & 0 \\end{array}\\right] Se puede observar que es necesario que $h=-3$ para que solo existan dos variables libres. Similitud de Matrices Se dice que dos matrices $A$ y $B$ de $n \\times n$ son similares si hay una matriz $P$ tal que P^{-1}AP=B\\;\\;\\; \\lor \\;\\;\\; A=PBP^{-1} Si las matrices $A$ y $B$ son similares, entonces tienen el mismo polinomio caracter\u00edstico y por lo tanto los mismos valores propios, incluso con las mismas multiplicidades. Aplicaci\u00f3n de Valores y Vectores Propios a Sistemas Din\u00e1micos Anteriormente se defini\u00f3 que una Cadena de Markov converg\u00eda a un vector de estado estable $\\boldsymbol{q}$, con la ecuaci\u00f3n $P\\boldsymbol{q}=\\boldsymbol{q}$. Resulta que si se profundiza m\u00e1s en esto, se puede observar que realmente se estaba determinando el vector propio de la matriz $P$ con un valor propio $\\lambda=1$. Ahora veremos c\u00f3mo resolver problemas que involucren sistemas din\u00e1micos, para ello definiremos que un sistema din\u00e1mico es aquel que se caracteriza por ser descrito por una matriz estoc\u00e1stica $A$ y un vector de probabilidad $\\boldsymbol{x_k}$, por lo que se cumple la ecuaci\u00f3n en recurrencia \\boldsymbol{x_{k+1}=A\\boldsymbol{x_k}} Como se pudo observar en la secci\u00f3n 5.1, la ecuaci\u00f3n en recurrencia puede ser escrita como \\boldsymbol{x_{k+1}}=\\lambda^{k+1}\\boldsymbol{x_0} Donde en este caso, $\\boldsymbol{x_0}$ es una combinaci\u00f3n lineal de los vectores propios de $A$. Algoritmo para Resolver Sistemas Din\u00e1micos Usar la ecuaci\u00f3n caracter\u00edstica para encontrar los valores propios de $A$. Encontrar los vectores propios de $A$. Encontrar $\\boldsymbol{x_0}$ como una combinaci\u00f3n lineal de los vectores propios de $A$. Determinar la ecuaci\u00f3n en recurrencia $\\boldsymbol{x_{k+1}}=\\lambda^{k+1}\\boldsymbol{x_0}$. Encuentre el vector de estado estable. Ejemplo 3: Dada la matriz estoc\u00e1stica $A$, y el vector $\\boldsymbol{x_0}$ determine el vector de estado estable del sistema din\u00e1mico. A=\\left[\\begin{array}{cc} 0.95 & 0.03\\\\ 0.05 & 0.97 \\end{array}\\right] \\;\\;\\; \\boldsymbol{x_0}=\\left[\\begin{array}{c} 0.60\\\\ 0.40 \\end{array}\\right] A parte de los ejemplos de Cadenas de Markov, tambi\u00e9n existen otras aplicaciones para los vectores y valores propios, uno de ellos es el algoritmo desarrollado por Google para indexar p\u00e1ginas web en su buscador. Puedes leer aqu\u00ed sobre ello. TAREA SECCI\u00d3N 5.2 1, 3, 5, 7, 9, 11, 13, 15, 17, 25, 27","title":"5.2 La Ecuaci\u00f3n Caracter\u00edstica"},{"location":"chapter_05/52_La_Ecuacion_Caracteristica/#5-vectores-propios-y-valores-propios","text":"","title":"5. Vectores Propios y Valores Propios"},{"location":"chapter_05/52_La_Ecuacion_Caracteristica/#52-la-ecuacion-caracteristica","text":"Un escalar $\\lambda$ es un valor propio de una matriz $A$ de $n \\times n$ si y solo si $\\lambda$ satisface la ecuaci\u00f3n caracter\u00edstica \\vert A-\\lambda I \\vert = 0 Ejemplo 1: Encuentre los valores propios para $A$ A=\\left[\\begin{array}{ccc} 3 & 1 & 1\\\\ 0 & 5 & 0\\\\ -2 & 0 & 7 \\end{array}\\right] Para encontrar los valores propios de $A$ se debe de calcular $\\vert A-\\lambda I \\vert = 0$ por lo que se tiene A-\\lambda I =\\left[\\begin{array}{ccc} 3-\\lambda & 1 & 1\\\\ 0 & 5-\\lambda & 0\\\\ -2 & 0 & 7-\\lambda \\end{array}\\right] Seleccionando el coeficiente $5-\\lambda$ para calcular el determinante, el mismo se reduce a \\vert A-\\lambda I \\vert = (-1)^{2+2}(5-\\lambda)\\left\\vert\\begin{array}{cc} 3-\\lambda & 1\\\\ -2 & 7-\\lambda \\end{array}\\right\\vert=(5-\\lambda)[(3-\\lambda)(7-\\lambda)+2]=0 (5-\\lambda)(\\lambda^2-10\\lambda+23)=0 Los valores que cumplen con esta ecuaci\u00f3n ser\u00e1n \\lambda=5, \\;\\;\\;\\lambda=5-\\sqrt2, \\;\\;\\; \\lambda=5+\\sqrt2 Nota: Al desarrollo de $(5-\\lambda)(\\lambda^2-10\\lambda+23)$ en $-\\lambda^3+15\\lambda^2-73\\lambda+115$ se le denomina polinomio caracter\u00edstico .","title":"5.2 La Ecuaci\u00f3n Caracter\u00edstica"},{"location":"chapter_05/52_La_Ecuacion_Caracteristica/#multiplicidad-de-los-vectores-propios","text":"La multiplicidad algebraica de un valor propio $\\lambda$ es siempre mayor o igual que la dimensi\u00f3n del espacio correspondiente a $\\lambda$.","title":"Multiplicidad de los Vectores Propios"},{"location":"chapter_05/52_La_Ecuacion_Caracteristica/#dimension-del-espacio-correspondiente-a-lambda","text":"La dimensi\u00f3n del espacio correspondiente a $\\lambda$ se refiere al numero de vectores propios asociados a $\\lambda$. Ejemplo 2: De termine $h$ tal que el espacio propio para $\\lambda=4$ sea bidimensional dada la matriz $A$ A=\\left[\\begin{array}{cccc} 4 & 2 & 3 & 3\\\\ 0 & 2 & h & 3\\\\ 0 & 0 & 4 & 14\\\\ 0 & 0 & 0 & 2 \\end{array}\\right] Este problema plantea que se encuentre la soluci\u00f3n a la ecuaci\u00f3n $(A-4I)\\boldsymbol{x}=\\boldsymbol{0}$ y que la misma tenga dos variables libres. Dado que se est\u00e1 restringido a un valor $h$ en $A$ se buscar\u00e1 llevar a una forma escalonada la expresi\u00f3n $A-4I$ y analizar los posibles resultados. A-4I=\\left[\\begin{array}{cccc} 4 & 2 & 3 & 3\\\\ 0 & 2 & h & 3\\\\ 0 & 0 & 4 & 14\\\\ 0 & 0 & 0 & 2 \\end{array}\\right]-4\\left[\\begin{array}{cccc} 1 & 0 & 0 & 0\\\\ 0 & 1 & 0 & 0\\\\ 0 & 0 & 1 & 0\\\\ 0 & 0 & 0 & 1 \\end{array}\\right]=\\left[\\begin{array}{cccc} 0 & 2 & 3 & 3\\\\ 0 & -2 & h & 3\\\\ 0 & 0 & 0 & 14\\\\ 0 & 0 & 0 & -2 \\end{array}\\right] \\sim \\left[\\begin{array}{cccc} 0 & 2 & 3 & 0\\\\ 0 & 0 & h+3 & 0\\\\ 0 & 0 & 0 & 1\\\\ 0 & 0 & 0 & 0 \\end{array}\\right] Se puede observar que es necesario que $h=-3$ para que solo existan dos variables libres.","title":"Dimensi\u00f3n del Espacio Correspondiente a $\\lambda$"},{"location":"chapter_05/52_La_Ecuacion_Caracteristica/#similitud-de-matrices","text":"Se dice que dos matrices $A$ y $B$ de $n \\times n$ son similares si hay una matriz $P$ tal que P^{-1}AP=B\\;\\;\\; \\lor \\;\\;\\; A=PBP^{-1} Si las matrices $A$ y $B$ son similares, entonces tienen el mismo polinomio caracter\u00edstico y por lo tanto los mismos valores propios, incluso con las mismas multiplicidades.","title":"Similitud de Matrices"},{"location":"chapter_05/52_La_Ecuacion_Caracteristica/#aplicacion-de-valores-y-vectores-propios-a-sistemas-dinamicos","text":"Anteriormente se defini\u00f3 que una Cadena de Markov converg\u00eda a un vector de estado estable $\\boldsymbol{q}$, con la ecuaci\u00f3n $P\\boldsymbol{q}=\\boldsymbol{q}$. Resulta que si se profundiza m\u00e1s en esto, se puede observar que realmente se estaba determinando el vector propio de la matriz $P$ con un valor propio $\\lambda=1$. Ahora veremos c\u00f3mo resolver problemas que involucren sistemas din\u00e1micos, para ello definiremos que un sistema din\u00e1mico es aquel que se caracteriza por ser descrito por una matriz estoc\u00e1stica $A$ y un vector de probabilidad $\\boldsymbol{x_k}$, por lo que se cumple la ecuaci\u00f3n en recurrencia \\boldsymbol{x_{k+1}=A\\boldsymbol{x_k}} Como se pudo observar en la secci\u00f3n 5.1, la ecuaci\u00f3n en recurrencia puede ser escrita como \\boldsymbol{x_{k+1}}=\\lambda^{k+1}\\boldsymbol{x_0} Donde en este caso, $\\boldsymbol{x_0}$ es una combinaci\u00f3n lineal de los vectores propios de $A$.","title":"Aplicaci\u00f3n de Valores y Vectores Propios a Sistemas Din\u00e1micos"},{"location":"chapter_05/52_La_Ecuacion_Caracteristica/#algoritmo-para-resolver-sistemas-dinamicos","text":"Usar la ecuaci\u00f3n caracter\u00edstica para encontrar los valores propios de $A$. Encontrar los vectores propios de $A$. Encontrar $\\boldsymbol{x_0}$ como una combinaci\u00f3n lineal de los vectores propios de $A$. Determinar la ecuaci\u00f3n en recurrencia $\\boldsymbol{x_{k+1}}=\\lambda^{k+1}\\boldsymbol{x_0}$. Encuentre el vector de estado estable. Ejemplo 3: Dada la matriz estoc\u00e1stica $A$, y el vector $\\boldsymbol{x_0}$ determine el vector de estado estable del sistema din\u00e1mico. A=\\left[\\begin{array}{cc} 0.95 & 0.03\\\\ 0.05 & 0.97 \\end{array}\\right] \\;\\;\\; \\boldsymbol{x_0}=\\left[\\begin{array}{c} 0.60\\\\ 0.40 \\end{array}\\right] A parte de los ejemplos de Cadenas de Markov, tambi\u00e9n existen otras aplicaciones para los vectores y valores propios, uno de ellos es el algoritmo desarrollado por Google para indexar p\u00e1ginas web en su buscador. Puedes leer aqu\u00ed sobre ello. TAREA SECCI\u00d3N 5.2 1, 3, 5, 7, 9, 11, 13, 15, 17, 25, 27","title":"Algoritmo para Resolver Sistemas Din\u00e1micos"},{"location":"chapter_05/53_Diagonalizacion/","text":"5. Vectores Propios y Valores Propios 5.3 Diagonalizaci\u00f3n Suponga que tiene la matrices $A$, $P$ y $D$ de $n \\times n$. A=\\left [\\begin{matrix} a_{11} & a_{12} & \\dots & a_{1n} \\\\ a_{21} & a_{22} & \\dots & a_{2n} \\\\ \\vdots & \\vdots & \\vdots & \\vdots \\\\ a_{n1} & a_{n2} & \\dots & a_{nn} \\end{matrix} \\right ]\\;\\;\\; P=\\left[ \\boldsymbol{v_1}\\; \\boldsymbol{v_2} \\dots \\boldsymbol{v_n} \\right] \\;\\;\\; D=\\left[\\begin{array}{cccc} \\lambda_1 & 0 & \\dots & 0\\\\ 0 & \\lambda_2 & \\dots & 0\\\\ \\vdots & \\vdots & \\vdots & \\vdots\\\\ 0 & 0 & \\dots & \\lambda_n \\end{array}\\right] Donde $\\boldsymbol{v_k}$ es un vector propio de $n$-entradas y $\\lambda_k$ un valor propio asociado a este vector. Partiremos de encontrar AP=A\\left[ \\boldsymbol{v_1} \\; \\boldsymbol{v_2} \\dots \\boldsymbol{v_n} \\right]=\\left[ A\\boldsymbol{v_1}\\; A\\boldsymbol{v_2} \\dots A\\boldsymbol{v_n} \\right] PD=P\\left[\\begin{array}{cccc} \\lambda_1 & 0 & \\dots & 0\\\\ 0 & \\lambda_2 & \\dots & 0\\\\ \\vdots & \\vdots & \\vdots & \\vdots\\\\ 0 & 0 & \\dots & \\lambda_n \\end{array}\\right]= \\left[ P\\left[\\begin{array}{c} \\lambda_1 \\\\ 0\\\\ \\vdots\\\\ 0 \\end{array}\\right]\\; P\\left[\\begin{array}{c} 0 \\\\ \\lambda_2\\\\ \\vdots\\\\ 0 \\end{array}\\right] \\; P\\left[\\begin{array}{c} 0 \\\\ 0\\\\ \\vdots\\\\ \\lambda_n \\end{array}\\right]\\right]=\\left[\\lambda_1 \\boldsymbol{v_1}\\; \\lambda_2\\boldsymbol{v_2} \\dots \\lambda_n\\boldsymbol{v_n} \\right] Debido a que, como se mencion\u00f3 anteriormente, $\\boldsymbol{v_k}$ y $\\lambda_k$ son vectores y valores propios relacionados, es posible establecer la siguiente igualdad AP=PD \\left[ A\\boldsymbol{v_1}\\; A\\boldsymbol{v_2} \\dots A\\boldsymbol{v_n} \\right]=\\left[\\lambda_1 \\boldsymbol{v_1}\\; \\lambda_2\\boldsymbol{v_2} \\dots \\lambda_n\\boldsymbol{v_n} \\right] De esto, se puede obtener APP^{-1}=PDP^{-1} A=PDP^{-1} Adem\u00e1s se puede decir que $A$ es similar a $D$ y por lo tanto $A$ es diagonizable. Se puede observar que $A$ es diagonizable si y solo si $A$ tiene $n$ vectores linealmente independientes. Diagonalizaci\u00f3n para el C\u00e1lculo de Potencia de Matrices Sea $A$ la matriz diagonizable A=PDP^{-1} Podemos calcular $A^2$ como A^2=(PDP^{-1})(PDP^{-1})=PD(P^{-1}P)DP^{-1}=PD^2P^{-1} Sucede que $D^2$ es mucho m\u00e1s f\u00e1cil de calcular, pues al ser una matriz diagonal se obtiene como D^2=\\left[\\begin{array}{cccc} \\lambda_1^2 & 0 & \\dots & 0\\\\ 0 & \\lambda_2^2 & \\dots & 0\\\\ \\vdots & \\vdots & \\vdots & \\vdots\\\\ 0 & 0 & \\dots & \\lambda_n^2 \\end{array}\\right] La forma m\u00e1s general de una potencia de matrices est\u00e1 dada por A^k=PD^kP^{-1} Siendo D^k=\\left[\\begin{array}{cccc} \\lambda_1^k & 0 & \\dots & 0\\\\ 0 & \\lambda_2^k & \\dots & 0\\\\ \\vdots & \\vdots & \\vdots & \\vdots\\\\ 0 & 0 & \\dots & \\lambda_n^k \\end{array}\\right] Ejemplo 1: Dados $A$, $P$ y $D$ encuentre $A^{5}$ A=\\left[\\begin{array}{cc} 9 & -4\\\\ 12 & -5 \\end{array}\\right] \\;\\;\\; P=\\left[\\begin{array}{cc} 1 & 2\\\\ 2 & 3 \\end{array}\\right] \\;\\;\\; D=\\left[\\begin{array}{cc} 1 & 0\\\\ 0 & 3 \\end{array}\\right] Para encontrar $A^{5}$ utilizaremos la siguiente expresi\u00f3n A^{5}=PD^{5}P^{-1} La inversa de $P$ puede ser obtenida como P^{-1}=\\frac{1}{-1}\\left[\\begin{array}{cc} 3 & -2\\\\ -2 & 1 \\end{array}\\right]=\\left[\\begin{array}{cc} -3 & 2\\\\ 2 & -1 \\end{array}\\right] Entonces A^{5}=\\left[\\begin{array}{cc} 1 & 2\\\\ 2 & 3 \\end{array}\\right]\\left[\\begin{array}{cc} 1 & 0\\\\ 0 & 3 \\end{array}\\right]^{5}\\left[\\begin{array}{cc} -3 & 2\\\\ 2 & -1 \\end{array}\\right]=\\left[\\begin{array}{cc} 1 & 2\\\\ 2 & 3 \\end{array}\\right]\\left[\\begin{array}{cc} 1 & 0\\\\ 0 & 243 \\end{array}\\right]\\left[\\begin{array}{cc} -3 & 2\\\\ 2 & -1 \\end{array}\\right] A^{5}=\\left[\\begin{array}{cc} 969 & -484\\\\ 1452 & -725 \\end{array}\\right] \u00bfC\u00f3mo Diagonalizar una Matriz? El algoritmo para diagonalizar una matriz $A$ de $n \\times n$ es el siguiente: Determinar los valores propios de $A$ Encontrar los vectores propios de $A$ Construir $P$ con los vectores propios obtenidos y encontrar $P^{-1}$ Construir $D$ con los valores propios. Ejemplo 2: Encuentre la diagonalizaci\u00f3n de la matriz $A$ si A=\\left[\\begin{array}{ccc} 3 & 0 & 0\\\\ 1 & 0 & 0\\\\ -2 & 5 & 4 \\end{array}\\right] Ejemplo 3: Diagonalice la matriz $A$ si los valores propios de la misma son $\\lambda=0$ y $\\lambda=1$. A=\\left[\\begin{array}{ccc} 0 & -1 & -1\\\\ 1 & 2 & 1\\\\ -1 & -1 & 0 \\end{array}\\right] Ejemplo 4 Determine $A^{15}$ A=\\left[\\begin{array}{ccccc} -\\frac{2713}{228} & \\frac{175}{38} & -\\frac{175}{228} & \\frac{700}{19} & \\frac{175}{19}\\\\ -\\frac{326}{57} & \\frac{51}{19} & \\frac{22}{57} & \\frac{256}{19} & \\frac{64}{19}\\\\ -\\frac{941}{228} & \\frac{47}{38} & \\frac{1093}{228} & \\frac{188}{19} & \\frac{47}{19}\\\\ -\\frac{929}{228} & \\frac{59}{38} & -\\frac{59}{228} & \\frac{255}{19} & \\frac{59}{19}\\\\ 0 & 0 & 0 & 0 & 1 \\end{array}\\right] Una condici\u00f3n que es suficiente para determinar si una matriz de $n \\times n$ es diagonizable es si tiene $n$ valores propios distintos. TAREA SECCI\u00d3N 5.3 1, 3, 4, 5, 11, 13, 15, 17, 19, 27, 29","title":"5.3 Diagonalizaci\u00f3n"},{"location":"chapter_05/53_Diagonalizacion/#5-vectores-propios-y-valores-propios","text":"","title":"5. Vectores Propios y Valores Propios"},{"location":"chapter_05/53_Diagonalizacion/#53-diagonalizacion","text":"Suponga que tiene la matrices $A$, $P$ y $D$ de $n \\times n$. A=\\left [\\begin{matrix} a_{11} & a_{12} & \\dots & a_{1n} \\\\ a_{21} & a_{22} & \\dots & a_{2n} \\\\ \\vdots & \\vdots & \\vdots & \\vdots \\\\ a_{n1} & a_{n2} & \\dots & a_{nn} \\end{matrix} \\right ]\\;\\;\\; P=\\left[ \\boldsymbol{v_1}\\; \\boldsymbol{v_2} \\dots \\boldsymbol{v_n} \\right] \\;\\;\\; D=\\left[\\begin{array}{cccc} \\lambda_1 & 0 & \\dots & 0\\\\ 0 & \\lambda_2 & \\dots & 0\\\\ \\vdots & \\vdots & \\vdots & \\vdots\\\\ 0 & 0 & \\dots & \\lambda_n \\end{array}\\right] Donde $\\boldsymbol{v_k}$ es un vector propio de $n$-entradas y $\\lambda_k$ un valor propio asociado a este vector. Partiremos de encontrar AP=A\\left[ \\boldsymbol{v_1} \\; \\boldsymbol{v_2} \\dots \\boldsymbol{v_n} \\right]=\\left[ A\\boldsymbol{v_1}\\; A\\boldsymbol{v_2} \\dots A\\boldsymbol{v_n} \\right] PD=P\\left[\\begin{array}{cccc} \\lambda_1 & 0 & \\dots & 0\\\\ 0 & \\lambda_2 & \\dots & 0\\\\ \\vdots & \\vdots & \\vdots & \\vdots\\\\ 0 & 0 & \\dots & \\lambda_n \\end{array}\\right]= \\left[ P\\left[\\begin{array}{c} \\lambda_1 \\\\ 0\\\\ \\vdots\\\\ 0 \\end{array}\\right]\\; P\\left[\\begin{array}{c} 0 \\\\ \\lambda_2\\\\ \\vdots\\\\ 0 \\end{array}\\right] \\; P\\left[\\begin{array}{c} 0 \\\\ 0\\\\ \\vdots\\\\ \\lambda_n \\end{array}\\right]\\right]=\\left[\\lambda_1 \\boldsymbol{v_1}\\; \\lambda_2\\boldsymbol{v_2} \\dots \\lambda_n\\boldsymbol{v_n} \\right] Debido a que, como se mencion\u00f3 anteriormente, $\\boldsymbol{v_k}$ y $\\lambda_k$ son vectores y valores propios relacionados, es posible establecer la siguiente igualdad AP=PD \\left[ A\\boldsymbol{v_1}\\; A\\boldsymbol{v_2} \\dots A\\boldsymbol{v_n} \\right]=\\left[\\lambda_1 \\boldsymbol{v_1}\\; \\lambda_2\\boldsymbol{v_2} \\dots \\lambda_n\\boldsymbol{v_n} \\right] De esto, se puede obtener APP^{-1}=PDP^{-1} A=PDP^{-1} Adem\u00e1s se puede decir que $A$ es similar a $D$ y por lo tanto $A$ es diagonizable. Se puede observar que $A$ es diagonizable si y solo si $A$ tiene $n$ vectores linealmente independientes.","title":"5.3 Diagonalizaci\u00f3n"},{"location":"chapter_05/53_Diagonalizacion/#diagonalizacion-para-el-calculo-de-potencia-de-matrices","text":"Sea $A$ la matriz diagonizable A=PDP^{-1} Podemos calcular $A^2$ como A^2=(PDP^{-1})(PDP^{-1})=PD(P^{-1}P)DP^{-1}=PD^2P^{-1} Sucede que $D^2$ es mucho m\u00e1s f\u00e1cil de calcular, pues al ser una matriz diagonal se obtiene como D^2=\\left[\\begin{array}{cccc} \\lambda_1^2 & 0 & \\dots & 0\\\\ 0 & \\lambda_2^2 & \\dots & 0\\\\ \\vdots & \\vdots & \\vdots & \\vdots\\\\ 0 & 0 & \\dots & \\lambda_n^2 \\end{array}\\right] La forma m\u00e1s general de una potencia de matrices est\u00e1 dada por A^k=PD^kP^{-1} Siendo D^k=\\left[\\begin{array}{cccc} \\lambda_1^k & 0 & \\dots & 0\\\\ 0 & \\lambda_2^k & \\dots & 0\\\\ \\vdots & \\vdots & \\vdots & \\vdots\\\\ 0 & 0 & \\dots & \\lambda_n^k \\end{array}\\right] Ejemplo 1: Dados $A$, $P$ y $D$ encuentre $A^{5}$ A=\\left[\\begin{array}{cc} 9 & -4\\\\ 12 & -5 \\end{array}\\right] \\;\\;\\; P=\\left[\\begin{array}{cc} 1 & 2\\\\ 2 & 3 \\end{array}\\right] \\;\\;\\; D=\\left[\\begin{array}{cc} 1 & 0\\\\ 0 & 3 \\end{array}\\right] Para encontrar $A^{5}$ utilizaremos la siguiente expresi\u00f3n A^{5}=PD^{5}P^{-1} La inversa de $P$ puede ser obtenida como P^{-1}=\\frac{1}{-1}\\left[\\begin{array}{cc} 3 & -2\\\\ -2 & 1 \\end{array}\\right]=\\left[\\begin{array}{cc} -3 & 2\\\\ 2 & -1 \\end{array}\\right] Entonces A^{5}=\\left[\\begin{array}{cc} 1 & 2\\\\ 2 & 3 \\end{array}\\right]\\left[\\begin{array}{cc} 1 & 0\\\\ 0 & 3 \\end{array}\\right]^{5}\\left[\\begin{array}{cc} -3 & 2\\\\ 2 & -1 \\end{array}\\right]=\\left[\\begin{array}{cc} 1 & 2\\\\ 2 & 3 \\end{array}\\right]\\left[\\begin{array}{cc} 1 & 0\\\\ 0 & 243 \\end{array}\\right]\\left[\\begin{array}{cc} -3 & 2\\\\ 2 & -1 \\end{array}\\right] A^{5}=\\left[\\begin{array}{cc} 969 & -484\\\\ 1452 & -725 \\end{array}\\right]","title":"Diagonalizaci\u00f3n para el C\u00e1lculo de Potencia de Matrices"},{"location":"chapter_05/53_Diagonalizacion/#como-diagonalizar-una-matriz","text":"El algoritmo para diagonalizar una matriz $A$ de $n \\times n$ es el siguiente: Determinar los valores propios de $A$ Encontrar los vectores propios de $A$ Construir $P$ con los vectores propios obtenidos y encontrar $P^{-1}$ Construir $D$ con los valores propios. Ejemplo 2: Encuentre la diagonalizaci\u00f3n de la matriz $A$ si A=\\left[\\begin{array}{ccc} 3 & 0 & 0\\\\ 1 & 0 & 0\\\\ -2 & 5 & 4 \\end{array}\\right] Ejemplo 3: Diagonalice la matriz $A$ si los valores propios de la misma son $\\lambda=0$ y $\\lambda=1$. A=\\left[\\begin{array}{ccc} 0 & -1 & -1\\\\ 1 & 2 & 1\\\\ -1 & -1 & 0 \\end{array}\\right] Ejemplo 4 Determine $A^{15}$ A=\\left[\\begin{array}{ccccc} -\\frac{2713}{228} & \\frac{175}{38} & -\\frac{175}{228} & \\frac{700}{19} & \\frac{175}{19}\\\\ -\\frac{326}{57} & \\frac{51}{19} & \\frac{22}{57} & \\frac{256}{19} & \\frac{64}{19}\\\\ -\\frac{941}{228} & \\frac{47}{38} & \\frac{1093}{228} & \\frac{188}{19} & \\frac{47}{19}\\\\ -\\frac{929}{228} & \\frac{59}{38} & -\\frac{59}{228} & \\frac{255}{19} & \\frac{59}{19}\\\\ 0 & 0 & 0 & 0 & 1 \\end{array}\\right] Una condici\u00f3n que es suficiente para determinar si una matriz de $n \\times n$ es diagonizable es si tiene $n$ valores propios distintos. TAREA SECCI\u00d3N 5.3 1, 3, 4, 5, 11, 13, 15, 17, 19, 27, 29","title":"\u00bfC\u00f3mo Diagonalizar una Matriz?"},{"location":"chapter_06/61_Producto_Interior_Longitud_Ortogonalidad/","text":"6. Ortogonalidad y M\u00ednimos Cuadrados 6.1 Producto Interior, Longitud y Ortogonalidad Producto Interior o Producto Punto Suponga que tiene dos vectores $\\boldsymbol{u}$ y $\\boldsymbol{v}$ de $n \\times 1$. \\boldsymbol{u}=\\left[\\begin{array}{c} u_{1}\\\\ u_{2}\\\\ \\vdots\\\\ u_{n} \\end{array}\\right] \\;\\;\\; \\boldsymbol{v}=\\left[\\begin{array}{c} v_{1}\\\\ v_{2}\\\\ \\vdots\\\\ v_{n} \\end{array}\\right] El producto interior se define como \\boldsymbol{u} \\cdot \\boldsymbol{v}=\\boldsymbol{u}^T \\boldsymbol{v} \\boldsymbol{u} \\cdot \\boldsymbol{v}=\\left[\\begin{array}{cccc} u_{1} & \\cdots & u_{2} & u_{n} \\end{array}\\right]\\left[\\begin{array}{c} v_{1}\\\\ v_{2}\\\\ \\vdots\\\\ v_{n} \\end{array}\\right] Ejemplo 1: Dados los vectores $\\boldsymbol{u}$ y $\\boldsymbol{v}$ , encuentre: \\boldsymbol{u}=\\left[\\begin{array}{c} 3\\\\ -1\\\\ 4 \\end{array}\\right] \\;\\;\\; \\boldsymbol{v}=\\left[\\begin{array}{c} -6\\\\ 7\\\\ 0 \\end{array}\\right] El producto interior $\\boldsymbol{u} \\cdot \\boldsymbol{v}$ El producto interior $\\boldsymbol{v} \\cdot \\boldsymbol{u}$. Producto interior $\\boldsymbol{u} \\cdot \\boldsymbol{v}$ \\boldsymbol{u} \\cdot \\boldsymbol{v}=\\left[\\begin{array}{ccc} 3 & -1 & 4 \\end{array}\\right]\\left[\\begin{array}{c} -6\\\\ 7\\\\ 0 \\end{array}\\right]=-18-7+0=-25 Producto interior $\\boldsymbol{v} \\cdot \\boldsymbol{u}$ \\boldsymbol{v} \\cdot \\boldsymbol{u}=\\left[\\begin{array}{ccc} -6 & 7 & 0 \\end{array}\\right]\\left[\\begin{array}{c} 3\\\\ -1\\\\ 4 \\end{array}\\right]=-18-7+0=-25 Como puede observar el producto interior cumple con la propiedad conmutativa. Propiedades del Producto Interior Sean $\\boldsymbol{u}$, $\\boldsymbol{v}$ y $\\boldsymbol{w}$ tres vectores y $c$ un escalar $\\boldsymbol{u} \\cdot \\boldsymbol{v}=\\boldsymbol{v} \\cdot \\boldsymbol{u}$ $(\\boldsymbol{u}+\\boldsymbol{v})\\cdot \\boldsymbol{w}=\\boldsymbol{u} \\cdot \\boldsymbol{w}+\\boldsymbol{v} \\cdot \\boldsymbol{w}$ $(c\\boldsymbol{u})\\cdot \\boldsymbol{v}=c(\\boldsymbol{u}\\cdot \\boldsymbol{v})=\\boldsymbol{u}\\cdot (c\\boldsymbol{v})$ $\\boldsymbol{u} \\cdot \\boldsymbol{u} \\ge 0 \\;\\;\\; \\wedge \\;\\;\\;\\boldsymbol{u} \\cdot \\boldsymbol{u}=0 \\iff\\boldsymbol{u}=0 $ Longitud o Norma Suponga que tiene un vector $\\boldsymbol{u}$ de $n \\times 1$, la longitud o norma del vector se define como \\left\\Vert \\boldsymbol{u} \\right\\Vert=\\sqrt{\\boldsymbol{u}\\cdot \\boldsymbol{u}}=\\sqrt{u_1^2+u_2^2+\\cdots u_n^2} En muchas ocasiones tambi\u00e9n es de utilidad encontrar \\left\\Vert \\boldsymbol{u} \\right\\Vert^2=\\boldsymbol{u}\\cdot \\boldsymbol{u} Ejemplo 2: Dados los vectores $\\boldsymbol{u}$ y $\\boldsymbol{v}$ , encuentre: \\boldsymbol{u}=\\left[\\begin{array}{c} 3\\\\ -1\\\\ 4 \\end{array}\\right] \\;\\;\\; \\boldsymbol{v}=\\left[\\begin{array}{c} -6\\\\ 7\\\\ 0 \\end{array}\\right] La longitud de $\\boldsymbol{u}$ La longitud de $\\boldsymbol{v}$ La longitud de $\\boldsymbol{u}$ estar\u00e1 dado por \\left\\Vert \\boldsymbol{u} \\right\\Vert=\\sqrt{\\left[\\begin{array}{ccc} 3 & -1 & 4 \\end{array}\\right] \\cdot\\left[\\begin{array}{c} 3\\\\ -1\\\\ 4 \\end{array}\\right]}=\\sqrt{9+1+16}=\\sqrt{26}\\approx5.1 La longitud de $\\boldsymbol{v}$ estar\u00e1 dado por \\left\\Vert \\boldsymbol{v} \\right\\Vert=\\sqrt{\\left[\\begin{array}{ccc} -6 & 7 & 0 \\end{array}\\right] \\cdot\\left[\\begin{array}{c} -6\\\\ 7\\\\ 0 \\end{array}\\right]}=\\sqrt{36+49+0}=\\sqrt{85}\\approx9.2 Vector Unitario Un vector unitario es aquel cuya longitud es igual a uno. Es decir \\left\\Vert \\boldsymbol{u} \\right\\Vert=\\sqrt{\\boldsymbol{u}\\cdot \\boldsymbol{u}}=\\sqrt{u_1^2+u_2^2+\\cdots u_n^2}=1 Normalizaci\u00f3n de un Vector Un vector $\\boldsymbol{v}$ que no sea unitario pude convertirse en unitario si se divide por su longitud de la siguiente manera \\boldsymbol{u}= \\frac{1}{\\left\\Vert \\boldsymbol{v} \\right\\Vert}\\boldsymbol{v} Ejemplo 3: Sea $W$ el espacio $\\mathbb{R}^4$ generado por $\\boldsymbol{v}$, obtenga un vector unitario que sea base para $W$ \\boldsymbol{v}=\\left[\\begin{array}{c} 1\\\\ 3\\\\ 5\\\\ -1 \\end{array}\\right] Para obtener la normalizaci\u00f3n es necesario encontrar la longitud de $\\boldsymbol{v}$ por lo que ser\u00e1 \\left\\Vert \\boldsymbol{v} \\right\\Vert = \\sqrt{1+9+25+1}=6 Por lo que el vector unitario $\\boldsymbol{u}$ ser\u00e1 \\boldsymbol{u}=\\frac{1}{6}\\left[\\begin{array}{c} 1\\\\ 3\\\\ 5\\\\ -1 \\end{array}\\right]=\\left[\\begin{array}{c} 0.167\\\\ 0.500\\\\ 0.833\\\\ -0.167 \\end{array}\\right] Distancia entre Vectores Para dos vectores $\\boldsymbol{u}$ y $\\boldsymbol{v}$ en $\\mathbb{R}^n$, la distancia entre estos vectores es la longitud del vector $\\boldsymbol{u}-\\boldsymbol{v}$, es decir \\boldsymbol{u}=\\left[\\begin{array}{c} u_{1}\\\\ u_{2}\\\\ \\vdots\\\\ u_{n} \\end{array}\\right] \\;\\;\\; \\boldsymbol{v}=\\left[\\begin{array}{c} v_{1}\\\\ v_{2}\\\\ \\vdots\\\\ v_{n} \\end{array}\\right] \\mathbf{dist}(\\boldsymbol{u},\\boldsymbol{v})=\\left\\Vert \\boldsymbol{u}-\\boldsymbol{v} \\right\\Vert \\mathbf{dist}(\\boldsymbol{u},\\boldsymbol{v})=\\sqrt{(u_1-v_1)^2+(u_2-v_2)^2+\\cdots+(u_n-v_n)^2} Ejemplo 4: \u00bfCu\u00e1l es la distancia entre $\\boldsymbol{u}$ y $\\boldsymbol{v}$? \\boldsymbol{u}=\\left[\\begin{array}{c} 0\\\\ -5\\\\ 2 \\end{array}\\right] \\;\\;\\; \\boldsymbol{v}=\\left[\\begin{array}{c} -4\\\\ -1\\\\ 8 \\end{array}\\right] La distancia entre estos vectores ser\u00e1 \\boldsymbol{u}-\\boldsymbol{v}=\\left[\\begin{array}{c} 0\\\\ -5\\\\ 2 \\end{array}\\right]-\\left[\\begin{array}{c} -4\\\\ -1\\\\ 8 \\end{array}\\right]=\\left[\\begin{array}{c} 4\\\\ -4\\\\ -6 \\end{array}\\right] \\left\\Vert \\boldsymbol{u}-\\boldsymbol{v} \\right\\Vert=\\sqrt{16+16+36}=\\sqrt{68} \\approx 8.25 Vectores Ortogonales En el siguiente apartado encontraremos la condici\u00f3n que se debe de cumplir para que dos vectores sean ortogonales. Comenzaremos por definir geom\u00e9tricamente nuestro problema. Se tiene lo siguiente: Dos rectas que pasan por el origen determinadas por los vectores $\\boldsymbol{u}$ y $\\boldsymbol{v}$. Se desea estimar la forma en que $\\mathbf{dist}(\\boldsymbol{u},\\boldsymbol{v})=\\mathbf{dist}(\\boldsymbol{u},\\boldsymbol{-v})$. Trabajaremos con los cuadrados de las distancias por conveniencia en nuestros c\u00e1lculos. Distancia cuadr\u00e1tica entre $\\boldsymbol{u}$ y $\\boldsymbol{v}$ [\\mathbf{dist}(\\boldsymbol{u},\\boldsymbol{v})]^2=\\left\\Vert \\boldsymbol{u}-\\boldsymbol{v} \\right\\Vert^2 =(\\boldsymbol{u}-\\boldsymbol{v})\\cdot(\\boldsymbol{u}-\\boldsymbol{v}) =\\boldsymbol{u}\\cdot(\\boldsymbol{u}-\\boldsymbol{v})-\\boldsymbol{v}\\cdot(\\boldsymbol{u}-\\boldsymbol{v}) =\\boldsymbol{u}\\cdot \\boldsymbol{u} - \\boldsymbol{u}\\cdot\\boldsymbol{v}-\\boldsymbol{v}\\cdot\\boldsymbol{u}+\\boldsymbol{v}\\cdot\\boldsymbol{v} =\\left\\Vert \\boldsymbol{u} \\right\\Vert^2 + \\left\\Vert \\boldsymbol{v} \\right\\Vert^2 - 2(\\boldsymbol{u}\\cdot\\boldsymbol{v}) Distancia cuadr\u00e1tica entre $\\boldsymbol{u}$ y $-\\boldsymbol{v}$ [\\mathbf{dist}(\\boldsymbol{u},\\boldsymbol{-v})]^2=\\left\\Vert \\boldsymbol{u}+\\boldsymbol{v} \\right\\Vert^2 =\\left\\Vert \\boldsymbol{u} \\right\\Vert^2 + \\left\\Vert \\boldsymbol{v} \\right\\Vert^2 + 2(\\boldsymbol{u}\\cdot\\boldsymbol{v}) Como se mencion\u00f3 al plantear el problema, se desea que se cumpla [\\mathbf{dist}(\\boldsymbol{u},\\boldsymbol{v})]^2=[\\mathbf{dist}(\\boldsymbol{u},\\boldsymbol{-v})]^2 \\left\\Vert \\boldsymbol{u} \\right\\Vert^2 + \\left\\Vert \\boldsymbol{v} \\right\\Vert^2 - 2(\\boldsymbol{u}\\cdot\\boldsymbol{v})= \\left\\Vert \\boldsymbol{u} \\right\\Vert^2 + \\left\\Vert \\boldsymbol{v} \\right\\Vert^2 + 2(\\boldsymbol{u}\\cdot\\boldsymbol{v}) - 2(\\boldsymbol{u}\\cdot\\boldsymbol{v})= 2(\\boldsymbol{u}\\cdot\\boldsymbol{v}) \\boldsymbol{u}\\cdot\\boldsymbol{v}= 0 Este resultado indica que la \u00fanica forma en que $\\mathbf{dist}(\\boldsymbol{u},\\boldsymbol{v})=\\mathbf{dist}(\\boldsymbol{u},\\boldsymbol{-v})$ exista es cuando $\\boldsymbol{u}\\cdot\\boldsymbol{v}= 0$, implicando que $\\boldsymbol{u}$ y $\\boldsymbol{v}$ son independientes uno de otro, y en consecuencia ortogonales. Teorema de Pit\u00e1goras El Teorema de Pit\u00e1goras puede ser inferido de la expresi\u00f3n \\left\\Vert \\boldsymbol{u}+\\boldsymbol{v} \\right\\Vert^2=\\left\\Vert \\boldsymbol{u} \\right\\Vert^2 + \\left\\Vert \\boldsymbol{v} \\right\\Vert^2 + 2(\\boldsymbol{u}\\cdot\\boldsymbol{v}) Si los vectores son ortogonales \\left\\Vert \\boldsymbol{u}+\\boldsymbol{v} \\right\\Vert^2=\\left\\Vert \\boldsymbol{u} \\right\\Vert^2 + \\left\\Vert \\boldsymbol{v} \\right\\Vert^2 \u00c1ngulo entre dos Vectores no Ortogonales En esta secci\u00f3n encontraremos el \u00e1ngulo sub-tendido por dos vectores que no son ortogonales. Para ello construiremos un tri\u00e1ngulo a partir de los vectores $\\boldsymbol{u}$ y $\\boldsymbol{v}$. Lo anterior comprueba que es posible aplicar la Ley de Cosenos al tri\u00e1ngulo que se forma por los vectores $\\boldsymbol{u}$, $\\boldsymbol{v}$ y $\\boldsymbol{u}-\\boldsymbol{v}$ . \\left\\Vert \\boldsymbol{u}-\\boldsymbol{v} \\right\\Vert^2=\\left\\Vert \\boldsymbol{u} \\right\\Vert^2 + \\left\\Vert \\boldsymbol{v} \\right\\Vert^2 - 2\\left\\Vert \\boldsymbol{u}\\right\\Vert\\left\\Vert \\boldsymbol{v}\\right\\Vert\\cos{\\theta} Siendo $\\theta$ el \u00e1ngulo sub-tendido entre $\\boldsymbol{u}$ y $\\boldsymbol{v}$. Anteriormente se encontr\u00f3 la siguiente expresi\u00f3n \\left\\Vert \\boldsymbol{u}-\\boldsymbol{v} \\right\\Vert^2=\\left\\Vert \\boldsymbol{u} \\right\\Vert^2 + \\left\\Vert \\boldsymbol{v} \\right\\Vert^2 - 2(\\boldsymbol{u}\\cdot\\boldsymbol{v}) Al igualar ambas ecuaciones se obtiene \\left\\Vert \\boldsymbol{u} \\right\\Vert^2 + \\left\\Vert \\boldsymbol{v} \\right\\Vert^2 - 2(\\boldsymbol{u}\\cdot\\boldsymbol{v})=\\left\\Vert \\boldsymbol{u} \\right\\Vert^2 + \\left\\Vert \\boldsymbol{v} \\right\\Vert^2 - 2\\left\\Vert \\boldsymbol{u}\\right\\Vert\\left\\Vert \\boldsymbol{v}\\right\\Vert\\cos{\\theta} \\boldsymbol{u}\\cdot\\boldsymbol{v}=\\left\\Vert \\boldsymbol{u}\\right\\Vert\\left\\Vert \\boldsymbol{v}\\right\\Vert\\cos{\\theta} Esta expresi\u00f3n puede ser interpretada de diversas formas, entre las que destacan: Proyecci\u00f3n de un vector sobre otro Si se define a $\\left\\Vert \\boldsymbol{u}\\right\\Vert\\cos{\\theta}$ como la proyecci\u00f3n de $\\boldsymbol{u}$ sobre la direcci\u00f3n de $\\boldsymbol{v}$ \\boldsymbol{u}\\cdot\\boldsymbol{v}=\\left\\Vert \\boldsymbol{u}\\right\\Vert\\left\\Vert \\boldsymbol{v}\\right\\Vert\\cos{\\theta} Define que tanto el vector $\\boldsymbol{u}$ se proyecta sobre $\\boldsymbol{v}$. \u00c1ngulos entre dos vectores La expresi\u00f3n \\theta=\\arccos{\\left(\\frac{\\boldsymbol{u}\\cdot\\boldsymbol{v}}{\\left\\Vert \\boldsymbol{u}\\right\\Vert\\left\\Vert \\boldsymbol{v}\\right\\Vert}\\right)} indica el \u00e1ngulo m\u00e1s peque\u00f1o entre $\\boldsymbol{u}$ y $\\boldsymbol{v}$. Similitud entre vectores La expresi\u00f3n \\cos{\\theta}={\\frac{\\boldsymbol{u}\\cdot\\boldsymbol{v}}{\\left\\Vert \\boldsymbol{u}\\right\\Vert\\left\\Vert \\boldsymbol{v}\\right\\Vert}} Aparte de indicar la relaci\u00f3n del \u00e1ngulo $\\theta$, tambi\u00e9n indica una m\u00e9trica de que tanto $\\boldsymbol{u}$ y $\\boldsymbol{v}$ se parecen entre s\u00ed. Complementos Ortogonales Dado el sub-espacio $W$ en $\\mathbb{R}^n$ podemos decir que un complemento ortogonal es el conjunto de todos los vectores $\\boldsymbol{z}$ que son ortogonales a $W$. A este espacio lo denotamos como $W^\\perp$. Observe que la recta $L$ es perpendicular a cada $\\boldsymbol{w}$ en $W$, por lo que se pueden observar dos cosas: $L=W^\\perp$ $W=L^{\\perp}$ Algunas consideraciones interesantes: El complemento ortogonal del espacio fila de $A$ es el espacio nulo de $A$. $(\\mathbf{Fila}A)^\\perp=\\mathbf{Nul}A$ El complemento ortogonal del espacio columna de $A$ es el espacio nulo de $A^T$. $(\\mathbf{Col}A)^\\perp=\\mathbf{Nul}A^T$ TAREA SECCI\u00d3N 6.1 1, 3, 5, 7, 9, 14, 16, 17, 22, 24","title":"6.1 Producto Interior, Longitud y Ortogonalidad"},{"location":"chapter_06/61_Producto_Interior_Longitud_Ortogonalidad/#6-ortogonalidad-y-minimos-cuadrados","text":"","title":"6. Ortogonalidad y M\u00ednimos Cuadrados"},{"location":"chapter_06/61_Producto_Interior_Longitud_Ortogonalidad/#61-producto-interior-longitud-y-ortogonalidad","text":"","title":"6.1 Producto Interior, Longitud y Ortogonalidad"},{"location":"chapter_06/61_Producto_Interior_Longitud_Ortogonalidad/#producto-interior-o-producto-punto","text":"Suponga que tiene dos vectores $\\boldsymbol{u}$ y $\\boldsymbol{v}$ de $n \\times 1$. \\boldsymbol{u}=\\left[\\begin{array}{c} u_{1}\\\\ u_{2}\\\\ \\vdots\\\\ u_{n} \\end{array}\\right] \\;\\;\\; \\boldsymbol{v}=\\left[\\begin{array}{c} v_{1}\\\\ v_{2}\\\\ \\vdots\\\\ v_{n} \\end{array}\\right] El producto interior se define como \\boldsymbol{u} \\cdot \\boldsymbol{v}=\\boldsymbol{u}^T \\boldsymbol{v} \\boldsymbol{u} \\cdot \\boldsymbol{v}=\\left[\\begin{array}{cccc} u_{1} & \\cdots & u_{2} & u_{n} \\end{array}\\right]\\left[\\begin{array}{c} v_{1}\\\\ v_{2}\\\\ \\vdots\\\\ v_{n} \\end{array}\\right] Ejemplo 1: Dados los vectores $\\boldsymbol{u}$ y $\\boldsymbol{v}$ , encuentre: \\boldsymbol{u}=\\left[\\begin{array}{c} 3\\\\ -1\\\\ 4 \\end{array}\\right] \\;\\;\\; \\boldsymbol{v}=\\left[\\begin{array}{c} -6\\\\ 7\\\\ 0 \\end{array}\\right] El producto interior $\\boldsymbol{u} \\cdot \\boldsymbol{v}$ El producto interior $\\boldsymbol{v} \\cdot \\boldsymbol{u}$. Producto interior $\\boldsymbol{u} \\cdot \\boldsymbol{v}$ \\boldsymbol{u} \\cdot \\boldsymbol{v}=\\left[\\begin{array}{ccc} 3 & -1 & 4 \\end{array}\\right]\\left[\\begin{array}{c} -6\\\\ 7\\\\ 0 \\end{array}\\right]=-18-7+0=-25 Producto interior $\\boldsymbol{v} \\cdot \\boldsymbol{u}$ \\boldsymbol{v} \\cdot \\boldsymbol{u}=\\left[\\begin{array}{ccc} -6 & 7 & 0 \\end{array}\\right]\\left[\\begin{array}{c} 3\\\\ -1\\\\ 4 \\end{array}\\right]=-18-7+0=-25 Como puede observar el producto interior cumple con la propiedad conmutativa.","title":"Producto Interior o Producto Punto"},{"location":"chapter_06/61_Producto_Interior_Longitud_Ortogonalidad/#propiedades-del-producto-interior","text":"Sean $\\boldsymbol{u}$, $\\boldsymbol{v}$ y $\\boldsymbol{w}$ tres vectores y $c$ un escalar $\\boldsymbol{u} \\cdot \\boldsymbol{v}=\\boldsymbol{v} \\cdot \\boldsymbol{u}$ $(\\boldsymbol{u}+\\boldsymbol{v})\\cdot \\boldsymbol{w}=\\boldsymbol{u} \\cdot \\boldsymbol{w}+\\boldsymbol{v} \\cdot \\boldsymbol{w}$ $(c\\boldsymbol{u})\\cdot \\boldsymbol{v}=c(\\boldsymbol{u}\\cdot \\boldsymbol{v})=\\boldsymbol{u}\\cdot (c\\boldsymbol{v})$ $\\boldsymbol{u} \\cdot \\boldsymbol{u} \\ge 0 \\;\\;\\; \\wedge \\;\\;\\;\\boldsymbol{u} \\cdot \\boldsymbol{u}=0 \\iff\\boldsymbol{u}=0 $","title":"Propiedades del Producto Interior"},{"location":"chapter_06/61_Producto_Interior_Longitud_Ortogonalidad/#longitud-o-norma","text":"Suponga que tiene un vector $\\boldsymbol{u}$ de $n \\times 1$, la longitud o norma del vector se define como \\left\\Vert \\boldsymbol{u} \\right\\Vert=\\sqrt{\\boldsymbol{u}\\cdot \\boldsymbol{u}}=\\sqrt{u_1^2+u_2^2+\\cdots u_n^2} En muchas ocasiones tambi\u00e9n es de utilidad encontrar \\left\\Vert \\boldsymbol{u} \\right\\Vert^2=\\boldsymbol{u}\\cdot \\boldsymbol{u} Ejemplo 2: Dados los vectores $\\boldsymbol{u}$ y $\\boldsymbol{v}$ , encuentre: \\boldsymbol{u}=\\left[\\begin{array}{c} 3\\\\ -1\\\\ 4 \\end{array}\\right] \\;\\;\\; \\boldsymbol{v}=\\left[\\begin{array}{c} -6\\\\ 7\\\\ 0 \\end{array}\\right] La longitud de $\\boldsymbol{u}$ La longitud de $\\boldsymbol{v}$ La longitud de $\\boldsymbol{u}$ estar\u00e1 dado por \\left\\Vert \\boldsymbol{u} \\right\\Vert=\\sqrt{\\left[\\begin{array}{ccc} 3 & -1 & 4 \\end{array}\\right] \\cdot\\left[\\begin{array}{c} 3\\\\ -1\\\\ 4 \\end{array}\\right]}=\\sqrt{9+1+16}=\\sqrt{26}\\approx5.1 La longitud de $\\boldsymbol{v}$ estar\u00e1 dado por \\left\\Vert \\boldsymbol{v} \\right\\Vert=\\sqrt{\\left[\\begin{array}{ccc} -6 & 7 & 0 \\end{array}\\right] \\cdot\\left[\\begin{array}{c} -6\\\\ 7\\\\ 0 \\end{array}\\right]}=\\sqrt{36+49+0}=\\sqrt{85}\\approx9.2","title":"Longitud o Norma"},{"location":"chapter_06/61_Producto_Interior_Longitud_Ortogonalidad/#vector-unitario","text":"Un vector unitario es aquel cuya longitud es igual a uno. Es decir \\left\\Vert \\boldsymbol{u} \\right\\Vert=\\sqrt{\\boldsymbol{u}\\cdot \\boldsymbol{u}}=\\sqrt{u_1^2+u_2^2+\\cdots u_n^2}=1","title":"Vector Unitario"},{"location":"chapter_06/61_Producto_Interior_Longitud_Ortogonalidad/#normalizacion-de-un-vector","text":"Un vector $\\boldsymbol{v}$ que no sea unitario pude convertirse en unitario si se divide por su longitud de la siguiente manera \\boldsymbol{u}= \\frac{1}{\\left\\Vert \\boldsymbol{v} \\right\\Vert}\\boldsymbol{v} Ejemplo 3: Sea $W$ el espacio $\\mathbb{R}^4$ generado por $\\boldsymbol{v}$, obtenga un vector unitario que sea base para $W$ \\boldsymbol{v}=\\left[\\begin{array}{c} 1\\\\ 3\\\\ 5\\\\ -1 \\end{array}\\right] Para obtener la normalizaci\u00f3n es necesario encontrar la longitud de $\\boldsymbol{v}$ por lo que ser\u00e1 \\left\\Vert \\boldsymbol{v} \\right\\Vert = \\sqrt{1+9+25+1}=6 Por lo que el vector unitario $\\boldsymbol{u}$ ser\u00e1 \\boldsymbol{u}=\\frac{1}{6}\\left[\\begin{array}{c} 1\\\\ 3\\\\ 5\\\\ -1 \\end{array}\\right]=\\left[\\begin{array}{c} 0.167\\\\ 0.500\\\\ 0.833\\\\ -0.167 \\end{array}\\right]","title":"Normalizaci\u00f3n de un Vector"},{"location":"chapter_06/61_Producto_Interior_Longitud_Ortogonalidad/#distancia-entre-vectores","text":"Para dos vectores $\\boldsymbol{u}$ y $\\boldsymbol{v}$ en $\\mathbb{R}^n$, la distancia entre estos vectores es la longitud del vector $\\boldsymbol{u}-\\boldsymbol{v}$, es decir \\boldsymbol{u}=\\left[\\begin{array}{c} u_{1}\\\\ u_{2}\\\\ \\vdots\\\\ u_{n} \\end{array}\\right] \\;\\;\\; \\boldsymbol{v}=\\left[\\begin{array}{c} v_{1}\\\\ v_{2}\\\\ \\vdots\\\\ v_{n} \\end{array}\\right] \\mathbf{dist}(\\boldsymbol{u},\\boldsymbol{v})=\\left\\Vert \\boldsymbol{u}-\\boldsymbol{v} \\right\\Vert \\mathbf{dist}(\\boldsymbol{u},\\boldsymbol{v})=\\sqrt{(u_1-v_1)^2+(u_2-v_2)^2+\\cdots+(u_n-v_n)^2} Ejemplo 4: \u00bfCu\u00e1l es la distancia entre $\\boldsymbol{u}$ y $\\boldsymbol{v}$? \\boldsymbol{u}=\\left[\\begin{array}{c} 0\\\\ -5\\\\ 2 \\end{array}\\right] \\;\\;\\; \\boldsymbol{v}=\\left[\\begin{array}{c} -4\\\\ -1\\\\ 8 \\end{array}\\right] La distancia entre estos vectores ser\u00e1 \\boldsymbol{u}-\\boldsymbol{v}=\\left[\\begin{array}{c} 0\\\\ -5\\\\ 2 \\end{array}\\right]-\\left[\\begin{array}{c} -4\\\\ -1\\\\ 8 \\end{array}\\right]=\\left[\\begin{array}{c} 4\\\\ -4\\\\ -6 \\end{array}\\right] \\left\\Vert \\boldsymbol{u}-\\boldsymbol{v} \\right\\Vert=\\sqrt{16+16+36}=\\sqrt{68} \\approx 8.25","title":"Distancia entre Vectores"},{"location":"chapter_06/61_Producto_Interior_Longitud_Ortogonalidad/#vectores-ortogonales","text":"En el siguiente apartado encontraremos la condici\u00f3n que se debe de cumplir para que dos vectores sean ortogonales. Comenzaremos por definir geom\u00e9tricamente nuestro problema. Se tiene lo siguiente: Dos rectas que pasan por el origen determinadas por los vectores $\\boldsymbol{u}$ y $\\boldsymbol{v}$. Se desea estimar la forma en que $\\mathbf{dist}(\\boldsymbol{u},\\boldsymbol{v})=\\mathbf{dist}(\\boldsymbol{u},\\boldsymbol{-v})$. Trabajaremos con los cuadrados de las distancias por conveniencia en nuestros c\u00e1lculos.","title":"Vectores Ortogonales"},{"location":"chapter_06/61_Producto_Interior_Longitud_Ortogonalidad/#distancia-cuadratica-entre-boldsymbolu-y-boldsymbolv","text":"[\\mathbf{dist}(\\boldsymbol{u},\\boldsymbol{v})]^2=\\left\\Vert \\boldsymbol{u}-\\boldsymbol{v} \\right\\Vert^2 =(\\boldsymbol{u}-\\boldsymbol{v})\\cdot(\\boldsymbol{u}-\\boldsymbol{v}) =\\boldsymbol{u}\\cdot(\\boldsymbol{u}-\\boldsymbol{v})-\\boldsymbol{v}\\cdot(\\boldsymbol{u}-\\boldsymbol{v}) =\\boldsymbol{u}\\cdot \\boldsymbol{u} - \\boldsymbol{u}\\cdot\\boldsymbol{v}-\\boldsymbol{v}\\cdot\\boldsymbol{u}+\\boldsymbol{v}\\cdot\\boldsymbol{v} =\\left\\Vert \\boldsymbol{u} \\right\\Vert^2 + \\left\\Vert \\boldsymbol{v} \\right\\Vert^2 - 2(\\boldsymbol{u}\\cdot\\boldsymbol{v})","title":"Distancia cuadr\u00e1tica entre $\\boldsymbol{u}$ y $\\boldsymbol{v}$"},{"location":"chapter_06/61_Producto_Interior_Longitud_Ortogonalidad/#distancia-cuadratica-entre-boldsymbolu-y-boldsymbolv_1","text":"[\\mathbf{dist}(\\boldsymbol{u},\\boldsymbol{-v})]^2=\\left\\Vert \\boldsymbol{u}+\\boldsymbol{v} \\right\\Vert^2 =\\left\\Vert \\boldsymbol{u} \\right\\Vert^2 + \\left\\Vert \\boldsymbol{v} \\right\\Vert^2 + 2(\\boldsymbol{u}\\cdot\\boldsymbol{v}) Como se mencion\u00f3 al plantear el problema, se desea que se cumpla [\\mathbf{dist}(\\boldsymbol{u},\\boldsymbol{v})]^2=[\\mathbf{dist}(\\boldsymbol{u},\\boldsymbol{-v})]^2 \\left\\Vert \\boldsymbol{u} \\right\\Vert^2 + \\left\\Vert \\boldsymbol{v} \\right\\Vert^2 - 2(\\boldsymbol{u}\\cdot\\boldsymbol{v})= \\left\\Vert \\boldsymbol{u} \\right\\Vert^2 + \\left\\Vert \\boldsymbol{v} \\right\\Vert^2 + 2(\\boldsymbol{u}\\cdot\\boldsymbol{v}) - 2(\\boldsymbol{u}\\cdot\\boldsymbol{v})= 2(\\boldsymbol{u}\\cdot\\boldsymbol{v}) \\boldsymbol{u}\\cdot\\boldsymbol{v}= 0 Este resultado indica que la \u00fanica forma en que $\\mathbf{dist}(\\boldsymbol{u},\\boldsymbol{v})=\\mathbf{dist}(\\boldsymbol{u},\\boldsymbol{-v})$ exista es cuando $\\boldsymbol{u}\\cdot\\boldsymbol{v}= 0$, implicando que $\\boldsymbol{u}$ y $\\boldsymbol{v}$ son independientes uno de otro, y en consecuencia ortogonales.","title":"Distancia cuadr\u00e1tica entre $\\boldsymbol{u}$ y $-\\boldsymbol{v}$"},{"location":"chapter_06/61_Producto_Interior_Longitud_Ortogonalidad/#teorema-de-pitagoras","text":"El Teorema de Pit\u00e1goras puede ser inferido de la expresi\u00f3n \\left\\Vert \\boldsymbol{u}+\\boldsymbol{v} \\right\\Vert^2=\\left\\Vert \\boldsymbol{u} \\right\\Vert^2 + \\left\\Vert \\boldsymbol{v} \\right\\Vert^2 + 2(\\boldsymbol{u}\\cdot\\boldsymbol{v}) Si los vectores son ortogonales \\left\\Vert \\boldsymbol{u}+\\boldsymbol{v} \\right\\Vert^2=\\left\\Vert \\boldsymbol{u} \\right\\Vert^2 + \\left\\Vert \\boldsymbol{v} \\right\\Vert^2","title":"Teorema de Pit\u00e1goras"},{"location":"chapter_06/61_Producto_Interior_Longitud_Ortogonalidad/#angulo-entre-dos-vectores-no-ortogonales","text":"En esta secci\u00f3n encontraremos el \u00e1ngulo sub-tendido por dos vectores que no son ortogonales. Para ello construiremos un tri\u00e1ngulo a partir de los vectores $\\boldsymbol{u}$ y $\\boldsymbol{v}$. Lo anterior comprueba que es posible aplicar la Ley de Cosenos al tri\u00e1ngulo que se forma por los vectores $\\boldsymbol{u}$, $\\boldsymbol{v}$ y $\\boldsymbol{u}-\\boldsymbol{v}$ . \\left\\Vert \\boldsymbol{u}-\\boldsymbol{v} \\right\\Vert^2=\\left\\Vert \\boldsymbol{u} \\right\\Vert^2 + \\left\\Vert \\boldsymbol{v} \\right\\Vert^2 - 2\\left\\Vert \\boldsymbol{u}\\right\\Vert\\left\\Vert \\boldsymbol{v}\\right\\Vert\\cos{\\theta} Siendo $\\theta$ el \u00e1ngulo sub-tendido entre $\\boldsymbol{u}$ y $\\boldsymbol{v}$. Anteriormente se encontr\u00f3 la siguiente expresi\u00f3n \\left\\Vert \\boldsymbol{u}-\\boldsymbol{v} \\right\\Vert^2=\\left\\Vert \\boldsymbol{u} \\right\\Vert^2 + \\left\\Vert \\boldsymbol{v} \\right\\Vert^2 - 2(\\boldsymbol{u}\\cdot\\boldsymbol{v}) Al igualar ambas ecuaciones se obtiene \\left\\Vert \\boldsymbol{u} \\right\\Vert^2 + \\left\\Vert \\boldsymbol{v} \\right\\Vert^2 - 2(\\boldsymbol{u}\\cdot\\boldsymbol{v})=\\left\\Vert \\boldsymbol{u} \\right\\Vert^2 + \\left\\Vert \\boldsymbol{v} \\right\\Vert^2 - 2\\left\\Vert \\boldsymbol{u}\\right\\Vert\\left\\Vert \\boldsymbol{v}\\right\\Vert\\cos{\\theta} \\boldsymbol{u}\\cdot\\boldsymbol{v}=\\left\\Vert \\boldsymbol{u}\\right\\Vert\\left\\Vert \\boldsymbol{v}\\right\\Vert\\cos{\\theta} Esta expresi\u00f3n puede ser interpretada de diversas formas, entre las que destacan:","title":"\u00c1ngulo entre dos Vectores no Ortogonales"},{"location":"chapter_06/61_Producto_Interior_Longitud_Ortogonalidad/#proyeccion-de-un-vector-sobre-otro","text":"Si se define a $\\left\\Vert \\boldsymbol{u}\\right\\Vert\\cos{\\theta}$ como la proyecci\u00f3n de $\\boldsymbol{u}$ sobre la direcci\u00f3n de $\\boldsymbol{v}$ \\boldsymbol{u}\\cdot\\boldsymbol{v}=\\left\\Vert \\boldsymbol{u}\\right\\Vert\\left\\Vert \\boldsymbol{v}\\right\\Vert\\cos{\\theta} Define que tanto el vector $\\boldsymbol{u}$ se proyecta sobre $\\boldsymbol{v}$.","title":"Proyecci\u00f3n de un vector sobre otro"},{"location":"chapter_06/61_Producto_Interior_Longitud_Ortogonalidad/#angulos-entre-dos-vectores","text":"La expresi\u00f3n \\theta=\\arccos{\\left(\\frac{\\boldsymbol{u}\\cdot\\boldsymbol{v}}{\\left\\Vert \\boldsymbol{u}\\right\\Vert\\left\\Vert \\boldsymbol{v}\\right\\Vert}\\right)} indica el \u00e1ngulo m\u00e1s peque\u00f1o entre $\\boldsymbol{u}$ y $\\boldsymbol{v}$.","title":"\u00c1ngulos entre dos vectores"},{"location":"chapter_06/61_Producto_Interior_Longitud_Ortogonalidad/#similitud-entre-vectores","text":"La expresi\u00f3n \\cos{\\theta}={\\frac{\\boldsymbol{u}\\cdot\\boldsymbol{v}}{\\left\\Vert \\boldsymbol{u}\\right\\Vert\\left\\Vert \\boldsymbol{v}\\right\\Vert}} Aparte de indicar la relaci\u00f3n del \u00e1ngulo $\\theta$, tambi\u00e9n indica una m\u00e9trica de que tanto $\\boldsymbol{u}$ y $\\boldsymbol{v}$ se parecen entre s\u00ed.","title":"Similitud entre vectores"},{"location":"chapter_06/61_Producto_Interior_Longitud_Ortogonalidad/#complementos-ortogonales","text":"Dado el sub-espacio $W$ en $\\mathbb{R}^n$ podemos decir que un complemento ortogonal es el conjunto de todos los vectores $\\boldsymbol{z}$ que son ortogonales a $W$. A este espacio lo denotamos como $W^\\perp$. Observe que la recta $L$ es perpendicular a cada $\\boldsymbol{w}$ en $W$, por lo que se pueden observar dos cosas: $L=W^\\perp$ $W=L^{\\perp}$ Algunas consideraciones interesantes: El complemento ortogonal del espacio fila de $A$ es el espacio nulo de $A$. $(\\mathbf{Fila}A)^\\perp=\\mathbf{Nul}A$ El complemento ortogonal del espacio columna de $A$ es el espacio nulo de $A^T$. $(\\mathbf{Col}A)^\\perp=\\mathbf{Nul}A^T$ TAREA SECCI\u00d3N 6.1 1, 3, 5, 7, 9, 14, 16, 17, 22, 24","title":"Complementos Ortogonales"},{"location":"chapter_06/62_Conjuntos_Ortogonales/","text":"6. Ortogonalidad y M\u00ednimos Cuadrados 6.2 Conjuntos Ortogonales Un conjunto de vectores {$\\boldsymbol{u_1}, \\boldsymbol{u_2}, \\cdots, \\boldsymbol{u_p}$} es un conjunto ortogonal si cada par de distintos vectores es ortogonal, es decir \\boldsymbol{u_1} \\cdot \\boldsymbol{u_2}=0, \\;\\;\\;\\boldsymbol{u_2} \\cdot \\boldsymbol{u_3}=0, \\;\\;\\;\\boldsymbol{u_1} \\cdot \\boldsymbol{u_3}=0 \\;\\;\\; \\cdots O en forma m\u00e1s general \\boldsymbol{u_i} \\cdot \\boldsymbol{u_j}=0; \\;\\;\\;i \\neq j Estos vectores son linealmente independientes y son una base para el sub-espacio generado. Ejemplo 1: Determine si el conjunto de vectores $S=${$\\boldsymbol{v_1}, \\boldsymbol{u_2}, \\boldsymbol{u_3}$} son ortogonales. \\boldsymbol{v_1}=\\left[\\begin{array}{c} 1\\\\ -2\\\\ 1 \\end{array}\\right]\\;\\;\\; \\boldsymbol{v_2}=\\left[\\begin{array}{c} 0\\\\ 1\\\\ 2 \\end{array}\\right]\\;\\;\\; \\boldsymbol{v_3}=\\left[\\begin{array}{c} -5\\\\ -2\\\\ 1 \\end{array}\\right] Para comprobar que el conjunto de vectores $S$ es ortogonal se debe de cumplir con $\\boldsymbol{u_i} \\cdot \\boldsymbol{u_j}=0$ para $i \\neq j$ \\boldsymbol{u_1} \\cdot \\boldsymbol{u_2}=\\left[\\begin{array}{ccc} 1 & -2 & 1 \\end{array}\\right]\\left[\\begin{array}{c} 0\\\\ 1\\\\ 2 \\end{array}\\right]=0-2+2=0 \\boldsymbol{u_1} \\cdot \\boldsymbol{u_3}=\\left[\\begin{array}{ccc} 1 & -2 & 1 \\end{array}\\right]\\left[\\begin{array}{c} -5\\\\ -2\\\\ 1 \\end{array}\\right]=-5+4+1=0 \\boldsymbol{u_2} \\cdot \\boldsymbol{u_3}=\\left[\\begin{array}{ccc} 0 & 1 & 2 \\end{array}\\right]\\left[\\begin{array}{c} -5\\\\ -2\\\\ 1 \\end{array}\\right]=0-2+2=0 Combinaci\u00f3n Lineal de Vectores Ortogonales Dado el conjunto de vectores ortogonales S=\\left\\{ \\boldsymbol{u_1}, \\boldsymbol{u_2}, \\cdots, \\boldsymbol{u_p} \\right\\} La combinaci\u00f3n de los vectores en $S$ puede generar al vector $y$ de la forma \\boldsymbol{y}=c_1\\boldsymbol{u_1}+c_2\\boldsymbol{u_2}+\\cdots +c_p\\boldsymbol{u_p} Si ahora se obtiene $\\boldsymbol{y} \\cdot \\boldsymbol{u_1}$ como \\boldsymbol{y}\\cdot \\boldsymbol{u_1}=c_1\\boldsymbol{u_1}\\cdot \\boldsymbol{u_1}+c_2\\boldsymbol{u_2}\\cdot \\boldsymbol{u_1}+\\cdots +c_p\\boldsymbol{u_p}\\cdot \\boldsymbol{u_1} Observe que todos los t\u00e9rminos $\\boldsymbol{u_i} \\cdot \\boldsymbol{u_j}=0$ excepto $\\boldsymbol{u_i} \\cdot \\boldsymbol{u_i}$ por lo que la ecuaci\u00f3n anterior se reduce a \\boldsymbol{y}\\cdot \\boldsymbol{u_1}=c_1\\boldsymbol{u_1}\\cdot \\boldsymbol{u_1} Con lo cual es posible obtener una expresi\u00f3n para $c_1$ como c_1\\frac{\\boldsymbol{y}\\cdot \\boldsymbol{u_1}}{\\boldsymbol{u_1}\\cdot \\boldsymbol{u_1}} Si se aplica la misma metodolog\u00eda es posible generalizar la soluci\u00f3n de $c_i$ de la siguiente manera c_i\\frac{\\boldsymbol{y}\\cdot \\boldsymbol{u_i}}{\\boldsymbol{u_i}\\cdot \\boldsymbol{u_i}} Observe que la ortogonalidad de los vectores $\\boldsymbol{u_i}$ hace que ya no tenga que resolver la ecuaci\u00f3n lineal para encontrar los coeficientes $c_i$. Ejemplo 2: Dado los vectores $\\boldsymbol{v_1}, \\boldsymbol{v_2}$ y $\\boldsymbol{v_3}$ encuentre una combinaci\u00f3n lineal de los mismos que producen $\\boldsymbol{y}$. \\boldsymbol{v_1}=\\left[\\begin{array}{c} 1\\\\ -2\\\\ 1 \\end{array}\\right] \\;\\;\\; \\boldsymbol{v_2}=\\left[\\begin{array}{c} 0\\\\ 1\\\\ 2 \\end{array}\\right] \\;\\;\\; \\boldsymbol{v_3}=\\left[\\begin{array}{c} -5\\\\ -2\\\\ 1 \\end{array}\\right]\\;\\;\\; \\boldsymbol{y}=\\left[\\begin{array}{c} 6\\\\ 1\\\\ -8 \\end{array}\\right] Proyecci\u00f3n Ortogonal Ahora nos interesa determinar la manera en que un vector $\\boldsymbol{y}$ puede ser descompuesto en dos o m\u00e1s vectores ortogonales. Para encontrar la forma de descomponer un vector en sus componentes ortogonales podemos partir de lo siguiente \\boldsymbol{y}=\\boldsymbol{\\hat{y}}+ \\boldsymbol{z} Tanto $\\boldsymbol{\\hat{y}}$ como $\\boldsymbol{z}$ son ortogonales entre s\u00ed, por lo que deben de cumplir con $\\boldsymbol{\\hat{y}}\\cdot \\boldsymbol{z}=0$. De igual manera, podemos definir que $\\boldsymbol{\\hat{y}}$ es una combinaci\u00f3n lineal del vector $\\boldsymbol{u}$ por lo que se puede tener la siguiente expresi\u00f3n \\boldsymbol{y}=\\alpha\\boldsymbol{u}+ \\boldsymbol{z} Siendo $\\alpha$ una constante, y tambi\u00e9n debe de cumplir con $\\boldsymbol{u}\\cdot \\boldsymbol{z}=0$. La ecuaci\u00f3n anterior puede ser reescrita como \\boldsymbol{z}=\\boldsymbol{y}-\\alpha\\boldsymbol{u} \\boldsymbol{z}\\cdot\\boldsymbol{u}=\\boldsymbol{y}\\cdot\\boldsymbol{u}-\\alpha\\boldsymbol{u}\\cdot\\boldsymbol{u} 0=\\boldsymbol{y}\\cdot\\boldsymbol{u}-\\alpha\\boldsymbol{u}\\cdot\\boldsymbol{u} \\alpha=\\frac{\\boldsymbol{y}\\cdot\\boldsymbol{u}}{\\boldsymbol{u}\\cdot\\boldsymbol{u}} Finalmente se puede decir que la proyecci\u00f3n ortogonal de $\\boldsymbol{y}$ en los vectores $\\boldsymbol{\\hat{y}}$ y $\\boldsymbol{z}$ se encuentra con \\boldsymbol{\\hat{y}}=\\frac{\\boldsymbol{y}\\cdot\\boldsymbol{u}}{\\boldsymbol{u}\\cdot\\boldsymbol{u}}\\boldsymbol{u},\\;\\;\\; \\boldsymbol{z}=\\boldsymbol{y}-\\boldsymbol{\\hat{y}} Algunas veces $\\boldsymbol{\\hat{y}}$ tambi\u00e9n se denomina proyecci\u00f3n ortogonal de $\\boldsymbol{y}$ sobre $L$ , $\\mathbf{proj_L}\\boldsymbol{y}$. Ejemplo 3: Dados los vectores $\\boldsymbol{y}$ y $\\boldsymbol{u}$ encuentre lo siguiente: La proyecci\u00f3n ortogonal de $\\boldsymbol{y}$ sobre $\\boldsymbol{u}$ Escriba $\\boldsymbol{y}$ como la suma de dos vectores, uno en $Gen${$\\boldsymbol{u}$} y el otro ortogonal a $\\boldsymbol{u}$ \\boldsymbol{y}=\\left[\\begin{array}{c} 1\\\\ 3\\\\ -2 \\end{array}\\right] \\;\\;\\; \\boldsymbol{u}=\\left[\\begin{array}{c} 7\\\\ -6\\\\ 5 \\end{array}\\right] Proyecci\u00f3n Ortogonal para $n$-Dimensiones Si se tiene una base $W=Gen${$\\boldsymbol{u_1}, \\boldsymbol{u_2}, \\cdots, \\boldsymbol{u_n}$} es posible descomponer un vector $\\boldsymbol{y}$ en $n$ vectores ortogonales aplicando lo siguiente \\boldsymbol{\\hat{y_1}}=\\frac{\\boldsymbol{y}\\cdot\\boldsymbol{u_1}}{\\boldsymbol{u_1}\\cdot\\boldsymbol{u_1}}\\boldsymbol{u_1} \\boldsymbol{\\hat{y_2}}=\\frac{\\boldsymbol{y}\\cdot\\boldsymbol{u_2}}{\\boldsymbol{u_2}\\cdot\\boldsymbol{u_2}}\\boldsymbol{u_2} \\vdots \\boldsymbol{\\hat{y_n}}=\\frac{\\boldsymbol{y}\\cdot\\boldsymbol{u_n}}{\\boldsymbol{u_n}\\cdot\\boldsymbol{u_n}}\\boldsymbol{u_n} Conjuntos Ortonormales Consiste en el conjunto ortogonal de vectores {$\\boldsymbol{u_1}, \\boldsymbol{u_2}, \\cdots, \\boldsymbol{u_p}$} unitarios. Para $W=Gen${$\\boldsymbol{u_1}, \\boldsymbol{u_2}, \\cdots, \\boldsymbol{u_p}$} decimos que $W$ es una base ortonormal. Base Est\u00e1ndar Uno de los conjuntos m\u00e1s importantes de vectores ortonormales es la base est\u00e1ndar, la cual consiste en los vectores \\boldsymbol{e_1}=\\left[\\begin{array}{c} 1\\\\ 0\\\\ 0 \\end{array}\\right] \\;\\;\\;\\boldsymbol{e_2}=\\left[\\begin{array}{c} 0\\\\ 1\\\\ 0 \\end{array}\\right] \\;\\;\\; \\boldsymbol{e_3}=\\left[\\begin{array}{c} 0\\\\ 0\\\\ 1 \\end{array}\\right] Observe que este conjunto de vectores cumple con \\boldsymbol{e_1} \\cdot \\boldsymbol{e_2}=0 \\;\\;\\;\\;\\;\\; \\left\\Vert \\boldsymbol{e_1} \\right\\Vert=1 \\boldsymbol{e_1} \\cdot \\boldsymbol{e_3}=0 \\;\\;\\;\\;\\;\\; \\left\\Vert \\boldsymbol{e_2} \\right\\Vert=1 \\boldsymbol{e_2} \\cdot \\boldsymbol{e_3}=0 \\;\\;\\;\\;\\;\\; \\left\\Vert \\boldsymbol{e_3} \\right\\Vert=1 Ejemplo 4: Dado el conjunto de vectores $\\boldsymbol{v_1}$, $\\boldsymbol{v_2}$ y $\\boldsymbol{v_3}$ determine una base ortonormal $W$. \\boldsymbol{v_1}=\\left[\\begin{array}{c} 1\\\\ 4\\\\ 1 \\end{array}\\right]\\;\\;\\; \\boldsymbol{v_2}=\\left[\\begin{array}{c} 1\\\\ 0\\\\ -1 \\end{array}\\right]\\;\\;\\; \\boldsymbol{v_3}=\\left[\\begin{array}{c} -2\\\\ 1\\\\ -2 \\end{array}\\right] Matrices Ortogonales Las matrices ortogonales son aquellas matrices $U$ de $m \\times n$ que poseen columnas ortonormales. Estas matrices cumplen con: U^TU=I Las matrices ortogonales $U$ de $n \\times n$, adem\u00e1s de tener sus columnas ortonormales, cumplen con que su filas tambi\u00e9n son ortonormales. Propiedades de las Matrices Ortogonales Sea $U$ una matriz de $m \\times n$ con columnas ortonormales, y $x$ y $y$ est\u00e1n en $\\mathbb{R}^n$ $U\\boldsymbol{x}=\\boldsymbol{x}$ $U\\boldsymbol{x} \\cdot U\\boldsymbol{y}=\\boldsymbol{x}\\cdot \\boldsymbol{y}$ $U\\boldsymbol{x} \\cdot U\\boldsymbol{y}=0\\iff \\boldsymbol{x}\\cdot \\boldsymbol{y=0}$ TAREA SECCI\u00d3N 6.2 2, 4, 7, 11, 13, 15, 18, 21, 27, 31, 34","title":"6.2 Conjuntos Ortogonales"},{"location":"chapter_06/62_Conjuntos_Ortogonales/#6-ortogonalidad-y-minimos-cuadrados","text":"","title":"6. Ortogonalidad y M\u00ednimos Cuadrados"},{"location":"chapter_06/62_Conjuntos_Ortogonales/#62-conjuntos-ortogonales","text":"Un conjunto de vectores {$\\boldsymbol{u_1}, \\boldsymbol{u_2}, \\cdots, \\boldsymbol{u_p}$} es un conjunto ortogonal si cada par de distintos vectores es ortogonal, es decir \\boldsymbol{u_1} \\cdot \\boldsymbol{u_2}=0, \\;\\;\\;\\boldsymbol{u_2} \\cdot \\boldsymbol{u_3}=0, \\;\\;\\;\\boldsymbol{u_1} \\cdot \\boldsymbol{u_3}=0 \\;\\;\\; \\cdots O en forma m\u00e1s general \\boldsymbol{u_i} \\cdot \\boldsymbol{u_j}=0; \\;\\;\\;i \\neq j Estos vectores son linealmente independientes y son una base para el sub-espacio generado. Ejemplo 1: Determine si el conjunto de vectores $S=${$\\boldsymbol{v_1}, \\boldsymbol{u_2}, \\boldsymbol{u_3}$} son ortogonales. \\boldsymbol{v_1}=\\left[\\begin{array}{c} 1\\\\ -2\\\\ 1 \\end{array}\\right]\\;\\;\\; \\boldsymbol{v_2}=\\left[\\begin{array}{c} 0\\\\ 1\\\\ 2 \\end{array}\\right]\\;\\;\\; \\boldsymbol{v_3}=\\left[\\begin{array}{c} -5\\\\ -2\\\\ 1 \\end{array}\\right] Para comprobar que el conjunto de vectores $S$ es ortogonal se debe de cumplir con $\\boldsymbol{u_i} \\cdot \\boldsymbol{u_j}=0$ para $i \\neq j$ \\boldsymbol{u_1} \\cdot \\boldsymbol{u_2}=\\left[\\begin{array}{ccc} 1 & -2 & 1 \\end{array}\\right]\\left[\\begin{array}{c} 0\\\\ 1\\\\ 2 \\end{array}\\right]=0-2+2=0 \\boldsymbol{u_1} \\cdot \\boldsymbol{u_3}=\\left[\\begin{array}{ccc} 1 & -2 & 1 \\end{array}\\right]\\left[\\begin{array}{c} -5\\\\ -2\\\\ 1 \\end{array}\\right]=-5+4+1=0 \\boldsymbol{u_2} \\cdot \\boldsymbol{u_3}=\\left[\\begin{array}{ccc} 0 & 1 & 2 \\end{array}\\right]\\left[\\begin{array}{c} -5\\\\ -2\\\\ 1 \\end{array}\\right]=0-2+2=0","title":"6.2 Conjuntos Ortogonales"},{"location":"chapter_06/62_Conjuntos_Ortogonales/#combinacion-lineal-de-vectores-ortogonales","text":"Dado el conjunto de vectores ortogonales S=\\left\\{ \\boldsymbol{u_1}, \\boldsymbol{u_2}, \\cdots, \\boldsymbol{u_p} \\right\\} La combinaci\u00f3n de los vectores en $S$ puede generar al vector $y$ de la forma \\boldsymbol{y}=c_1\\boldsymbol{u_1}+c_2\\boldsymbol{u_2}+\\cdots +c_p\\boldsymbol{u_p} Si ahora se obtiene $\\boldsymbol{y} \\cdot \\boldsymbol{u_1}$ como \\boldsymbol{y}\\cdot \\boldsymbol{u_1}=c_1\\boldsymbol{u_1}\\cdot \\boldsymbol{u_1}+c_2\\boldsymbol{u_2}\\cdot \\boldsymbol{u_1}+\\cdots +c_p\\boldsymbol{u_p}\\cdot \\boldsymbol{u_1} Observe que todos los t\u00e9rminos $\\boldsymbol{u_i} \\cdot \\boldsymbol{u_j}=0$ excepto $\\boldsymbol{u_i} \\cdot \\boldsymbol{u_i}$ por lo que la ecuaci\u00f3n anterior se reduce a \\boldsymbol{y}\\cdot \\boldsymbol{u_1}=c_1\\boldsymbol{u_1}\\cdot \\boldsymbol{u_1} Con lo cual es posible obtener una expresi\u00f3n para $c_1$ como c_1\\frac{\\boldsymbol{y}\\cdot \\boldsymbol{u_1}}{\\boldsymbol{u_1}\\cdot \\boldsymbol{u_1}} Si se aplica la misma metodolog\u00eda es posible generalizar la soluci\u00f3n de $c_i$ de la siguiente manera c_i\\frac{\\boldsymbol{y}\\cdot \\boldsymbol{u_i}}{\\boldsymbol{u_i}\\cdot \\boldsymbol{u_i}} Observe que la ortogonalidad de los vectores $\\boldsymbol{u_i}$ hace que ya no tenga que resolver la ecuaci\u00f3n lineal para encontrar los coeficientes $c_i$. Ejemplo 2: Dado los vectores $\\boldsymbol{v_1}, \\boldsymbol{v_2}$ y $\\boldsymbol{v_3}$ encuentre una combinaci\u00f3n lineal de los mismos que producen $\\boldsymbol{y}$. \\boldsymbol{v_1}=\\left[\\begin{array}{c} 1\\\\ -2\\\\ 1 \\end{array}\\right] \\;\\;\\; \\boldsymbol{v_2}=\\left[\\begin{array}{c} 0\\\\ 1\\\\ 2 \\end{array}\\right] \\;\\;\\; \\boldsymbol{v_3}=\\left[\\begin{array}{c} -5\\\\ -2\\\\ 1 \\end{array}\\right]\\;\\;\\; \\boldsymbol{y}=\\left[\\begin{array}{c} 6\\\\ 1\\\\ -8 \\end{array}\\right]","title":"Combinaci\u00f3n Lineal de Vectores Ortogonales"},{"location":"chapter_06/62_Conjuntos_Ortogonales/#proyeccion-ortogonal","text":"Ahora nos interesa determinar la manera en que un vector $\\boldsymbol{y}$ puede ser descompuesto en dos o m\u00e1s vectores ortogonales. Para encontrar la forma de descomponer un vector en sus componentes ortogonales podemos partir de lo siguiente \\boldsymbol{y}=\\boldsymbol{\\hat{y}}+ \\boldsymbol{z} Tanto $\\boldsymbol{\\hat{y}}$ como $\\boldsymbol{z}$ son ortogonales entre s\u00ed, por lo que deben de cumplir con $\\boldsymbol{\\hat{y}}\\cdot \\boldsymbol{z}=0$. De igual manera, podemos definir que $\\boldsymbol{\\hat{y}}$ es una combinaci\u00f3n lineal del vector $\\boldsymbol{u}$ por lo que se puede tener la siguiente expresi\u00f3n \\boldsymbol{y}=\\alpha\\boldsymbol{u}+ \\boldsymbol{z} Siendo $\\alpha$ una constante, y tambi\u00e9n debe de cumplir con $\\boldsymbol{u}\\cdot \\boldsymbol{z}=0$. La ecuaci\u00f3n anterior puede ser reescrita como \\boldsymbol{z}=\\boldsymbol{y}-\\alpha\\boldsymbol{u} \\boldsymbol{z}\\cdot\\boldsymbol{u}=\\boldsymbol{y}\\cdot\\boldsymbol{u}-\\alpha\\boldsymbol{u}\\cdot\\boldsymbol{u} 0=\\boldsymbol{y}\\cdot\\boldsymbol{u}-\\alpha\\boldsymbol{u}\\cdot\\boldsymbol{u} \\alpha=\\frac{\\boldsymbol{y}\\cdot\\boldsymbol{u}}{\\boldsymbol{u}\\cdot\\boldsymbol{u}} Finalmente se puede decir que la proyecci\u00f3n ortogonal de $\\boldsymbol{y}$ en los vectores $\\boldsymbol{\\hat{y}}$ y $\\boldsymbol{z}$ se encuentra con \\boldsymbol{\\hat{y}}=\\frac{\\boldsymbol{y}\\cdot\\boldsymbol{u}}{\\boldsymbol{u}\\cdot\\boldsymbol{u}}\\boldsymbol{u},\\;\\;\\; \\boldsymbol{z}=\\boldsymbol{y}-\\boldsymbol{\\hat{y}} Algunas veces $\\boldsymbol{\\hat{y}}$ tambi\u00e9n se denomina proyecci\u00f3n ortogonal de $\\boldsymbol{y}$ sobre $L$ , $\\mathbf{proj_L}\\boldsymbol{y}$. Ejemplo 3: Dados los vectores $\\boldsymbol{y}$ y $\\boldsymbol{u}$ encuentre lo siguiente: La proyecci\u00f3n ortogonal de $\\boldsymbol{y}$ sobre $\\boldsymbol{u}$ Escriba $\\boldsymbol{y}$ como la suma de dos vectores, uno en $Gen${$\\boldsymbol{u}$} y el otro ortogonal a $\\boldsymbol{u}$ \\boldsymbol{y}=\\left[\\begin{array}{c} 1\\\\ 3\\\\ -2 \\end{array}\\right] \\;\\;\\; \\boldsymbol{u}=\\left[\\begin{array}{c} 7\\\\ -6\\\\ 5 \\end{array}\\right]","title":"Proyecci\u00f3n Ortogonal"},{"location":"chapter_06/62_Conjuntos_Ortogonales/#proyeccion-ortogonal-para-n-dimensiones","text":"Si se tiene una base $W=Gen${$\\boldsymbol{u_1}, \\boldsymbol{u_2}, \\cdots, \\boldsymbol{u_n}$} es posible descomponer un vector $\\boldsymbol{y}$ en $n$ vectores ortogonales aplicando lo siguiente \\boldsymbol{\\hat{y_1}}=\\frac{\\boldsymbol{y}\\cdot\\boldsymbol{u_1}}{\\boldsymbol{u_1}\\cdot\\boldsymbol{u_1}}\\boldsymbol{u_1} \\boldsymbol{\\hat{y_2}}=\\frac{\\boldsymbol{y}\\cdot\\boldsymbol{u_2}}{\\boldsymbol{u_2}\\cdot\\boldsymbol{u_2}}\\boldsymbol{u_2} \\vdots \\boldsymbol{\\hat{y_n}}=\\frac{\\boldsymbol{y}\\cdot\\boldsymbol{u_n}}{\\boldsymbol{u_n}\\cdot\\boldsymbol{u_n}}\\boldsymbol{u_n}","title":"Proyecci\u00f3n Ortogonal para $n$-Dimensiones"},{"location":"chapter_06/62_Conjuntos_Ortogonales/#conjuntos-ortonormales","text":"Consiste en el conjunto ortogonal de vectores {$\\boldsymbol{u_1}, \\boldsymbol{u_2}, \\cdots, \\boldsymbol{u_p}$} unitarios. Para $W=Gen${$\\boldsymbol{u_1}, \\boldsymbol{u_2}, \\cdots, \\boldsymbol{u_p}$} decimos que $W$ es una base ortonormal.","title":"Conjuntos Ortonormales"},{"location":"chapter_06/62_Conjuntos_Ortogonales/#base-estandar","text":"Uno de los conjuntos m\u00e1s importantes de vectores ortonormales es la base est\u00e1ndar, la cual consiste en los vectores \\boldsymbol{e_1}=\\left[\\begin{array}{c} 1\\\\ 0\\\\ 0 \\end{array}\\right] \\;\\;\\;\\boldsymbol{e_2}=\\left[\\begin{array}{c} 0\\\\ 1\\\\ 0 \\end{array}\\right] \\;\\;\\; \\boldsymbol{e_3}=\\left[\\begin{array}{c} 0\\\\ 0\\\\ 1 \\end{array}\\right] Observe que este conjunto de vectores cumple con \\boldsymbol{e_1} \\cdot \\boldsymbol{e_2}=0 \\;\\;\\;\\;\\;\\; \\left\\Vert \\boldsymbol{e_1} \\right\\Vert=1 \\boldsymbol{e_1} \\cdot \\boldsymbol{e_3}=0 \\;\\;\\;\\;\\;\\; \\left\\Vert \\boldsymbol{e_2} \\right\\Vert=1 \\boldsymbol{e_2} \\cdot \\boldsymbol{e_3}=0 \\;\\;\\;\\;\\;\\; \\left\\Vert \\boldsymbol{e_3} \\right\\Vert=1 Ejemplo 4: Dado el conjunto de vectores $\\boldsymbol{v_1}$, $\\boldsymbol{v_2}$ y $\\boldsymbol{v_3}$ determine una base ortonormal $W$. \\boldsymbol{v_1}=\\left[\\begin{array}{c} 1\\\\ 4\\\\ 1 \\end{array}\\right]\\;\\;\\; \\boldsymbol{v_2}=\\left[\\begin{array}{c} 1\\\\ 0\\\\ -1 \\end{array}\\right]\\;\\;\\; \\boldsymbol{v_3}=\\left[\\begin{array}{c} -2\\\\ 1\\\\ -2 \\end{array}\\right]","title":"Base Est\u00e1ndar"},{"location":"chapter_06/62_Conjuntos_Ortogonales/#matrices-ortogonales","text":"Las matrices ortogonales son aquellas matrices $U$ de $m \\times n$ que poseen columnas ortonormales. Estas matrices cumplen con: U^TU=I Las matrices ortogonales $U$ de $n \\times n$, adem\u00e1s de tener sus columnas ortonormales, cumplen con que su filas tambi\u00e9n son ortonormales.","title":"Matrices Ortogonales"},{"location":"chapter_06/62_Conjuntos_Ortogonales/#propiedades-de-las-matrices-ortogonales","text":"Sea $U$ una matriz de $m \\times n$ con columnas ortonormales, y $x$ y $y$ est\u00e1n en $\\mathbb{R}^n$ $U\\boldsymbol{x}=\\boldsymbol{x}$ $U\\boldsymbol{x} \\cdot U\\boldsymbol{y}=\\boldsymbol{x}\\cdot \\boldsymbol{y}$ $U\\boldsymbol{x} \\cdot U\\boldsymbol{y}=0\\iff \\boldsymbol{x}\\cdot \\boldsymbol{y=0}$ TAREA SECCI\u00d3N 6.2 2, 4, 7, 11, 13, 15, 18, 21, 27, 31, 34","title":"Propiedades de las Matrices Ortogonales"},{"location":"chapter_06/63_Proyecciones_Ortogonales/","text":"6. Ortogonalidad y M\u00ednimos Cuadrados 6.3 Proyecciones Ortogonales Un espacio ortogonal puede ser descompuesto en varios sub-espacios ortogonales. Supongamos el espacio ortogonal $S$ en $\\mathbb{R}^5$ S=Gen\\{ \\boldsymbol{u_1}, \\boldsymbol{u_2}, \\boldsymbol{u_3}, \\boldsymbol{u_4}, \\boldsymbol{u_5} \\} Esta base ortogonal puede ser descompuesta en dos sub-espacios ortogonales $W$ y $W^\\perp$ W=Gen\\{ \\boldsymbol{u_1}, \\boldsymbol{u_2} \\}\\;\\;\\; W^\\perp=Gen\\{ \\boldsymbol{u_3}, \\boldsymbol{u_4}, \\boldsymbol{u_5} \\} Note que estos sub-espacios pueden generar m\u00e1s sub-espacios. Ejemplo 1: Suponga que {$\\boldsymbol{u_1}, \\boldsymbol{u_2}, \\boldsymbol{u_3}, \\boldsymbol{u_4}$} es una base ortogonal para $\\mathbb{R^4}$, escriba $\\boldsymbol{v}$ como la suma de dos vectores: uno en $Gen=${$\\boldsymbol{u_1}$} y otro en $Gen=${$\\boldsymbol{u_2}, \\boldsymbol{u_3}, \\boldsymbol{u_4}$}. \\boldsymbol{v}=\\left[\\begin{array}{c} 4\\\\ 5\\\\ -3\\\\ 3 \\end{array}\\right] \\;\\;\\; \\boldsymbol{u_1}=\\left[\\begin{array}{c} 1\\\\ 2\\\\ 1\\\\ 1 \\end{array}\\right]\\;\\;\\; \\boldsymbol{u_2}=\\left[\\begin{array}{c} -2\\\\ 1\\\\ -1\\\\ 1 \\end{array}\\right] \\;\\;\\; \\boldsymbol{u_3}=\\left[\\begin{array}{c} 1\\\\ 1\\\\ -2\\\\ -1 \\end{array}\\right] \\;\\;\\; \\boldsymbol{u_4}=\\left[\\begin{array}{c} -1\\\\ 1\\\\ 1\\\\ -2 \\end{array}\\right] Teorema de Descomposici\u00f3n Ortogonal Sea $W$ un sub-espacio de $\\mathbb{R^n}$, entonces toda $\\boldsymbol{y}$ en $\\mathbb{R^n}$ se puede escribir de forma \u00fanica como \\boldsymbol{y}=\\boldsymbol{\\hat{y}}+ \\boldsymbol{z} donde $\\boldsymbol{\\hat{y}}$ est\u00e1 en $W$ y $\\boldsymbol{z}$ est\u00e1 en $W^\\perp$ . Si {$\\boldsymbol{u_1}, \\boldsymbol{u_2}, \\cdots, \\boldsymbol{u_p}$} es cualquier base ortogonal de $W$ \\boldsymbol{\\hat{y}}=\\frac{\\boldsymbol{y}\\cdot\\boldsymbol{u_1}}{\\boldsymbol{u_1}\\cdot\\boldsymbol{u_1}}\\boldsymbol{u_1}+\\frac{\\boldsymbol{y}\\cdot\\boldsymbol{u_2}}{\\boldsymbol{u_2}\\cdot\\boldsymbol{u_2}}\\boldsymbol{u_2}+\\cdots+\\frac{\\boldsymbol{y}\\cdot\\boldsymbol{u_p}}{\\boldsymbol{u_p}\\cdot\\boldsymbol{u_p}}\\boldsymbol{u_p} y \\boldsymbol{z}=\\boldsymbol{y}-\\boldsymbol{\\hat{y}} Recuerde que muchas veces el t\u00e9rmino $\\boldsymbol{\\hat{y}}$ tambi\u00e9n se conoce como $\\mathbf{proj_W}\\boldsymbol{y}$. Ejemplo 2: Sea $W$ el sub-espacio generado por los vectores $\\boldsymbol{u}$, escriba a $\\boldsymbol{y}$ como la suma de un vector en $W$ y otro ortogonal a $W$. \\boldsymbol{y}=\\left[\\begin{array}{c} 1\\\\ 3\\\\ 5 \\end{array}\\right] \\;\\;\\; \\boldsymbol{u_1}=\\left[\\begin{array}{c} 1\\\\ 3\\\\ -2 \\end{array}\\right] \\;\\;\\; \\boldsymbol{u_2}= \\left[\\begin{array}{c} 5\\\\ 1\\\\ 4 \\end{array}\\right] Distancia m\u00e1s Corta a un Vector La siguiente animaci\u00f3n muestra dos vectores $\\boldsymbol{v}$, $\\boldsymbol{\\hat{y}}$ que est\u00e1n en $W$ as\u00ed como tambi\u00e9n un vector $\\boldsymbol{y}$ que est\u00e1 en $W^\\perp$. En la animaci\u00f3n puede observar que el vector m\u00e1s cercano a $\\boldsymbol{y}$ es $\\boldsymbol{\\hat{y}}$. A continuaci\u00f3n demostraremos que esto es cierto. Podemos definir lo siguiente: \\boldsymbol{y}-\\boldsymbol{v} = (\\boldsymbol{y}-\\boldsymbol{\\hat{y}})+ (\\boldsymbol{\\hat{y}}-\\boldsymbol{v}) O en t\u00e9rminos de las distancias cuadr\u00e1ticas \\left\\Vert \\boldsymbol{y}-\\boldsymbol{v} \\right\\Vert ^2 = \\left\\Vert \\boldsymbol{y}-\\boldsymbol{\\hat{y}} \\right\\Vert ^2+ \\left\\Vert \\boldsymbol{\\hat{y}}-\\boldsymbol{v} \\right\\Vert ^2 Observe que $\\boldsymbol{\\hat{y}} \\neq \\boldsymbol{v}$ por lo que \\left\\Vert \\boldsymbol{y}-\\boldsymbol{v} \\right\\Vert ^2 > \\left\\Vert \\boldsymbol{y}-\\boldsymbol{\\hat{y}} \\right\\Vert ^2 Ejemplo 3: Determine el punto y la distancia m\u00e1s cercana a $\\boldsymbol{y}$ en el sub-espacio $W$ generado por $\\boldsymbol{v_1}$ y $\\boldsymbol{v_2}$. \\boldsymbol{y}=\\left[\\begin{array}{c} 3\\\\ -1\\\\ 1\\\\ 13 \\end{array}\\right] \\;\\;\\; \\boldsymbol{v_1}=\\left[\\begin{array}{c} 1\\\\ -2\\\\ -1\\\\ 2 \\end{array}\\right] \\;\\;\\; \\boldsymbol{v_2}=\\left[\\begin{array}{c} -4\\\\ 1\\\\ 0\\\\ 3 \\end{array}\\right] Proyecciones Ortogonales con Bases Ortonormales Si {$\\boldsymbol{u_1},\\dots, \\boldsymbol{u_p}$} es una base ortonormal para un subespacio $W$ de $\\mathbb{R^n}$, entonces \\mathbf{proj_W}\\boldsymbol{y}=(\\boldsymbol{y}\\cdot\\boldsymbol{u_1})\\boldsymbol{u_1}+(\\boldsymbol{y}\\cdot\\boldsymbol{u_2})\\boldsymbol{u_2}+\\cdots+(\\boldsymbol{y}\\cdot\\boldsymbol{u_p})\\boldsymbol{u_p} Observe que en esta ecuaci\u00f3n $\\mathbf{proj_W}\\boldsymbol{y}$ puede ser interpretado como la combinaci\u00f3n lineal de los vectores {$\\boldsymbol{u_1},\\dots, \\boldsymbol{u_p}$}. Adem\u00e1s \\boldsymbol{y}\\cdot\\boldsymbol{u_k}=\\boldsymbol{u_k}^T\\boldsymbol{y} Por lo que se puede generalizar una matriz $U$ tal que U=\\left[\\begin{array}{c} \\boldsymbol{u_1}^T\\\\ \\boldsymbol{u_2}^T\\\\ \\vdots\\\\ \\boldsymbol{u_4}^T \\end{array}\\right] Finalmente se puede escribir \\mathbf{proj_W}\\boldsymbol{y}=UU^T\\boldsymbol{y} TAREA SECCI\u00d3N 6.3 1, 3, 5, 8, 9, 11, 13, 19, 23","title":"6.3 Proyecciones Ortogonales"},{"location":"chapter_06/63_Proyecciones_Ortogonales/#6-ortogonalidad-y-minimos-cuadrados","text":"","title":"6. Ortogonalidad y M\u00ednimos Cuadrados"},{"location":"chapter_06/63_Proyecciones_Ortogonales/#63-proyecciones-ortogonales","text":"Un espacio ortogonal puede ser descompuesto en varios sub-espacios ortogonales. Supongamos el espacio ortogonal $S$ en $\\mathbb{R}^5$ S=Gen\\{ \\boldsymbol{u_1}, \\boldsymbol{u_2}, \\boldsymbol{u_3}, \\boldsymbol{u_4}, \\boldsymbol{u_5} \\} Esta base ortogonal puede ser descompuesta en dos sub-espacios ortogonales $W$ y $W^\\perp$ W=Gen\\{ \\boldsymbol{u_1}, \\boldsymbol{u_2} \\}\\;\\;\\; W^\\perp=Gen\\{ \\boldsymbol{u_3}, \\boldsymbol{u_4}, \\boldsymbol{u_5} \\} Note que estos sub-espacios pueden generar m\u00e1s sub-espacios. Ejemplo 1: Suponga que {$\\boldsymbol{u_1}, \\boldsymbol{u_2}, \\boldsymbol{u_3}, \\boldsymbol{u_4}$} es una base ortogonal para $\\mathbb{R^4}$, escriba $\\boldsymbol{v}$ como la suma de dos vectores: uno en $Gen=${$\\boldsymbol{u_1}$} y otro en $Gen=${$\\boldsymbol{u_2}, \\boldsymbol{u_3}, \\boldsymbol{u_4}$}. \\boldsymbol{v}=\\left[\\begin{array}{c} 4\\\\ 5\\\\ -3\\\\ 3 \\end{array}\\right] \\;\\;\\; \\boldsymbol{u_1}=\\left[\\begin{array}{c} 1\\\\ 2\\\\ 1\\\\ 1 \\end{array}\\right]\\;\\;\\; \\boldsymbol{u_2}=\\left[\\begin{array}{c} -2\\\\ 1\\\\ -1\\\\ 1 \\end{array}\\right] \\;\\;\\; \\boldsymbol{u_3}=\\left[\\begin{array}{c} 1\\\\ 1\\\\ -2\\\\ -1 \\end{array}\\right] \\;\\;\\; \\boldsymbol{u_4}=\\left[\\begin{array}{c} -1\\\\ 1\\\\ 1\\\\ -2 \\end{array}\\right]","title":"6.3 Proyecciones Ortogonales"},{"location":"chapter_06/63_Proyecciones_Ortogonales/#teorema-de-descomposicion-ortogonal","text":"Sea $W$ un sub-espacio de $\\mathbb{R^n}$, entonces toda $\\boldsymbol{y}$ en $\\mathbb{R^n}$ se puede escribir de forma \u00fanica como \\boldsymbol{y}=\\boldsymbol{\\hat{y}}+ \\boldsymbol{z} donde $\\boldsymbol{\\hat{y}}$ est\u00e1 en $W$ y $\\boldsymbol{z}$ est\u00e1 en $W^\\perp$ . Si {$\\boldsymbol{u_1}, \\boldsymbol{u_2}, \\cdots, \\boldsymbol{u_p}$} es cualquier base ortogonal de $W$ \\boldsymbol{\\hat{y}}=\\frac{\\boldsymbol{y}\\cdot\\boldsymbol{u_1}}{\\boldsymbol{u_1}\\cdot\\boldsymbol{u_1}}\\boldsymbol{u_1}+\\frac{\\boldsymbol{y}\\cdot\\boldsymbol{u_2}}{\\boldsymbol{u_2}\\cdot\\boldsymbol{u_2}}\\boldsymbol{u_2}+\\cdots+\\frac{\\boldsymbol{y}\\cdot\\boldsymbol{u_p}}{\\boldsymbol{u_p}\\cdot\\boldsymbol{u_p}}\\boldsymbol{u_p} y \\boldsymbol{z}=\\boldsymbol{y}-\\boldsymbol{\\hat{y}} Recuerde que muchas veces el t\u00e9rmino $\\boldsymbol{\\hat{y}}$ tambi\u00e9n se conoce como $\\mathbf{proj_W}\\boldsymbol{y}$. Ejemplo 2: Sea $W$ el sub-espacio generado por los vectores $\\boldsymbol{u}$, escriba a $\\boldsymbol{y}$ como la suma de un vector en $W$ y otro ortogonal a $W$. \\boldsymbol{y}=\\left[\\begin{array}{c} 1\\\\ 3\\\\ 5 \\end{array}\\right] \\;\\;\\; \\boldsymbol{u_1}=\\left[\\begin{array}{c} 1\\\\ 3\\\\ -2 \\end{array}\\right] \\;\\;\\; \\boldsymbol{u_2}= \\left[\\begin{array}{c} 5\\\\ 1\\\\ 4 \\end{array}\\right]","title":"Teorema de Descomposici\u00f3n Ortogonal"},{"location":"chapter_06/63_Proyecciones_Ortogonales/#distancia-mas-corta-a-un-vector","text":"La siguiente animaci\u00f3n muestra dos vectores $\\boldsymbol{v}$, $\\boldsymbol{\\hat{y}}$ que est\u00e1n en $W$ as\u00ed como tambi\u00e9n un vector $\\boldsymbol{y}$ que est\u00e1 en $W^\\perp$. En la animaci\u00f3n puede observar que el vector m\u00e1s cercano a $\\boldsymbol{y}$ es $\\boldsymbol{\\hat{y}}$. A continuaci\u00f3n demostraremos que esto es cierto. Podemos definir lo siguiente: \\boldsymbol{y}-\\boldsymbol{v} = (\\boldsymbol{y}-\\boldsymbol{\\hat{y}})+ (\\boldsymbol{\\hat{y}}-\\boldsymbol{v}) O en t\u00e9rminos de las distancias cuadr\u00e1ticas \\left\\Vert \\boldsymbol{y}-\\boldsymbol{v} \\right\\Vert ^2 = \\left\\Vert \\boldsymbol{y}-\\boldsymbol{\\hat{y}} \\right\\Vert ^2+ \\left\\Vert \\boldsymbol{\\hat{y}}-\\boldsymbol{v} \\right\\Vert ^2 Observe que $\\boldsymbol{\\hat{y}} \\neq \\boldsymbol{v}$ por lo que \\left\\Vert \\boldsymbol{y}-\\boldsymbol{v} \\right\\Vert ^2 > \\left\\Vert \\boldsymbol{y}-\\boldsymbol{\\hat{y}} \\right\\Vert ^2 Ejemplo 3: Determine el punto y la distancia m\u00e1s cercana a $\\boldsymbol{y}$ en el sub-espacio $W$ generado por $\\boldsymbol{v_1}$ y $\\boldsymbol{v_2}$. \\boldsymbol{y}=\\left[\\begin{array}{c} 3\\\\ -1\\\\ 1\\\\ 13 \\end{array}\\right] \\;\\;\\; \\boldsymbol{v_1}=\\left[\\begin{array}{c} 1\\\\ -2\\\\ -1\\\\ 2 \\end{array}\\right] \\;\\;\\; \\boldsymbol{v_2}=\\left[\\begin{array}{c} -4\\\\ 1\\\\ 0\\\\ 3 \\end{array}\\right]","title":"Distancia m\u00e1s Corta a un Vector"},{"location":"chapter_06/63_Proyecciones_Ortogonales/#proyecciones-ortogonales-con-bases-ortonormales","text":"Si {$\\boldsymbol{u_1},\\dots, \\boldsymbol{u_p}$} es una base ortonormal para un subespacio $W$ de $\\mathbb{R^n}$, entonces \\mathbf{proj_W}\\boldsymbol{y}=(\\boldsymbol{y}\\cdot\\boldsymbol{u_1})\\boldsymbol{u_1}+(\\boldsymbol{y}\\cdot\\boldsymbol{u_2})\\boldsymbol{u_2}+\\cdots+(\\boldsymbol{y}\\cdot\\boldsymbol{u_p})\\boldsymbol{u_p} Observe que en esta ecuaci\u00f3n $\\mathbf{proj_W}\\boldsymbol{y}$ puede ser interpretado como la combinaci\u00f3n lineal de los vectores {$\\boldsymbol{u_1},\\dots, \\boldsymbol{u_p}$}. Adem\u00e1s \\boldsymbol{y}\\cdot\\boldsymbol{u_k}=\\boldsymbol{u_k}^T\\boldsymbol{y} Por lo que se puede generalizar una matriz $U$ tal que U=\\left[\\begin{array}{c} \\boldsymbol{u_1}^T\\\\ \\boldsymbol{u_2}^T\\\\ \\vdots\\\\ \\boldsymbol{u_4}^T \\end{array}\\right] Finalmente se puede escribir \\mathbf{proj_W}\\boldsymbol{y}=UU^T\\boldsymbol{y} TAREA SECCI\u00d3N 6.3 1, 3, 5, 8, 9, 11, 13, 19, 23","title":"Proyecciones Ortogonales con Bases Ortonormales"},{"location":"chapter_06/64_Proceso_Gram_Schmidt/","text":"6. Ortogonalidad y M\u00ednimos Cuadrados 6.4 Proceso de Gram-Schmidt El proceso de Gram-Schmidt es un sencillo algoritmo para obtener una base ortogonal u ortonormal para cualquier subespacio diferente de cero de $\\mathbb{R^n}$. A partir de una base {$\\boldsymbol{x_1},\\dots, \\boldsymbol{x_p}$} para un subespacio $W$ de $\\mathbb{R^n}$, se define \\boldsymbol{v_1} = \\boldsymbol{x_1} \\boldsymbol{v_2} = \\boldsymbol{x_2}-\\frac{\\boldsymbol{x_2 \\cdot \\boldsymbol{v_1}}}{\\boldsymbol{v_1 \\cdot \\boldsymbol{v_1}}}\\boldsymbol{v_1} \\boldsymbol{v_3} = \\boldsymbol{x_3}-\\frac{\\boldsymbol{x_3 \\cdot \\boldsymbol{v_1}}}{\\boldsymbol{v_1 \\cdot \\boldsymbol{v_1}}}\\boldsymbol{v_1} -\\frac{\\boldsymbol{x_3 \\cdot \\boldsymbol{v_2}}}{\\boldsymbol{v_2 \\cdot \\boldsymbol{v_2}}}\\boldsymbol{v_2} \\vdots \\boldsymbol{v_p} = \\boldsymbol{x_p}-\\frac{\\boldsymbol{x_p \\cdot \\boldsymbol{v_1}}}{\\boldsymbol{v_1 \\cdot \\boldsymbol{v_1}}}\\boldsymbol{v_1} -\\frac{\\boldsymbol{x_p \\cdot \\boldsymbol{v_2}}}{\\boldsymbol{v_2 \\cdot \\boldsymbol{v_2}}}\\boldsymbol{v_2}-\\cdots-\\frac{\\boldsymbol{x_p \\cdot \\boldsymbol{v_{p-1}}}}{\\boldsymbol{v_{p-1} \\cdot \\boldsymbol{v_{p-1}}}}\\boldsymbol{v_{p-1}} Base Ortonormal Una base ortonormal se construye con facilidad a partir de una base ortogonal {$\\boldsymbol{v_1},\\dots, \\boldsymbol{v_p}$} simplemente normalizando todas las $\\boldsymbol{v_k}$, es decir \\boldsymbol{u_k}=\\frac{1}{\\left\\Vert \\boldsymbol{v_k} \\right\\Vert}\\boldsymbol{v_k} Ejemplo 1: Dados los vectores $\\boldsymbol{x_1} $, $\\boldsymbol{x_2}$, $\\boldsymbol{x_3}$ que forman una base para $W$, encuentre: Una base ortogonal para $W$. Una base ortonormal para $W$. \\boldsymbol{x_1}=\\left[\\begin{array}{c} 1\\\\ 0\\\\ 1\\\\ 1\\\\ 0 \\end{array}\\right]\\;\\;\\; \\boldsymbol{x_2}=\\left[\\begin{array}{c} 0\\\\ 0\\\\ 1\\\\ 0\\\\ 1 \\end{array}\\right] \\;\\;\\; \\boldsymbol{x_3}=\\left[\\begin{array}{c} 1\\\\ 1\\\\ 0\\\\ 1\\\\ 1 \\end{array}\\right] Ejemplo 2: Dados los vectores $\\boldsymbol{x_1} $, $\\boldsymbol{x_2}$, $\\boldsymbol{x_3}$ que forman una base para $W$, encuentre una base ortogonal para $W$, luego implemente este algoritmo en python. \\boldsymbol{x_1}=\\left[\\begin{array}{c} 9\\\\ 0\\\\ 6\\\\ -7 \\end{array}\\right]\\;\\;\\; \\boldsymbol{x_2}=\\left[\\begin{array}{c} -1\\\\ 8\\\\ 6\\\\ 9 \\end{array}\\right] \\;\\;\\; \\boldsymbol{x_3}=\\left[\\begin{array}{c} 3\\\\ -9\\\\ 7\\\\ 8 \\end{array}\\right] Algoritmo en Software del Proceso de Gram-Schmidt El siguiente bloque de c\u00f3digo presenta la implementaci\u00f3n del algoritmo del Proceso de Gram-Schmidt en Python. El costo de este algoritmo es de $\\mathcal{O}(nk^2)$ operaciones de punto flotante, donde $n$ es el n\u00famero de filas y $k$ el n\u00famero de columnas de la matriz $V$ a encontrar una base ortonormal. Factorizaci\u00f3n QR Si $A$ es una matriz de $m \\times n$ con columnas linealmente independientes, entonces $A$ se puede factorizar como $A = QR$, donde $Q$ es una matriz de $m \\times n$ cuyas columnas forman una base ortonormal para $\\mathbf{Col} A$, y $R$ es una matriz triangular superior invertible de $n \\times n$ con entradas positivas en su diagonal. Para comprender la validez de la factorizaci\u00f3n $QR$ puede considerar que el espacio de $\\mathbf{Col}A$ debe de ser generado tanto por las columnas de $A$ como por las columnas de $Q$, por lo que si $A=[\\boldsymbol{x_1}, \\boldsymbol{x_2}, \\cdots, \\boldsymbol{x_n}]$ y $Q=[\\boldsymbol{u_1}, \\boldsymbol{u_2}, \\cdots, \\boldsymbol{u_n}]$ entonces Gen=\\{\\boldsymbol{x_1}, \\boldsymbol{x_2}, \\cdots, \\boldsymbol{x_n}\\}=Gen=\\{\\boldsymbol{u_1}, \\boldsymbol{u_2}, \\cdots, \\boldsymbol{u_n}\\} Esto sugiere adem\u00e1s que debe de ser valido lo siguiente \\boldsymbol{x_1}=r_{11}\\boldsymbol{u_1} \\boldsymbol{x_2}=r_{12}\\boldsymbol{u_1} + r_{22}\\boldsymbol{u_2} \\boldsymbol{x_3}=r_{13}\\boldsymbol{u_1} + r_{23}\\boldsymbol{u_2} + r_{33}\\boldsymbol{u_3} \\vdots \\boldsymbol{x_n}=r_{1n}\\boldsymbol{u_1} + r_{2n}\\boldsymbol{u_2} +\\dots + r_{nn}\\boldsymbol{u_n} O de una forma matricial [\\boldsymbol{u_1} \\; \\boldsymbol{u_2}\\; \\cdots \\; \\boldsymbol{u_n}]\\left[\\begin{array}{ccccc} r_{11} & r_{12} & r_{13} & \\dots & r_{1n}\\\\ 0 & r_{22} & r_{23} & \\cdots & r_{2n}\\\\ 0 & 0 & r_{33} & \\cdots & r_{3n}\\\\ \\vdots & \\vdots & \\vdots & \\cdots & \\vdots\\\\ 0 & 0 & 0 & 0 & r_{nn} \\end{array}\\right] Observe que al conocer $Q$ es posible determinar $R$ del hecho de que $Q$ es ortonormal cumple con $Q^TQ=I$ por lo que A=QR Q^TA=Q^TQR Q^TA=R El siguiente c\u00f3digo presenta como implementar la factorizaci\u00f3n $QR$ en python. TAREA SECCI\u00d3N 6.4","title":"6.4 Proceso de Gram-Schmidt"},{"location":"chapter_06/64_Proceso_Gram_Schmidt/#6-ortogonalidad-y-minimos-cuadrados","text":"","title":"6. Ortogonalidad y M\u00ednimos Cuadrados"},{"location":"chapter_06/64_Proceso_Gram_Schmidt/#64-proceso-de-gram-schmidt","text":"El proceso de Gram-Schmidt es un sencillo algoritmo para obtener una base ortogonal u ortonormal para cualquier subespacio diferente de cero de $\\mathbb{R^n}$. A partir de una base {$\\boldsymbol{x_1},\\dots, \\boldsymbol{x_p}$} para un subespacio $W$ de $\\mathbb{R^n}$, se define \\boldsymbol{v_1} = \\boldsymbol{x_1} \\boldsymbol{v_2} = \\boldsymbol{x_2}-\\frac{\\boldsymbol{x_2 \\cdot \\boldsymbol{v_1}}}{\\boldsymbol{v_1 \\cdot \\boldsymbol{v_1}}}\\boldsymbol{v_1} \\boldsymbol{v_3} = \\boldsymbol{x_3}-\\frac{\\boldsymbol{x_3 \\cdot \\boldsymbol{v_1}}}{\\boldsymbol{v_1 \\cdot \\boldsymbol{v_1}}}\\boldsymbol{v_1} -\\frac{\\boldsymbol{x_3 \\cdot \\boldsymbol{v_2}}}{\\boldsymbol{v_2 \\cdot \\boldsymbol{v_2}}}\\boldsymbol{v_2} \\vdots \\boldsymbol{v_p} = \\boldsymbol{x_p}-\\frac{\\boldsymbol{x_p \\cdot \\boldsymbol{v_1}}}{\\boldsymbol{v_1 \\cdot \\boldsymbol{v_1}}}\\boldsymbol{v_1} -\\frac{\\boldsymbol{x_p \\cdot \\boldsymbol{v_2}}}{\\boldsymbol{v_2 \\cdot \\boldsymbol{v_2}}}\\boldsymbol{v_2}-\\cdots-\\frac{\\boldsymbol{x_p \\cdot \\boldsymbol{v_{p-1}}}}{\\boldsymbol{v_{p-1} \\cdot \\boldsymbol{v_{p-1}}}}\\boldsymbol{v_{p-1}}","title":"6.4 Proceso de Gram-Schmidt"},{"location":"chapter_06/64_Proceso_Gram_Schmidt/#base-ortonormal","text":"Una base ortonormal se construye con facilidad a partir de una base ortogonal {$\\boldsymbol{v_1},\\dots, \\boldsymbol{v_p}$} simplemente normalizando todas las $\\boldsymbol{v_k}$, es decir \\boldsymbol{u_k}=\\frac{1}{\\left\\Vert \\boldsymbol{v_k} \\right\\Vert}\\boldsymbol{v_k} Ejemplo 1: Dados los vectores $\\boldsymbol{x_1} $, $\\boldsymbol{x_2}$, $\\boldsymbol{x_3}$ que forman una base para $W$, encuentre: Una base ortogonal para $W$. Una base ortonormal para $W$. \\boldsymbol{x_1}=\\left[\\begin{array}{c} 1\\\\ 0\\\\ 1\\\\ 1\\\\ 0 \\end{array}\\right]\\;\\;\\; \\boldsymbol{x_2}=\\left[\\begin{array}{c} 0\\\\ 0\\\\ 1\\\\ 0\\\\ 1 \\end{array}\\right] \\;\\;\\; \\boldsymbol{x_3}=\\left[\\begin{array}{c} 1\\\\ 1\\\\ 0\\\\ 1\\\\ 1 \\end{array}\\right] Ejemplo 2: Dados los vectores $\\boldsymbol{x_1} $, $\\boldsymbol{x_2}$, $\\boldsymbol{x_3}$ que forman una base para $W$, encuentre una base ortogonal para $W$, luego implemente este algoritmo en python. \\boldsymbol{x_1}=\\left[\\begin{array}{c} 9\\\\ 0\\\\ 6\\\\ -7 \\end{array}\\right]\\;\\;\\; \\boldsymbol{x_2}=\\left[\\begin{array}{c} -1\\\\ 8\\\\ 6\\\\ 9 \\end{array}\\right] \\;\\;\\; \\boldsymbol{x_3}=\\left[\\begin{array}{c} 3\\\\ -9\\\\ 7\\\\ 8 \\end{array}\\right]","title":"Base Ortonormal"},{"location":"chapter_06/64_Proceso_Gram_Schmidt/#algoritmo-en-software-del-proceso-de-gram-schmidt","text":"El siguiente bloque de c\u00f3digo presenta la implementaci\u00f3n del algoritmo del Proceso de Gram-Schmidt en Python. El costo de este algoritmo es de $\\mathcal{O}(nk^2)$ operaciones de punto flotante, donde $n$ es el n\u00famero de filas y $k$ el n\u00famero de columnas de la matriz $V$ a encontrar una base ortonormal.","title":"Algoritmo en Software del Proceso de Gram-Schmidt"},{"location":"chapter_06/64_Proceso_Gram_Schmidt/#factorizacion-qr","text":"Si $A$ es una matriz de $m \\times n$ con columnas linealmente independientes, entonces $A$ se puede factorizar como $A = QR$, donde $Q$ es una matriz de $m \\times n$ cuyas columnas forman una base ortonormal para $\\mathbf{Col} A$, y $R$ es una matriz triangular superior invertible de $n \\times n$ con entradas positivas en su diagonal. Para comprender la validez de la factorizaci\u00f3n $QR$ puede considerar que el espacio de $\\mathbf{Col}A$ debe de ser generado tanto por las columnas de $A$ como por las columnas de $Q$, por lo que si $A=[\\boldsymbol{x_1}, \\boldsymbol{x_2}, \\cdots, \\boldsymbol{x_n}]$ y $Q=[\\boldsymbol{u_1}, \\boldsymbol{u_2}, \\cdots, \\boldsymbol{u_n}]$ entonces Gen=\\{\\boldsymbol{x_1}, \\boldsymbol{x_2}, \\cdots, \\boldsymbol{x_n}\\}=Gen=\\{\\boldsymbol{u_1}, \\boldsymbol{u_2}, \\cdots, \\boldsymbol{u_n}\\} Esto sugiere adem\u00e1s que debe de ser valido lo siguiente \\boldsymbol{x_1}=r_{11}\\boldsymbol{u_1} \\boldsymbol{x_2}=r_{12}\\boldsymbol{u_1} + r_{22}\\boldsymbol{u_2} \\boldsymbol{x_3}=r_{13}\\boldsymbol{u_1} + r_{23}\\boldsymbol{u_2} + r_{33}\\boldsymbol{u_3} \\vdots \\boldsymbol{x_n}=r_{1n}\\boldsymbol{u_1} + r_{2n}\\boldsymbol{u_2} +\\dots + r_{nn}\\boldsymbol{u_n} O de una forma matricial [\\boldsymbol{u_1} \\; \\boldsymbol{u_2}\\; \\cdots \\; \\boldsymbol{u_n}]\\left[\\begin{array}{ccccc} r_{11} & r_{12} & r_{13} & \\dots & r_{1n}\\\\ 0 & r_{22} & r_{23} & \\cdots & r_{2n}\\\\ 0 & 0 & r_{33} & \\cdots & r_{3n}\\\\ \\vdots & \\vdots & \\vdots & \\cdots & \\vdots\\\\ 0 & 0 & 0 & 0 & r_{nn} \\end{array}\\right] Observe que al conocer $Q$ es posible determinar $R$ del hecho de que $Q$ es ortonormal cumple con $Q^TQ=I$ por lo que A=QR Q^TA=Q^TQR Q^TA=R El siguiente c\u00f3digo presenta como implementar la factorizaci\u00f3n $QR$ en python. TAREA SECCI\u00d3N 6.4","title":"Factorizaci\u00f3n QR"},{"location":"chapter_06/65_Problemas_de_Minimos_Cuadrados/","text":"6. Ortogonalidad y M\u00ednimos Cuadrados 6.5 Problemas de M\u00ednimos Cuadrados Cuando se desea una soluci\u00f3n y la misma no existe, lo mejor que se puede hacer es encontrar una $\\boldsymbol{x}$ tal que $A\\boldsymbol{x}$ est\u00e9 lo m\u00e1s cerca posible de $\\boldsymbol{b}$. Podemos decir que: $A\\boldsymbol{x}$ es una aproximaci\u00f3n de $\\boldsymbol{b}$. Cuanto menor sea la distancia entre $\\boldsymbol{b}$ y $A\\boldsymbol{x}$, $\\left\\Vert \\boldsymbol{b} - A\\boldsymbol{x}\\right \\Vert $, mucho mejor ser\u00e1 la aproximaci\u00f3n. El problema general de m\u00ednimos cuadrados consiste en encontrar una $\\boldsymbol{x}$ que haga a $\\left\\Vert \\boldsymbol{b} - A\\boldsymbol{x}\\right \\Vert $ tan peque\u00f1a como sea posible. Definici\u00f3n del Problema de M\u00ednimos Cuadrados Si $A$ es de $m \\times n$ y $\\boldsymbol{b}$ en $\\mathbb{R^m}$, una soluci\u00f3n de m\u00ednimos cuadrados de $A\\boldsymbol{x}=\\boldsymbol{b}$ es un $\\boldsymbol{\\hat{x}}$ en $\\mathbb{R^n}$ tal que \\left\\Vert \\boldsymbol{b} - A\\boldsymbol{\\hat{x}}\\right \\Vert \\leq \\left\\Vert \\boldsymbol{b} - A\\boldsymbol{x}\\right \\Vert para cualquier $\\boldsymbol{x}$ en $\\mathbb{R^n}$ En forma resumida, el Problema de M\u00ednimos Cuadrados busca el vector $\\boldsymbol{x}$ que haga que $A\\boldsymbol{x}$ sea el punto en $\\mathbf{Col}A$ m\u00e1s cercano a $\\boldsymbol{b}$. Ecuaci\u00f3n de un Problema de M\u00ednimos Cuadrados La ecuaci\u00f3n de la soluci\u00f3n de un problema por m\u00ednimos cuadrados es A^TA\\boldsymbol{x}=A^T\\boldsymbol{b} Usualmente a esta ecuaci\u00f3n se le denomina Sistema de Ecuaciones Normales para $A\\boldsymbol{x}=\\boldsymbol{b}$ . Esta ecuaci\u00f3n se puede obtener si se considera que $A\\boldsymbol{x}=\\boldsymbol{b}$ no tiene soluci\u00f3n, sin embargo se puede buscar un A\\boldsymbol{\\hat{x}}=\\boldsymbol{\\hat{b}} que si existe. Observe que la descomposici\u00f3n ortogonal $\\boldsymbol{z}=\\boldsymbol{b}-\\boldsymbol{\\hat{{b}}}$ debe de ser v\u00e1lida. As\u00ed mismo, $\\boldsymbol{z}$ debe de ser ortogonal a $\\mathbf{Col}A$ por lo que \\boldsymbol{a_1}\\cdot\\boldsymbol{z}=\\boldsymbol{a_1}\\cdot(\\boldsymbol{b}-\\boldsymbol{\\hat{{b}}})=\\boldsymbol{a_1}^T(\\boldsymbol{b}-\\boldsymbol{\\hat{{b}}})=0 \\boldsymbol{a_2}\\cdot\\boldsymbol{z}=\\boldsymbol{a_2}\\cdot(\\boldsymbol{b}-\\boldsymbol{\\hat{{b}}})=\\boldsymbol{a_2}^T(\\boldsymbol{b}-\\boldsymbol{\\hat{{b}}})=0 \\vdots \\boldsymbol{a_n}\\cdot\\boldsymbol{z}=\\boldsymbol{a_n}\\cdot(\\boldsymbol{b}-\\boldsymbol{\\hat{{b}}})=\\boldsymbol{a_n}^T(\\boldsymbol{b}-\\boldsymbol{\\hat{{b}}})=0 Si $A^T=[\\boldsymbol{a_1}^T \\;\\boldsymbol{a_2}^T \\; \\dots\\;\\boldsymbol{a_n}^T]$, se puede escribir A^T(\\boldsymbol{b}-\\boldsymbol{\\hat{{b}}})=0 A^T(\\boldsymbol{b}-A\\boldsymbol{\\hat{{x}}})=0 A^T\\boldsymbol{b}-A^TA\\boldsymbol{\\hat{{x}}}=0 A^TA\\boldsymbol{x}=A^T\\boldsymbol{b} Teorema El conjunto de soluciones de m\u00ednimos cuadrados de $A\\boldsymbol{x}=\\boldsymbol{b}$ coincide con el conjunto no vac\u00edo de soluciones de las ecuaciones normales $A^TA\\boldsymbol{x}=A^T\\boldsymbol{b}$. Ejemplo 1: Encuentre una soluci\u00f3n de m\u00ednimos cuadrados del sistema inconsistente $A\\boldsymbol{x}=\\boldsymbol{b}$ para A = \\left[\\begin{array}{cc} 4 & 0\\\\ 0 & 2\\\\ 1 & 1 \\end{array}\\right] \\;\\;\\; \\boldsymbol{b}=\\left[\\begin{array}{c} 2\\\\ 0\\\\ 11 \\end{array}\\right] Ejemplo 2: Encuentre una soluci\u00f3n de m\u00ednimos cuadrados del sistema inconsistente $A\\boldsymbol{x}=\\boldsymbol{b}$ para A=\\left[\\begin{array}{cccc} 1 & 1 & 0 & 0\\\\ 1 & 1 & 0 & 0\\\\ 1 & 0 & 1 & 0\\\\ 1 & 0 & 1 & 0\\\\ 1 & 0 & 0 & 1\\\\ 1 & 0 & 0 & 1 \\end{array}\\right] \\;\\;\\; \\boldsymbol{b}=\\left[\\begin{array}{c} -3\\\\ -1\\\\ 0\\\\ 2\\\\ 5\\\\ 1 \\end{array}\\right] Observe que en este caso la forma escalonada de $A^TA$ muestra que el sistema tiene infinita soluciones para el problema de m\u00ednimos cuadrados. Con esto debe de tener cuidado, pues en realidad existe una sola $\\mathbb{proj}\\boldsymbol{b}$ de $\\boldsymbol{b}$, sin embargo todos estos vectores se encuentran a la misma distancia de $\\boldsymbol{b}$. El siguiente teorema es \u00fatil para determinar si existe una \u00fanica soluci\u00f3n de m\u00ednimos cuadrados Sea A una matriz de $m \\times n$. Los siguientes enunciados son l\u00f3gicamente equivalentes: La ecuaci\u00f3n $A\\boldsymbol{x} = \\boldsymbol{b}$ tiene una soluci\u00f3n de m\u00ednimos cuadrados \u00fanica para cada $\\boldsymbol{b}$ en $\\mathbb{R^m}$. Las columnas de $A$ son linealmente independientes. La matriz $A^TA$ es invertible. Cuando estos enunciados son verdaderos, la soluci\u00f3n $\\boldsymbol{\\hat{x}}$ de m\u00ednimos cuadrados est\u00e1 dada por \\boldsymbol{\\hat{x}}=(A^TA)^{-1}A^T\\boldsymbol{b} Problemas de M\u00ednimos Cuadrados para Factorizaci\u00f3n $QR$ En algunos casos, es posible que las ecuaciones normales para un problema de m\u00ednimos cuadrados est\u00e9n mal condicionadas; es decir, en ocasiones, peque\u00f1os errores en los c\u00e1lculos de las entradas de $A^TA$ causan grandes errores en la soluci\u00f3n $\\boldsymbol{\\hat{x}}$. Si las columnas de $A$ son linealmente independientes, la soluci\u00f3n de m\u00ednimos cuadrados con frecuencia se puede calcular de manera m\u00e1s confiable con una factorizaci\u00f3n $QR$ de $A$. Dada una matriz $A$ de $m \\times n$, con columnas linealmente independientes, sea $A=QR$ una factorizaci\u00f3n $QR$ de $A$. Entonces, para cada $\\boldsymbol{b}$ en $\\mathbb{R^m}$, la ecuaci\u00f3n $A\\boldsymbol{x} = \\boldsymbol{b}$ tiene una soluci\u00f3n de m\u00ednimos cuadrados \u00fanica, dada por \\boldsymbol{\\hat{x}}=R^{-1}Q^T\\boldsymbol{b} Ejemplo 3: Encuentre la soluci\u00f3n de m\u00ednimos cuadrados de $A\\boldsymbol{x} = \\boldsymbol{b}$ para A=\\left[\\begin{array}{ccc} 1 & 3 & 5\\\\ 1 & 1 & 0\\\\ 1 & 1 & 2\\\\ 1 & 3 & 3 \\end{array}\\right] \\;\\;\\; b=\\left[\\begin{array}{c} 3\\\\ 5\\\\ 7\\\\ -3 \\end{array}\\right]","title":"6.5 Problemas de M\u00ednimos Cuadrados"},{"location":"chapter_06/65_Problemas_de_Minimos_Cuadrados/#6-ortogonalidad-y-minimos-cuadrados","text":"","title":"6. Ortogonalidad y M\u00ednimos Cuadrados"},{"location":"chapter_06/65_Problemas_de_Minimos_Cuadrados/#65-problemas-de-minimos-cuadrados","text":"Cuando se desea una soluci\u00f3n y la misma no existe, lo mejor que se puede hacer es encontrar una $\\boldsymbol{x}$ tal que $A\\boldsymbol{x}$ est\u00e9 lo m\u00e1s cerca posible de $\\boldsymbol{b}$. Podemos decir que: $A\\boldsymbol{x}$ es una aproximaci\u00f3n de $\\boldsymbol{b}$. Cuanto menor sea la distancia entre $\\boldsymbol{b}$ y $A\\boldsymbol{x}$, $\\left\\Vert \\boldsymbol{b} - A\\boldsymbol{x}\\right \\Vert $, mucho mejor ser\u00e1 la aproximaci\u00f3n. El problema general de m\u00ednimos cuadrados consiste en encontrar una $\\boldsymbol{x}$ que haga a $\\left\\Vert \\boldsymbol{b} - A\\boldsymbol{x}\\right \\Vert $ tan peque\u00f1a como sea posible.","title":"6.5 Problemas de M\u00ednimos Cuadrados"},{"location":"chapter_06/65_Problemas_de_Minimos_Cuadrados/#definicion-del-problema-de-minimos-cuadrados","text":"Si $A$ es de $m \\times n$ y $\\boldsymbol{b}$ en $\\mathbb{R^m}$, una soluci\u00f3n de m\u00ednimos cuadrados de $A\\boldsymbol{x}=\\boldsymbol{b}$ es un $\\boldsymbol{\\hat{x}}$ en $\\mathbb{R^n}$ tal que \\left\\Vert \\boldsymbol{b} - A\\boldsymbol{\\hat{x}}\\right \\Vert \\leq \\left\\Vert \\boldsymbol{b} - A\\boldsymbol{x}\\right \\Vert para cualquier $\\boldsymbol{x}$ en $\\mathbb{R^n}$ En forma resumida, el Problema de M\u00ednimos Cuadrados busca el vector $\\boldsymbol{x}$ que haga que $A\\boldsymbol{x}$ sea el punto en $\\mathbf{Col}A$ m\u00e1s cercano a $\\boldsymbol{b}$.","title":"Definici\u00f3n del Problema de M\u00ednimos Cuadrados"},{"location":"chapter_06/65_Problemas_de_Minimos_Cuadrados/#ecuacion-de-un-problema-de-minimos-cuadrados","text":"La ecuaci\u00f3n de la soluci\u00f3n de un problema por m\u00ednimos cuadrados es A^TA\\boldsymbol{x}=A^T\\boldsymbol{b} Usualmente a esta ecuaci\u00f3n se le denomina Sistema de Ecuaciones Normales para $A\\boldsymbol{x}=\\boldsymbol{b}$ . Esta ecuaci\u00f3n se puede obtener si se considera que $A\\boldsymbol{x}=\\boldsymbol{b}$ no tiene soluci\u00f3n, sin embargo se puede buscar un A\\boldsymbol{\\hat{x}}=\\boldsymbol{\\hat{b}} que si existe. Observe que la descomposici\u00f3n ortogonal $\\boldsymbol{z}=\\boldsymbol{b}-\\boldsymbol{\\hat{{b}}}$ debe de ser v\u00e1lida. As\u00ed mismo, $\\boldsymbol{z}$ debe de ser ortogonal a $\\mathbf{Col}A$ por lo que \\boldsymbol{a_1}\\cdot\\boldsymbol{z}=\\boldsymbol{a_1}\\cdot(\\boldsymbol{b}-\\boldsymbol{\\hat{{b}}})=\\boldsymbol{a_1}^T(\\boldsymbol{b}-\\boldsymbol{\\hat{{b}}})=0 \\boldsymbol{a_2}\\cdot\\boldsymbol{z}=\\boldsymbol{a_2}\\cdot(\\boldsymbol{b}-\\boldsymbol{\\hat{{b}}})=\\boldsymbol{a_2}^T(\\boldsymbol{b}-\\boldsymbol{\\hat{{b}}})=0 \\vdots \\boldsymbol{a_n}\\cdot\\boldsymbol{z}=\\boldsymbol{a_n}\\cdot(\\boldsymbol{b}-\\boldsymbol{\\hat{{b}}})=\\boldsymbol{a_n}^T(\\boldsymbol{b}-\\boldsymbol{\\hat{{b}}})=0 Si $A^T=[\\boldsymbol{a_1}^T \\;\\boldsymbol{a_2}^T \\; \\dots\\;\\boldsymbol{a_n}^T]$, se puede escribir A^T(\\boldsymbol{b}-\\boldsymbol{\\hat{{b}}})=0 A^T(\\boldsymbol{b}-A\\boldsymbol{\\hat{{x}}})=0 A^T\\boldsymbol{b}-A^TA\\boldsymbol{\\hat{{x}}}=0 A^TA\\boldsymbol{x}=A^T\\boldsymbol{b} Teorema El conjunto de soluciones de m\u00ednimos cuadrados de $A\\boldsymbol{x}=\\boldsymbol{b}$ coincide con el conjunto no vac\u00edo de soluciones de las ecuaciones normales $A^TA\\boldsymbol{x}=A^T\\boldsymbol{b}$. Ejemplo 1: Encuentre una soluci\u00f3n de m\u00ednimos cuadrados del sistema inconsistente $A\\boldsymbol{x}=\\boldsymbol{b}$ para A = \\left[\\begin{array}{cc} 4 & 0\\\\ 0 & 2\\\\ 1 & 1 \\end{array}\\right] \\;\\;\\; \\boldsymbol{b}=\\left[\\begin{array}{c} 2\\\\ 0\\\\ 11 \\end{array}\\right] Ejemplo 2: Encuentre una soluci\u00f3n de m\u00ednimos cuadrados del sistema inconsistente $A\\boldsymbol{x}=\\boldsymbol{b}$ para A=\\left[\\begin{array}{cccc} 1 & 1 & 0 & 0\\\\ 1 & 1 & 0 & 0\\\\ 1 & 0 & 1 & 0\\\\ 1 & 0 & 1 & 0\\\\ 1 & 0 & 0 & 1\\\\ 1 & 0 & 0 & 1 \\end{array}\\right] \\;\\;\\; \\boldsymbol{b}=\\left[\\begin{array}{c} -3\\\\ -1\\\\ 0\\\\ 2\\\\ 5\\\\ 1 \\end{array}\\right] Observe que en este caso la forma escalonada de $A^TA$ muestra que el sistema tiene infinita soluciones para el problema de m\u00ednimos cuadrados. Con esto debe de tener cuidado, pues en realidad existe una sola $\\mathbb{proj}\\boldsymbol{b}$ de $\\boldsymbol{b}$, sin embargo todos estos vectores se encuentran a la misma distancia de $\\boldsymbol{b}$. El siguiente teorema es \u00fatil para determinar si existe una \u00fanica soluci\u00f3n de m\u00ednimos cuadrados Sea A una matriz de $m \\times n$. Los siguientes enunciados son l\u00f3gicamente equivalentes: La ecuaci\u00f3n $A\\boldsymbol{x} = \\boldsymbol{b}$ tiene una soluci\u00f3n de m\u00ednimos cuadrados \u00fanica para cada $\\boldsymbol{b}$ en $\\mathbb{R^m}$. Las columnas de $A$ son linealmente independientes. La matriz $A^TA$ es invertible. Cuando estos enunciados son verdaderos, la soluci\u00f3n $\\boldsymbol{\\hat{x}}$ de m\u00ednimos cuadrados est\u00e1 dada por \\boldsymbol{\\hat{x}}=(A^TA)^{-1}A^T\\boldsymbol{b}","title":"Ecuaci\u00f3n de un Problema de M\u00ednimos Cuadrados"},{"location":"chapter_06/65_Problemas_de_Minimos_Cuadrados/#problemas-de-minimos-cuadrados-para-factorizacion-qr","text":"En algunos casos, es posible que las ecuaciones normales para un problema de m\u00ednimos cuadrados est\u00e9n mal condicionadas; es decir, en ocasiones, peque\u00f1os errores en los c\u00e1lculos de las entradas de $A^TA$ causan grandes errores en la soluci\u00f3n $\\boldsymbol{\\hat{x}}$. Si las columnas de $A$ son linealmente independientes, la soluci\u00f3n de m\u00ednimos cuadrados con frecuencia se puede calcular de manera m\u00e1s confiable con una factorizaci\u00f3n $QR$ de $A$. Dada una matriz $A$ de $m \\times n$, con columnas linealmente independientes, sea $A=QR$ una factorizaci\u00f3n $QR$ de $A$. Entonces, para cada $\\boldsymbol{b}$ en $\\mathbb{R^m}$, la ecuaci\u00f3n $A\\boldsymbol{x} = \\boldsymbol{b}$ tiene una soluci\u00f3n de m\u00ednimos cuadrados \u00fanica, dada por \\boldsymbol{\\hat{x}}=R^{-1}Q^T\\boldsymbol{b} Ejemplo 3: Encuentre la soluci\u00f3n de m\u00ednimos cuadrados de $A\\boldsymbol{x} = \\boldsymbol{b}$ para A=\\left[\\begin{array}{ccc} 1 & 3 & 5\\\\ 1 & 1 & 0\\\\ 1 & 1 & 2\\\\ 1 & 3 & 3 \\end{array}\\right] \\;\\;\\; b=\\left[\\begin{array}{c} 3\\\\ 5\\\\ 7\\\\ -3 \\end{array}\\right]","title":"Problemas de M\u00ednimos Cuadrados para Factorizaci\u00f3n $QR$"}]}